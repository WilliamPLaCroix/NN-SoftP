
=============
== PyTorch ==
=============

NVIDIA Release 24.01 (build 80741402)
PyTorch Version 2.2.0a0+81ea7a4

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

NOTE: CUDA Forward Compatibility mode ENABLED.
  Using CUDA 12.3 driver version 545.23.08 with kernel driver version 525.85.12.
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

Language Model has hidden_size: 5120
freezing Model... (AutoModel)
Running on device: cuda
Epoch [1/300] took 171.7255244255066s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.794460190048099, train accuracy: 0.18297789463433636
Val mean loss: 1.7971536211851167, val accuracy: 0.18925233644859812

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
45 			 1998 			 7
5689 			 2123 			 1157
209 			 1966 			 47
112 			 1683 			 14
4212 			 1657 			 653
2 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
7 			 263 			 0
826 			 248 			 161
49 			 251 			 9
18 			 169 			 7
384 			 237 			 66
0 			 116 			 0
Max memory allocated: 13077464576; Memory allocated: 7190770176
Epoch [2/300] took 173.2694685459137s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.784844375473688, train accuracy: 0.18765215697731036
Val mean loss: 1.7818984781823508, val accuracy: 0.1939252336448598

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
111 			 1998 			 20
6968 			 2123 			 1402
437 			 1966 			 99
121 			 1683 			 15
2631 			 1657 			 391
1 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
16 			 263 			 2
931 			 248 			 181
68 			 251 			 17
18 			 169 			 6
251 			 237 			 43
0 			 116 			 0
Max memory allocated: 13090566144; Memory allocated: 7217921024
Epoch [3/300] took 173.1995828151703s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7785707730741886, train accuracy: 0.1925211802512416
Val mean loss: 1.7799701661598393, val accuracy: 0.19626168224299065

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
221 			 1998 			 32
7503 			 2123 			 1520
619 			 1966 			 141
114 			 1683 			 16
1810 			 1657 			 268
2 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
27 			 263 			 4
986 			 248 			 193
85 			 251 			 19
16 			 169 			 6
170 			 237 			 30
0 			 116 			 0
Max memory allocated: 13435397120; Memory allocated: 7268024320
Epoch [4/300] took 173.10405731201172s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7733047985213568, train accuracy: 0.19865614957639496
Val mean loss: 1.777080806290231, val accuracy: 0.19626168224299065

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
319 			 1998 			 52
7901 			 2123 			 1603
739 			 1966 			 177
104 			 1683 			 15
1206 			 1657 			 193
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
47 			 263 			 7
1001 			 248 			 194
105 			 251 			 23
14 			 169 			 4
117 			 237 			 24
0 			 116 			 0
Max memory allocated: 13435397120; Memory allocated: 7294107648
Epoch [5/300] took 173.28895664215088s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.769204806315936, train accuracy: 0.1956373551465576
Val mean loss: 1.7799117099948045, val accuracy: 0.1954828660436137

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
417 			 1998 			 64
8037 			 2123 			 1623
832 			 1966 			 178
107 			 1683 			 16
876 			 1657 			 128
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
65 			 263 			 8
996 			 248 			 193
132 			 251 			 34
7 			 169 			 2
84 			 237 			 14
0 			 116 			 0
Max memory allocated: 13543157760; Memory allocated: 7355033600
Epoch [6/300] took 172.53002834320068s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7666149484777005, train accuracy: 0.1991430519037881
Val mean loss: 1.7727523954903208, val accuracy: 0.20015576323987538

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
540 			 1998 			 78
8026 			 2123 			 1619
905 			 1966 			 218
105 			 1683 			 20
693 			 1657 			 110
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
69 			 263 			 9
1006 			 248 			 197
128 			 251 			 35
6 			 169 			 1
75 			 237 			 15
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7197465600
Epoch [7/300] took 172.66602039337158s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.763355994521643, train accuracy: 0.20001947609309573
Val mean loss: 1.7689996085515836, val accuracy: 0.20171339563862928

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
625 			 1998 			 96
8004 			 2123 			 1620
1016 			 1966 			 241
87 			 1683 			 13
537 			 1657 			 84
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
78 			 263 			 14
994 			 248 			 191
138 			 251 			 39
7 			 169 			 1
67 			 237 			 14
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7201618944
Epoch [8/300] took 173.36222958564758s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7611116839346486, train accuracy: 0.20216184633362547
Val mean loss: 1.7703110125006698, val accuracy: 0.1923676012461059

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
760 			 1998 			 140
7776 			 2123 			 1569
1093 			 1966 			 258
98 			 1683 			 18
542 			 1657 			 91
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
85 			 263 			 12
989 			 248 			 188
139 			 251 			 32
8 			 169 			 2
63 			 237 			 13
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7228636160
Epoch [9/300] took 171.8041229248047s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7590982360631877, train accuracy: 0.2057649235563346
Val mean loss: 1.760550164594883, val accuracy: 0.19314641744548286

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
834 			 1998 			 153
7747 			 2123 			 1589
1116 			 1966 			 267
92 			 1683 			 19
480 			 1657 			 85
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
112 			 263 			 18
964 			 248 			 180
153 			 251 			 40
7 			 169 			 2
48 			 237 			 8
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7236951040
Epoch [10/300] took 172.53799891471863s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7571437637382579, train accuracy: 0.203330411919369
Val mean loss: 1.7663747275747903, val accuracy: 0.20249221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
836 			 1998 			 153
7826 			 2123 			 1580
1088 			 1966 			 257
94 			 1683 			 22
425 			 1657 			 76
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
104 			 263 			 17
985 			 248 			 192
131 			 251 			 40
10 			 169 			 1
54 			 237 			 10
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7199243264
Epoch [11/300] took 172.55004715919495s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7551231165169927, train accuracy: 0.20508326029798424
Val mean loss: 1.7581700435498866, val accuracy: 0.19937694704049844

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
854 			 1998 			 166
7751 			 2123 			 1575
1143 			 1966 			 269
106 			 1683 			 24
415 			 1657 			 72
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
94 			 263 			 18
991 			 248 			 187
141 			 251 			 41
9 			 169 			 1
49 			 237 			 9
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7198489600
Epoch [12/300] took 172.26205897331238s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7534735793265226, train accuracy: 0.2088810984516506
Val mean loss: 1.7663351064775048, val accuracy: 0.19626168224299065

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
865 			 1998 			 161
7673 			 2123 			 1574
1218 			 1966 			 307
121 			 1683 			 32
392 			 1657 			 71
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
130 			 263 			 25
926 			 248 			 171
164 			 251 			 45
11 			 169 			 2
53 			 237 			 9
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7211392000
Epoch [13/300] took 172.96987962722778s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.751270854955893, train accuracy: 0.21141299055409485
Val mean loss: 1.7562354250652035, val accuracy: 0.1970404984423676

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
907 			 1998 			 182
7627 			 2123 			 1578
1190 			 1966 			 301
138 			 1683 			 36
407 			 1657 			 74
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
109 			 263 			 17
967 			 248 			 183
140 			 251 			 40
13 			 169 			 4
55 			 237 			 9
0 			 116 			 0
Max memory allocated: 13980285952; Memory allocated: 7192623104
Epoch [14/300] took 172.65118789672852s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7500483428949136, train accuracy: 0.21170513195053073
Val mean loss: 1.7552284845491735, val accuracy: 0.20794392523364486

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
933 			 1998 			 180
7430 			 2123 			 1535
1307 			 1966 			 339
155 			 1683 			 38
444 			 1657 			 82
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
111 			 263 			 21
947 			 248 			 186
157 			 251 			 47
15 			 169 			 2
54 			 237 			 11
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7260307456
Epoch [15/300] took 172.32965922355652s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7487440918836268, train accuracy: 0.21345798032914598
Val mean loss: 1.7617937791638258, val accuracy: 0.20482866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
892 			 1998 			 178
7593 			 2123 			 1580
1222 			 1966 			 318
154 			 1683 			 40
408 			 1657 			 76
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
124 			 263 			 22
928 			 248 			 179
168 			 251 			 50
11 			 169 			 2
53 			 237 			 10
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7233829888
Epoch [16/300] took 172.62773537635803s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7468023909215245, train accuracy: 0.2116077514850521
Val mean loss: 1.7550991221172054, val accuracy: 0.20794392523364486

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
923 			 1998 			 169
7352 			 2123 			 1509
1382 			 1966 			 368
172 			 1683 			 49
440 			 1657 			 78
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
127 			 263 			 27
932 			 248 			 180
161 			 251 			 49
12 			 169 			 2
52 			 237 			 9
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7225261056
Epoch [17/300] took 172.67341327667236s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7448331448147973, train accuracy: 0.2147239263803681
Val mean loss: 1.7491589842773065, val accuracy: 0.20327102803738317

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
933 			 1998 			 191
7306 			 2123 			 1511
1392 			 1966 			 362
179 			 1683 			 45
459 			 1657 			 96
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
112 			 263 			 27
939 			 248 			 176
162 			 251 			 45
14 			 169 			 3
57 			 237 			 10
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7194048512
Epoch [18/300] took 172.40580916404724s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.742899836038132, train accuracy: 0.21540558963871848
Val mean loss: 1.7510076790321163, val accuracy: 0.205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
932 			 1998 			 187
7368 			 2123 			 1530
1358 			 1966 			 358
193 			 1683 			 51
418 			 1657 			 86
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
110 			 263 			 22
931 			 248 			 179
179 			 251 			 53
13 			 169 			 3
51 			 237 			 7
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7235673088
Epoch [19/300] took 172.8037133216858s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7415643581348788, train accuracy: 0.2139448826565391
Val mean loss: 1.7476150059118503, val accuracy: 0.2087227414330218

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
916 			 1998 			 193
7250 			 2123 			 1485
1451 			 1966 			 375
218 			 1683 			 56
434 			 1657 			 88
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
128 			 263 			 26
907 			 248 			 176
180 			 251 			 54
15 			 169 			 3
54 			 237 			 9
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7157725184
Epoch [20/300] took 173.19713401794434s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7398093864553814, train accuracy: 0.2182296231375986
Val mean loss: 1.748122389723615, val accuracy: 0.21651090342679127

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
956 			 1998 			 206
7114 			 2123 			 1480
1484 			 1966 			 394
236 			 1683 			 61
479 			 1657 			 100
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
125 			 263 			 27
910 			 248 			 175
168 			 251 			 61
20 			 169 			 6
61 			 237 			 9
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7213390848
Epoch [21/300] took 171.90371918678284s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7378282521001276, train accuracy: 0.2193981887233421
Val mean loss: 1.7516140472598192, val accuracy: 0.20327102803738317

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1001 			 1998 			 225
7010 			 2123 			 1456
1536 			 1966 			 407
231 			 1683 			 61
491 			 1657 			 104
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
136 			 263 			 28
888 			 248 			 164
179 			 251 			 51
24 			 169 			 7
57 			 237 			 11
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7242678272
Epoch [22/300] took 172.44979619979858s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7368804647172351, train accuracy: 0.22085889570552147
Val mean loss: 1.7428695661265676, val accuracy: 0.20794392523364486

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
945 			 1998 			 216
7114 			 2123 			 1491
1488 			 1966 			 404
244 			 1683 			 60
478 			 1657 			 97
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
149 			 263 			 31
854 			 248 			 160
198 			 251 			 59
24 			 169 			 6
59 			 237 			 11
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7198784512
Epoch [23/300] took 172.6637523174286s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7351681632787639, train accuracy: 0.22183270036030772
Val mean loss: 1.7467045318789598, val accuracy: 0.21651090342679127

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1064 			 1998 			 239
6963 			 2123 			 1462
1489 			 1966 			 402
261 			 1683 			 72
492 			 1657 			 103
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
140 			 263 			 32
872 			 248 			 171
178 			 251 			 55
33 			 169 			 9
61 			 237 			 11
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7265927168
Epoch [24/300] took 171.9832901954651s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7337038747246762, train accuracy: 0.2249488752556237
Val mean loss: 1.7430703465531512, val accuracy: 0.21495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1077 			 1998 			 243
6829 			 2123 			 1450
1599 			 1966 			 432
270 			 1683 			 76
494 			 1657 			 109
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
147 			 263 			 32
853 			 248 			 164
184 			 251 			 57
31 			 169 			 9
69 			 237 			 14
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7220935680
Epoch [25/300] took 172.01760745048523s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7329037616557421, train accuracy: 0.22475411432466647
Val mean loss: 1.7438636872826554, val accuracy: 0.20950155763239875

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1170 			 1998 			 264
6575 			 2123 			 1380
1663 			 1966 			 463
300 			 1683 			 84
561 			 1657 			 117
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
153 			 263 			 31
852 			 248 			 163
179 			 251 			 54
32 			 169 			 8
68 			 237 			 13
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7189641216
Epoch [26/300] took 173.1248264312744s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.732436575622202, train accuracy: 0.22592267991040998
Val mean loss: 1.739037086323994, val accuracy: 0.2071651090342679

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1067 			 1998 			 244
6779 			 2123 			 1452
1532 			 1966 			 419
314 			 1683 			 83
577 			 1657 			 122
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
139 			 263 			 29
857 			 248 			 163
177 			 251 			 51
33 			 169 			 8
78 			 237 			 15
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7254949888
Epoch [27/300] took 171.62669849395752s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.730905142528617, train accuracy: 0.23049956178790534
Val mean loss: 1.7335656997634143, val accuracy: 0.21105919003115264

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1182 			 1998 			 267
6480 			 2123 			 1394
1680 			 1966 			 483
333 			 1683 			 88
594 			 1657 			 135
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
148 			 263 			 30
832 			 248 			 156
188 			 251 			 62
33 			 169 			 9
83 			 237 			 14
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7198783488
Epoch [28/300] took 171.56073880195618s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7290569105623668, train accuracy: 0.2283571915473756
Val mean loss: 1.7377279182759726, val accuracy: 0.20950155763239875

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1113 			 1998 			 249
6499 			 2123 			 1378
1717 			 1966 			 485
358 			 1683 			 101
582 			 1657 			 132
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
151 			 263 			 32
811 			 248 			 157
202 			 251 			 58
38 			 169 			 9
82 			 237 			 13
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7201758208
Epoch [29/300] took 172.3642909526825s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.728166095935667, train accuracy: 0.22855195247833285
Val mean loss: 1.7369615479213436, val accuracy: 0.2087227414330218

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1156 			 1998 			 277
6422 			 2123 			 1365
1694 			 1966 			 478
373 			 1683 			 96
624 			 1657 			 131
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
152 			 263 			 36
800 			 248 			 149
211 			 251 			 60
31 			 169 			 8
90 			 237 			 15
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7354583040
Epoch [30/300] took 172.71498560905457s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.727304178234944, train accuracy: 0.23001265946051222
Val mean loss: 1.7380121917259403, val accuracy: 0.2118380062305296

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1144 			 1998 			 259
6446 			 2123 			 1387
1685 			 1966 			 481
369 			 1683 			 97
625 			 1657 			 138
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
158 			 263 			 36
798 			 248 			 153
205 			 251 			 61
37 			 169 			 8
86 			 237 			 14
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7212448768
Epoch [31/300] took 171.88223838806152s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7257181495149558, train accuracy: 0.23196026877008472
Val mean loss: 1.733890539262353, val accuracy: 0.21962616822429906

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1246 			 1998 			 287
6238 			 2123 			 1339
1763 			 1966 			 513
409 			 1683 			 106
613 			 1657 			 137
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
162 			 263 			 37
772 			 248 			 154
220 			 251 			 67
44 			 169 			 10
86 			 237 			 14
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7222590464
Epoch [32/300] took 172.92269277572632s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7253680333170192, train accuracy: 0.2330314538903496
Val mean loss: 1.739220084213629, val accuracy: 0.21651090342679127

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1176 			 1998 			 288
6204 			 2123 			 1330
1772 			 1966 			 506
429 			 1683 			 108
688 			 1657 			 161
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
160 			 263 			 37
754 			 248 			 147
230 			 251 			 71
47 			 169 			 10
93 			 237 			 13
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7189477376
Epoch [33/300] took 172.82804703712463s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7236377346181424, train accuracy: 0.23624500925114422
Val mean loss: 1.7289019154339302, val accuracy: 0.2118380062305296

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1284 			 1998 			 319
6041 			 2123 			 1306
1800 			 1966 			 517
453 			 1683 			 126
691 			 1657 			 158
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
166 			 263 			 38
764 			 248 			 146
218 			 251 			 66
50 			 169 			 9
86 			 237 			 13
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7242365952
Epoch [34/300] took 172.79371881484985s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.722307576940067, train accuracy: 0.2349790631999221
Val mean loss: 1.7297721490627382, val accuracy: 0.21417445482866043

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1274 			 1998 			 310
6056 			 2123 			 1313
1773 			 1966 			 509
449 			 1683 			 120
717 			 1657 			 161
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
176 			 263 			 40
741 			 248 			 144
227 			 251 			 65
50 			 169 			 11
90 			 237 			 15
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7192803328
Epoch [35/300] took 172.2172348499298s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7211928022242038, train accuracy: 0.2357581069237511
Val mean loss: 1.7278517397438609, val accuracy: 0.21495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1324 			 1998 			 316
6004 			 2123 			 1304
1819 			 1966 			 533
447 			 1683 			 116
675 			 1657 			 152
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
175 			 263 			 39
745 			 248 			 141
227 			 251 			 70
50 			 169 			 11
87 			 237 			 15
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7230651392
Epoch [36/300] took 173.0074062347412s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.720208500775964, train accuracy: 0.2384847599571526
Val mean loss: 1.7249893269887784, val accuracy: 0.21806853582554517

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1390 			 1998 			 339
5785 			 2123 			 1268
1922 			 1966 			 553
471 			 1683 			 123
701 			 1657 			 166
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
173 			 263 			 41
738 			 248 			 138
226 			 251 			 71
56 			 169 			 14
91 			 237 			 16
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7228472320
Epoch [37/300] took 173.05275964736938s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7197939840804009, train accuracy: 0.2384847599571526
Val mean loss: 1.7267555201925882, val accuracy: 0.2235202492211838

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1478 			 1998 			 350
5542 			 2123 			 1229
1943 			 1966 			 555
549 			 1683 			 142
757 			 1657 			 173
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
176 			 263 			 46
726 			 248 			 144
226 			 251 			 66
61 			 169 			 16
95 			 237 			 15
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7251673088
Epoch [38/300] took 171.74938464164734s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7186024530654385, train accuracy: 0.2392638036809816
Val mean loss: 1.7270278000250094, val accuracy: 0.22118380062305296

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1488 			 1998 			 352
5633 			 2123 			 1250
1958 			 1966 			 564
482 			 1683 			 126
708 			 1657 			 165
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
184 			 263 			 48
725 			 248 			 142
222 			 251 			 65
56 			 169 			 14
97 			 237 			 15
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7216897024
Epoch [39/300] took 172.3162567615509s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7175943253567656, train accuracy: 0.24189307624890447
Val mean loss: 1.7240965279137217, val accuracy: 0.22585669781931464

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1592 			 1998 			 385
5605 			 2123 			 1255
1891 			 1966 			 558
504 			 1683 			 127
677 			 1657 			 159
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
203 			 263 			 51
683 			 248 			 135
246 			 251 			 73
59 			 169 			 14
93 			 237 			 17
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7292862464
Epoch [40/300] took 172.28578877449036s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7163017928785995, train accuracy: 0.2431590223001266
Val mean loss: 1.727600865247773, val accuracy: 0.22897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1594 			 1998 			 390
5333 			 2123 			 1196
2054 			 1966 			 588
534 			 1683 			 138
754 			 1657 			 185
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
211 			 263 			 52
674 			 248 			 135
246 			 251 			 75
56 			 169 			 14
97 			 237 			 18
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7230766080
Epoch [41/300] took 172.81388521194458s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.715934452609481, train accuracy: 0.2458856753335281
Val mean loss: 1.7241370299967325, val accuracy: 0.220404984423676

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1630 			 1998 			 411
5150 			 2123 			 1169
2143 			 1966 			 616
570 			 1683 			 140
776 			 1657 			 189
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
199 			 263 			 48
676 			 248 			 133
243 			 251 			 70
66 			 169 			 16
100 			 237 			 16
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7198047232
Epoch [42/300] took 172.0129532814026s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7142551584035808, train accuracy: 0.24685947998831434
Val mean loss: 1.7204673958987724, val accuracy: 0.22819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1664 			 1998 			 423
5191 			 2123 			 1183
2101 			 1966 			 601
564 			 1683 			 144
748 			 1657 			 184
1 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
224 			 263 			 56
655 			 248 			 127
250 			 251 			 74
62 			 169 			 18
93 			 237 			 18
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7151089664
Epoch [43/300] took 172.4292550086975s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7139097842100626, train accuracy: 0.2482228065050151
Val mean loss: 1.7272085532909487, val accuracy: 0.2266355140186916

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1761 			 1998 			 449
5143 			 2123 			 1171
2094 			 1966 			 605
561 			 1683 			 142
710 			 1657 			 182
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
228 			 263 			 58
647 			 248 			 129
248 			 251 			 71
64 			 169 			 17
97 			 237 			 16
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7211654144
Epoch [44/300] took 173.20136761665344s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.712354922220343, train accuracy: 0.2478332846431006
Val mean loss: 1.7244133367771055, val accuracy: 0.22819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1842 			 1998 			 465
5105 			 2123 			 1154
2005 			 1966 			 595
608 			 1683 			 150
709 			 1657 			 181
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
238 			 263 			 62
649 			 248 			 129
242 			 251 			 70
60 			 169 			 15
95 			 237 			 17
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7213702144
Epoch [45/300] took 172.8313283920288s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7123656614547207, train accuracy: 0.25231278605511737
Val mean loss: 1.7221824337796467, val accuracy: 0.23208722741433022

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1844 			 1998 			 479
5029 			 2123 			 1154
2096 			 1966 			 625
581 			 1683 			 148
719 			 1657 			 185
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
246 			 263 			 65
628 			 248 			 122
254 			 251 			 75
64 			 169 			 17
92 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7197865984
Epoch [46/300] took 172.52733540534973s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7109786019518367, train accuracy: 0.2554289609504333
Val mean loss: 1.7222628593444824, val accuracy: 0.24143302180685358

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1969 			 1998 			 522
4834 			 2123 			 1124
2155 			 1966 			 629
598 			 1683 			 161
713 			 1657 			 187
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
256 			 263 			 70
612 			 248 			 126
259 			 251 			 81
65 			 169 			 16
92 			 237 			 17
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7194146816
Epoch [47/300] took 171.71448755264282s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7098598844165742, train accuracy: 0.25289706884798907
Val mean loss: 1.7237990861985741, val accuracy: 0.23753894080996885

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2030 			 1998 			 529
4784 			 2123 			 1094
2164 			 1966 			 633
573 			 1683 			 152
718 			 1657 			 189
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
256 			 263 			 67
622 			 248 			 126
256 			 251 			 79
62 			 169 			 17
88 			 237 			 16
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7205895168
Epoch [48/300] took 172.7310495376587s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7096903944312598, train accuracy: 0.25591586327782645
Val mean loss: 1.7117931115918044, val accuracy: 0.24299065420560748

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2107 			 1998 			 551
4826 			 2123 			 1122
2075 			 1966 			 618
588 			 1683 			 149
672 			 1657 			 188
1 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
283 			 263 			 76
591 			 248 			 124
249 			 251 			 78
71 			 169 			 18
90 			 237 			 16
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7224884224
Epoch [49/300] took 171.9811987876892s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7081505628389733, train accuracy: 0.258642516311228
Val mean loss: 1.7135724120023774, val accuracy: 0.24454828660436137

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2187 			 1998 			 571
4566 			 2123 			 1080
2209 			 1966 			 661
607 			 1683 			 157
700 			 1657 			 187
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
288 			 263 			 78
570 			 248 			 122
259 			 251 			 80
76 			 169 			 17
91 			 237 			 17
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7199702016
Epoch [50/300] took 172.55653977394104s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7077360951640523, train accuracy: 0.26244035446489433
Val mean loss: 1.7158175125354673, val accuracy: 0.24610591900311526

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2217 			 1998 			 597
4506 			 2123 			 1080
2134 			 1966 			 643
661 			 1683 			 179
751 			 1657 			 196
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
301 			 263 			 81
563 			 248 			 119
265 			 251 			 80
67 			 169 			 17
88 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7191091200
Epoch [51/300] took 172.06164264678955s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7067184875315966, train accuracy: 0.26321939818872336
Val mean loss: 1.7170344591140747, val accuracy: 0.2515576323987539

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2391 			 1998 			 642
4371 			 2123 			 1042
2187 			 1966 			 656
613 			 1683 			 168
707 			 1657 			 195
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
307 			 263 			 84
570 			 248 			 125
246 			 251 			 78
72 			 169 			 17
89 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7228472320
Epoch [52/300] took 172.2909722328186s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7062772297042181, train accuracy: 0.2626351153958516
Val mean loss: 1.7216270231619113, val accuracy: 0.2507788161993769

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2400 			 1998 			 635
4322 			 2123 			 1044
2165 			 1966 			 652
657 			 1683 			 177
725 			 1657 			 189
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
315 			 263 			 88
546 			 248 			 117
259 			 251 			 80
74 			 169 			 18
90 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7232740352
Epoch [53/300] took 172.33299827575684s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.705326128600171, train accuracy: 0.26487486610185995
Val mean loss: 1.7078255531264515, val accuracy: 0.2507788161993769

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2407 			 1998 			 640
4295 			 2123 			 1038
2263 			 1966 			 683
600 			 1683 			 168
704 			 1657 			 191
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 92
533 			 248 			 116
258 			 251 			 78
73 			 169 			 17
86 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7199357952
Epoch [54/300] took 173.07893586158752s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.704887356342185, train accuracy: 0.26662771448047523
Val mean loss: 1.7223766809556542, val accuracy: 0.2538940809968847

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2604 			 1998 			 700
4084 			 2123 			 1004
2246 			 1966 			 673
622 			 1683 			 171
711 			 1657 			 190
2 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
346 			 263 			 98
523 			 248 			 112
258 			 251 			 78
71 			 169 			 19
86 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7193393152
Epoch [55/300] took 172.2790424823761s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.704462385994623, train accuracy: 0.2661408121530821
Val mean loss: 1.709995051709617, val accuracy: 0.26479750778816197

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2654 			 1998 			 707
4000 			 2123 			 980
2289 			 1966 			 681
605 			 1683 			 171
721 			 1657 			 194
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 100
516 			 248 			 116
263 			 251 			 84
69 			 169 			 19
85 			 237 			 21
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7208631296
Epoch [56/300] took 172.57171249389648s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7030011976248007, train accuracy: 0.2702307917031843
Val mean loss: 1.7219717182764194, val accuracy: 0.2515576323987539

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2691 			 1998 			 731
3976 			 2123 			 984
2247 			 1966 			 687
641 			 1683 			 179
713 			 1657 			 194
1 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
362 			 263 			 101
502 			 248 			 108
269 			 251 			 79
72 			 169 			 16
79 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7191664640
Epoch [57/300] took 172.87792921066284s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7021512625002044, train accuracy: 0.27256792287467135
Val mean loss: 1.7123760101271839, val accuracy: 0.2538940809968847

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2755 			 1998 			 751
3965 			 2123 			 988
2252 			 1966 			 686
636 			 1683 			 189
660 			 1657 			 184
1 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 102
509 			 248 			 111
261 			 251 			 75
71 			 169 			 18
82 			 237 			 20
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7201045504
Epoch [58/300] took 172.8024878501892s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.701341555125988, train accuracy: 0.27256792287467135
Val mean loss: 1.7163444030575636, val accuracy: 0.25778816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2787 			 1998 			 762
3993 			 2123 			 988
2243 			 1966 			 686
612 			 1683 			 184
632 			 1657 			 178
2 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
375 			 263 			 104
499 			 248 			 108
265 			 251 			 82
64 			 169 			 17
81 			 237 			 20
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7217298432
Epoch [59/300] took 172.9492325782776s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7016488324815982, train accuracy: 0.2731522056675431
Val mean loss: 1.7096592624013016, val accuracy: 0.2554517133956386

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2826 			 1998 			 778
3937 			 2123 			 979
2246 			 1966 			 675
592 			 1683 			 181
665 			 1657 			 190
3 			 842 			 2
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
376 			 263 			 105
488 			 248 			 107
261 			 251 			 78
73 			 169 			 17
85 			 237 			 21
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7277887488
Epoch [60/300] took 172.2378385066986s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.699991178289752, train accuracy: 0.2740286298568507
Val mean loss: 1.7129289580554496, val accuracy: 0.2538940809968847

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2959 			 1998 			 800
3723 			 2123 			 940
2316 			 1966 			 712
608 			 1683 			 177
659 			 1657 			 183
4 			 842 			 2
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
391 			 263 			 108
483 			 248 			 103
256 			 251 			 76
71 			 169 			 19
83 			 237 			 20
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7222656000
Epoch [61/300] took 172.46685481071472s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6997915079289136, train accuracy: 0.27490505404615834
Val mean loss: 1.7154307336342045, val accuracy: 0.25

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2975 			 1998 			 800
3714 			 2123 			 943
2277 			 1966 			 700
624 			 1683 			 187
676 			 1657 			 192
3 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
402 			 263 			 111
462 			 248 			 96
269 			 251 			 77
68 			 169 			 18
83 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7222377472
Epoch [62/300] took 172.98239278793335s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6991785419321506, train accuracy: 0.27695004382120947
Val mean loss: 1.71001278191078, val accuracy: 0.25778816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3021 			 1998 			 814
3629 			 2123 			 931
2298 			 1966 			 712
619 			 1683 			 191
699 			 1657 			 195
3 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
406 			 263 			 114
462 			 248 			 99
268 			 251 			 84
64 			 169 			 15
83 			 237 			 19
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7269941248
Epoch [63/300] took 172.20586442947388s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6979390119095086, train accuracy: 0.2758788587009446
Val mean loss: 1.713798043204517, val accuracy: 0.2570093457943925

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3142 			 1998 			 844
3649 			 2123 			 938
2237 			 1966 			 686
599 			 1683 			 184
640 			 1657 			 181
2 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
420 			 263 			 119
447 			 248 			 98
266 			 251 			 79
68 			 169 			 16
82 			 237 			 18
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7291879424
Epoch [64/300] took 172.22191524505615s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6975497278469003, train accuracy: 0.2756840977699873
Val mean loss: 1.704654757569476, val accuracy: 0.2585669781931464

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3107 			 1998 			 828
3570 			 2123 			 915
2289 			 1966 			 705
619 			 1683 			 190
680 			 1657 			 191
4 			 842 			 2
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
411 			 263 			 114
452 			 248 			 99
264 			 251 			 81
70 			 169 			 19
86 			 237 			 19
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7189903360
Epoch [65/300] took 171.300151348114s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6963724588679376, train accuracy: 0.2756840977699873
Val mean loss: 1.713744951457512, val accuracy: 0.2531152647975078

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3153 			 1998 			 831
3540 			 2123 			 917
2272 			 1966 			 700
620 			 1683 			 191
680 			 1657 			 189
4 			 842 			 3
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
419 			 263 			 116
448 			 248 			 95
264 			 251 			 79
67 			 169 			 17
85 			 237 			 18
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7201692672
Epoch [66/300] took 172.55136251449585s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6964420165599692, train accuracy: 0.2761710000973805
Val mean loss: 1.7125331163406372, val accuracy: 0.25934579439252337

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3217 			 1998 			 851
3482 			 2123 			 905
2248 			 1966 			 699
632 			 1683 			 185
684 			 1657 			 193
6 			 842 			 3
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
418 			 263 			 117
439 			 248 			 96
266 			 251 			 82
73 			 169 			 20
87 			 237 			 18
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7216118784
Epoch [67/300] took 172.6272327899933s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6960364231068026, train accuracy: 0.27957931638913236
Val mean loss: 1.7079356792496472, val accuracy: 0.2570093457943925

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3220 			 1998 			 851
3326 			 2123 			 881
2381 			 1966 			 733
625 			 1683 			 199
713 			 1657 			 205
4 			 842 			 2
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
424 			 263 			 119
422 			 248 			 91
268 			 251 			 79
78 			 169 			 19
92 			 237 			 22
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7208664064
Epoch [68/300] took 172.98815870285034s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6955869851454024, train accuracy: 0.2806505015093972
Val mean loss: 1.70585245911668, val accuracy: 0.2585669781931464

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3256 			 1998 			 874
3337 			 2123 			 880
2316 			 1966 			 717
634 			 1683 			 202
719 			 1657 			 205
7 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
431 			 263 			 118
426 			 248 			 94
273 			 251 			 82
69 			 169 			 19
85 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7219559424
Epoch [69/300] took 172.86557579040527s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6947164164153958, train accuracy: 0.28045574057843997
Val mean loss: 1.7018658300725424, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3316 			 1998 			 887
3281 			 2123 			 867
2312 			 1966 			 714
635 			 1683 			 204
721 			 1657 			 207
4 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
427 			 263 			 119
417 			 248 			 89
276 			 251 			 83
71 			 169 			 17
92 			 237 			 21
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7216872448
Epoch [70/300] took 172.45855045318604s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6935277000023197, train accuracy: 0.2794819359236537
Val mean loss: 1.7122830123436161, val accuracy: 0.2507788161993769

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3330 			 1998 			 893
3312 			 2123 			 867
2332 			 1966 			 727
619 			 1683 			 187
670 			 1657 			 192
6 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
436 			 263 			 119
415 			 248 			 87
271 			 251 			 80
75 			 169 			 17
87 			 237 			 19
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7198718976
Epoch [71/300] took 171.89316630363464s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6929111814944544, train accuracy: 0.27957931638913236
Val mean loss: 1.7086653651260748, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3300 			 1998 			 869
3290 			 2123 			 869
2336 			 1966 			 726
602 			 1683 			 189
735 			 1657 			 214
6 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
435 			 263 			 123
414 			 248 			 89
271 			 251 			 81
74 			 169 			 21
89 			 237 			 23
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7220214784
Epoch [72/300] took 172.91294288635254s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6931223018889858, train accuracy: 0.28191644756061934
Val mean loss: 1.708045622197593, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3429 			 1998 			 917
3159 			 2123 			 844
2344 			 1966 			 728
640 			 1683 			 204
692 			 1657 			 200
5 			 842 			 2
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
429 			 263 			 120
412 			 248 			 86
275 			 251 			 83
71 			 169 			 17
96 			 237 			 23
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7188723712
Epoch [73/300] took 172.33970737457275s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6918331258393522, train accuracy: 0.28123478430226895
Val mean loss: 1.7065181790328607, val accuracy: 0.2546728971962617

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3409 			 1998 			 910
3187 			 2123 			 853
2354 			 1966 			 721
623 			 1683 			 200
688 			 1657 			 199
8 			 842 			 5
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
436 			 263 			 122
407 			 248 			 84
271 			 251 			 81
75 			 169 			 18
94 			 237 			 22
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7211424768
Epoch [74/300] took 171.9053909778595s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6916703962462714, train accuracy: 0.28435095919758496
Val mean loss: 1.713012605178647, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3420 			 1998 			 932
3192 			 2123 			 853
2323 			 1966 			 722
628 			 1683 			 202
699 			 1657 			 207
7 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
447 			 263 			 122
402 			 248 			 85
273 			 251 			 82
71 			 169 			 19
90 			 237 			 21
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7193491456
Epoch [75/300] took 171.880366563797s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.690915574165891, train accuracy: 0.2826954912844483
Val mean loss: 1.703014652903487, val accuracy: 0.2570093457943925

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3562 			 1998 			 948
3087 			 2123 			 835
2294 			 1966 			 709
628 			 1683 			 206
687 			 1657 			 199
11 			 842 			 6
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
451 			 263 			 125
400 			 248 			 86
268 			 251 			 82
75 			 169 			 19
90 			 237 			 18
0 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7154407424
Epoch [76/300] took 173.03720116615295s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.68999098320245, train accuracy: 0.28435095919758496
Val mean loss: 1.7170707627040585, val accuracy: 0.2554517133956386

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3551 			 1998 			 951
3116 			 2123 			 847
2338 			 1966 			 732
607 			 1683 			 198
649 			 1657 			 188
8 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
455 			 263 			 125
391 			 248 			 85
274 			 251 			 82
74 			 169 			 18
89 			 237 			 18
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7205207040
Epoch [77/300] took 172.50470185279846s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.689870201167288, train accuracy: 0.28561690524880706
Val mean loss: 1.70663792912553, val accuracy: 0.2570093457943925

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3592 			 1998 			 960
2935 			 2123 			 807
2372 			 1966 			 744
655 			 1683 			 213
707 			 1657 			 205
8 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
453 			 263 			 125
393 			 248 			 83
278 			 251 			 83
72 			 169 			 19
87 			 237 			 20
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7244873728
Epoch [78/300] took 172.32836747169495s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6889646027318415, train accuracy: 0.2844483396630636
Val mean loss: 1.69644367113346, val accuracy: 0.2554517133956386

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3541 			 1998 			 944
3088 			 2123 			 842
2341 			 1966 			 730
621 			 1683 			 204
668 			 1657 			 195
10 			 842 			 6
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
445 			 263 			 121
394 			 248 			 86
276 			 251 			 82
75 			 169 			 17
92 			 237 			 22
2 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7161042944
Epoch [79/300] took 171.75075149536133s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6888035075315433, train accuracy: 0.28347453500827735
Val mean loss: 1.6958971575992863, val accuracy: 0.25778816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3515 			 1998 			 938
3133 			 2123 			 842
2300 			 1966 			 716
611 			 1683 			 201
702 			 1657 			 209
8 			 842 			 5
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
438 			 263 			 119
395 			 248 			 85
270 			 251 			 85
82 			 169 			 20
97 			 237 			 22
2 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7208426496
Epoch [80/300] took 171.93461990356445s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.688227483788012, train accuracy: 0.28668809036907195
Val mean loss: 1.7022231875396356, val accuracy: 0.2546728971962617

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3591 			 1998 			 962
2992 			 2123 			 823
2328 			 1966 			 730
646 			 1683 			 214
700 			 1657 			 209
12 			 842 			 6
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
444 			 263 			 122
396 			 248 			 85
268 			 251 			 79
79 			 169 			 18
95 			 237 			 22
2 			 116 			 1
Max memory allocated: 14211944448; Memory allocated: 7198309376
Epoch [81/300] took 172.6552379131317s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6880345095726559, train accuracy: 0.2855195247833285
Val mean loss: 1.7112912899110375, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3592 			 1998 			 955
2934 			 2123 			 807
2323 			 1966 			 726
661 			 1683 			 223
747 			 1657 			 215
12 			 842 			 6
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
452 			 263 			 125
389 			 248 			 84
272 			 251 			 82
77 			 169 			 19
91 			 237 			 23
3 			 116 			 1
Max memory allocated: 14211944448; Memory allocated: 7201946624
Epoch [82/300] took 172.39146733283997s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6871410645428477, train accuracy: 0.2852273833868926
Val mean loss: 1.7025802775127132, val accuracy: 0.25778816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3637 			 1998 			 969
2923 			 2123 			 806
2345 			 1966 			 731
644 			 1683 			 213
706 			 1657 			 202
14 			 842 			 8
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
453 			 263 			 126
387 			 248 			 86
269 			 251 			 79
82 			 169 			 21
92 			 237 			 19
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7216577536
Epoch [83/300] took 172.53210306167603s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.686567781870239, train accuracy: 0.2840588178011491
Val mean loss: 1.700043311933192, val accuracy: 0.25934579439252337

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3586 			 1998 			 956
2966 			 2123 			 806
2342 			 1966 			 732
653 			 1683 			 213
712 			 1657 			 205
10 			 842 			 5
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
451 			 263 			 126
381 			 248 			 84
275 			 251 			 82
81 			 169 			 19
93 			 237 			 20
3 			 116 			 2
Max memory allocated: 14211944448; Memory allocated: 7224523776
Epoch [84/300] took 172.1055212020874s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6854556962337077, train accuracy: 0.28698023176550785
Val mean loss: 1.6971043290161505, val accuracy: 0.2570093457943925

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3648 			 1998 			 973
2922 			 2123 			 807
2284 			 1966 			 723
682 			 1683 			 227
719 			 1657 			 210
14 			 842 			 7
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
457 			 263 			 126
380 			 248 			 82
271 			 251 			 81
84 			 169 			 20
91 			 237 			 21
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7236099072
Epoch [85/300] took 172.8600218296051s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6860460236065113, train accuracy: 0.2875645145583796
Val mean loss: 1.6991755729768334, val accuracy: 0.2515576323987539

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3599 			 1998 			 965
2925 			 2123 			 811
2350 			 1966 			 738
644 			 1683 			 215
735 			 1657 			 215
16 			 842 			 9
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
464 			 263 			 127
382 			 248 			 81
264 			 251 			 77
85 			 169 			 19
88 			 237 			 19
1 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7213865984
Epoch [86/300] took 172.09593605995178s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6856292460195001, train accuracy: 0.2892199824715162
Val mean loss: 1.7030763684249506, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3633 			 1998 			 978
2964 			 2123 			 824
2291 			 1966 			 724
658 			 1683 			 227
706 			 1657 			 209
17 			 842 			 8
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
454 			 263 			 127
382 			 248 			 83
273 			 251 			 87
83 			 169 			 21
90 			 237 			 18
2 			 116 			 1
Max memory allocated: 14211944448; Memory allocated: 7211564032
Epoch [87/300] took 172.69031238555908s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.684307162635423, train accuracy: 0.2872723731619437
Val mean loss: 1.7009474068153194, val accuracy: 0.25934579439252337

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3675 			 1998 			 988
2918 			 2123 			 806
2250 			 1966 			 702
669 			 1683 			 226
740 			 1657 			 218
17 			 842 			 10
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 129
370 			 248 			 79
268 			 251 			 80
84 			 169 			 20
93 			 237 			 24
2 			 116 			 1
Max memory allocated: 14211944448; Memory allocated: 7248093184
Epoch [88/300] took 172.19612908363342s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6838302159235115, train accuracy: 0.289025221540559
Val mean loss: 1.6980136284014073, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3691 			 1998 			 999
2836 			 2123 			 798
2343 			 1966 			 731
660 			 1683 			 218
723 			 1657 			 215
16 			 842 			 7
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
456 			 263 			 126
379 			 248 			 82
274 			 251 			 83
81 			 169 			 20
92 			 237 			 22
2 			 116 			 1
Max memory allocated: 14211944448; Memory allocated: 7212694528
Epoch [89/300] took 171.86809062957764s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6833152919543495, train accuracy: 0.2883435582822086
Val mean loss: 1.6917173978759021, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3681 			 1998 			 989
2889 			 2123 			 813
2262 			 1966 			 707
691 			 1683 			 230
729 			 1657 			 214
17 			 842 			 8
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
463 			 263 			 127
364 			 248 			 79
278 			 251 			 82
81 			 169 			 19
96 			 237 			 22
2 			 116 			 0
Max memory allocated: 14211944448; Memory allocated: 7277985792
Epoch [90/300] took 173.0338773727417s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6834030106802966, train accuracy: 0.28912260200603757
Val mean loss: 1.6977739479483627, val accuracy: 0.2546728971962617

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3678 			 1998 			 995
2783 			 2123 			 780
2382 			 1966 			 742
665 			 1683 			 220
743 			 1657 			 222
18 			 842 			 10
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
469 			 263 			 126
355 			 248 			 78
282 			 251 			 83
86 			 169 			 20
90 			 237 			 20
2 			 116 			 0
Max memory allocated: 14219099136; Memory allocated: 7250812928
Epoch [91/300] took 172.5020318031311s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6823765050585024, train accuracy: 0.2907780699191742
Val mean loss: 1.6969064125200597, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3690 			 1998 			 1003
2850 			 2123 			 799
2321 			 1966 			 731
661 			 1683 			 220
725 			 1657 			 219
22 			 842 			 14
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 263 			 127
364 			 248 			 83
274 			 251 			 81
86 			 169 			 21
94 			 237 			 22
4 			 116 			 3
Max memory allocated: 14219099136; Memory allocated: 7228472320
Epoch [92/300] took 172.7893705368042s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6823393344136413, train accuracy: 0.2897068847989093
Val mean loss: 1.694773554801941, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3708 			 1998 			 994
2808 			 2123 			 793
2339 			 1966 			 733
668 			 1683 			 223
725 			 1657 			 219
21 			 842 			 13
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
458 			 263 			 125
372 			 248 			 84
273 			 251 			 84
85 			 169 			 24
94 			 237 			 22
2 			 116 			 0
Max memory allocated: 14219099136; Memory allocated: 7191140352
Epoch [93/300] took 171.8237109184265s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6817287511171952, train accuracy: 0.289025221540559
Val mean loss: 1.6983530579543695, val accuracy: 0.2585669781931464

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3770 			 1998 			 1015
2786 			 2123 			 783
2338 			 1966 			 727
632 			 1683 			 218
729 			 1657 			 218
14 			 842 			 7
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
452 			 263 			 125
367 			 248 			 82
282 			 251 			 84
84 			 169 			 20
97 			 237 			 20
2 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7230282752
Epoch [94/300] took 172.59755635261536s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.681078585508828, train accuracy: 0.29107021131561006
Val mean loss: 1.692317700967556, val accuracy: 0.2554517133956386

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3752 			 1998 			 1017
2725 			 2123 			 772
2378 			 1966 			 748
666 			 1683 			 226
725 			 1657 			 211
23 			 842 			 15
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 129
362 			 248 			 80
276 			 251 			 78
87 			 169 			 20
87 			 237 			 20
1 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7207943168
Epoch [95/300] took 172.20781135559082s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6806198674198995, train accuracy: 0.28863569967864444
Val mean loss: 1.6972368664857818, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3813 			 1998 			 1007
2728 			 2123 			 773
2336 			 1966 			 732
679 			 1683 			 226
693 			 1657 			 213
20 			 842 			 13
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 129
359 			 248 			 79
277 			 251 			 82
83 			 169 			 20
97 			 237 			 24
1 			 116 			 0
Max memory allocated: 14219099136; Memory allocated: 7186790400
Epoch [96/300] took 172.25350213050842s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6804888099896202, train accuracy: 0.29058330898821694
Val mean loss: 1.7003080903030023, val accuracy: 0.2538940809968847

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3734 			 1998 			 1010
2729 			 2123 			 775
2334 			 1966 			 732
689 			 1683 			 226
761 			 1657 			 228
22 			 842 			 13
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 130
354 			 248 			 80
269 			 251 			 73
93 			 169 			 21
90 			 237 			 21
3 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7221033984
Epoch [97/300] took 172.2171652317047s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6800808330933996, train accuracy: 0.2894147434024735
Val mean loss: 1.6913845510017582, val accuracy: 0.26479750778816197

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3748 			 1998 			 999
2671 			 2123 			 754
2377 			 1966 			 745
667 			 1683 			 227
785 			 1657 			 235
21 			 842 			 12
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 129
359 			 248 			 80
279 			 251 			 85
85 			 169 			 20
91 			 237 			 24
3 			 116 			 2
Max memory allocated: 14219099136; Memory allocated: 7205272576
Epoch [98/300] took 172.38021397590637s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6787074477501747, train accuracy: 0.2927256792287467
Val mean loss: 1.6982930898666382, val accuracy: 0.25934579439252337

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3789 			 1998 			 1028
2718 			 2123 			 775
2350 			 1966 			 739
663 			 1683 			 229
723 			 1657 			 222
26 			 842 			 13
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 129
350 			 248 			 75
276 			 251 			 83
89 			 169 			 22
93 			 237 			 23
2 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7217560576
Epoch [99/300] took 172.1367609500885s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6790786079157178, train accuracy: 0.28931736293699484
Val mean loss: 1.6924448216833718, val accuracy: 0.26791277258566976

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3785 			 1998 			 1019
2711 			 2123 			 757
2306 			 1966 			 722
686 			 1683 			 230
755 			 1657 			 232
26 			 842 			 11
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 135
353 			 248 			 81
285 			 251 			 83
81 			 169 			 20
92 			 237 			 24
3 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7197236224
Epoch [100/300] took 172.35304260253906s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6787339842579447, train accuracy: 0.2922387769013536
Val mean loss: 1.700163541770563, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3772 			 1998 			 1018
2754 			 2123 			 785
2324 			 1966 			 732
684 			 1683 			 234
709 			 1657 			 215
26 			 842 			 17
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 133
351 			 248 			 78
270 			 251 			 80
91 			 169 			 21
94 			 237 			 24
2 			 116 			 0
Max memory allocated: 14219099136; Memory allocated: 7255031808
Epoch [101/300] took 172.09373688697815s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6781456099121, train accuracy: 0.29194663550491773
Val mean loss: 1.6991318813184413, val accuracy: 0.26791277258566976

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3821 			 1998 			 1023
2683 			 2123 			 769
2337 			 1966 			 740
670 			 1683 			 234
729 			 1657 			 215
29 			 842 			 17
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 132
347 			 248 			 81
280 			 251 			 84
86 			 169 			 22
95 			 237 			 23
3 			 116 			 2
Max memory allocated: 14219099136; Memory allocated: 7221361664
Epoch [102/300] took 171.96559262275696s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6773341047429593, train accuracy: 0.29126497224656733
Val mean loss: 1.6916341287333791, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 1998 			 1039
2652 			 2123 			 754
2286 			 1966 			 720
694 			 1683 			 234
742 			 1657 			 224
33 			 842 			 20
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 263 			 127
348 			 248 			 77
275 			 251 			 81
88 			 169 			 21
92 			 237 			 22
2 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7228955648
Epoch [103/300] took 172.43386840820312s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.677266391266915, train accuracy: 0.29243353783231085
Val mean loss: 1.703212493803443, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3873 			 1998 			 1038
2621 			 2123 			 751
2344 			 1966 			 737
662 			 1683 			 229
743 			 1657 			 232
26 			 842 			 16
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 128
340 			 248 			 72
277 			 251 			 83
92 			 169 			 24
91 			 237 			 21
2 			 116 			 1
Max memory allocated: 14219099136; Memory allocated: 7197407232
Epoch [104/300] took 172.43179845809937s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6777735034996104, train accuracy: 0.2892199824715162
Val mean loss: 1.6889806055441134, val accuracy: 0.26635514018691586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3871 			 1998 			 1025
2607 			 2123 			 742
2325 			 1966 			 739
713 			 1683 			 231
725 			 1657 			 220
28 			 842 			 13
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
465 			 263 			 130
343 			 248 			 79
285 			 251 			 84
90 			 169 			 23
98 			 237 			 24
3 			 116 			 2
Max memory allocated: 14219099136; Memory allocated: 7197145088
Epoch [105/300] took 171.9262125492096s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6765304261650251, train accuracy: 0.2896095043334307
Val mean loss: 1.6931319556585172, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3829 			 1998 			 1023
2613 			 2123 			 742
2340 			 1966 			 735
701 			 1683 			 232
758 			 1657 			 227
28 			 842 			 15
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 131
337 			 248 			 77
280 			 251 			 84
89 			 169 			 21
98 			 237 			 23
3 			 116 			 1
Max memory allocated: 14709633024; Memory allocated: 7227587584
Epoch [106/300] took 171.57928895950317s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6756340358116173, train accuracy: 0.2914597331775246
Val mean loss: 1.6919998308507407, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3808 			 1998 			 1024
2575 			 2123 			 733
2351 			 1966 			 742
710 			 1683 			 238
787 			 1657 			 235
38 			 842 			 21
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 135
328 			 248 			 76
291 			 251 			 85
87 			 169 			 21
90 			 237 			 22
4 			 116 			 0
Max memory allocated: 14709633024; Memory allocated: 7196620800
Epoch [107/300] took 171.59980750083923s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6750477028784352, train accuracy: 0.2949654299347551
Val mean loss: 1.6914641566392852, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 1998 			 1042
2572 			 2123 			 738
2386 			 1966 			 757
691 			 1683 			 238
770 			 1657 			 237
30 			 842 			 17
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 263 			 130
336 			 248 			 76
283 			 251 			 84
86 			 169 			 20
97 			 237 			 24
3 			 116 			 2
Max memory allocated: 14709633024; Memory allocated: 7191312384
Epoch [108/300] took 172.55237436294556s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6753233708325206, train accuracy: 0.29369948388353295
Val mean loss: 1.6897517704382174, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3868 			 1998 			 1046
2580 			 2123 			 741
2337 			 1966 			 748
698 			 1683 			 239
751 			 1657 			 225
35 			 842 			 17
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 130
333 			 248 			 76
279 			 251 			 81
93 			 169 			 24
101 			 237 			 23
5 			 116 			 2
Max memory allocated: 14709633024; Memory allocated: 7199489024
Epoch [109/300] took 172.4838252067566s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6749236728543433, train accuracy: 0.294478527607362
Val mean loss: 1.6957694757275465, val accuracy: 0.25934579439252337

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3794 			 1998 			 1030
2545 			 2123 			 733
2377 			 1966 			 751
698 			 1683 			 239
819 			 1657 			 251
36 			 842 			 20
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 131
337 			 248 			 76
279 			 251 			 82
85 			 169 			 19
102 			 237 			 23
6 			 116 			 2
Max memory allocated: 14709633024; Memory allocated: 7192033280
Epoch [110/300] took 172.21355986595154s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6740800068014507, train accuracy: 0.29330996202161846
Val mean loss: 1.6885889972128518, val accuracy: 0.26557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3814 			 1998 			 1037
2585 			 2123 			 743
2352 			 1966 			 742
724 			 1683 			 243
761 			 1657 			 226
33 			 842 			 21
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
466 			 263 			 132
349 			 248 			 79
278 			 251 			 83
90 			 169 			 22
96 			 237 			 22
5 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7193098240
Epoch [111/300] took 172.53675842285156s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.673991557222289, train accuracy: 0.2951601908657123
Val mean loss: 1.6898488620432413, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3854 			 1998 			 1039
2576 			 2123 			 749
2349 			 1966 			 754
700 			 1683 			 239
753 			 1657 			 230
37 			 842 			 20
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 131
342 			 248 			 80
270 			 251 			 81
91 			 169 			 22
97 			 237 			 22
7 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7209319424
Epoch [112/300] took 172.00400400161743s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6732005166858899, train accuracy: 0.2949654299347551
Val mean loss: 1.6842421613088467, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3764 			 1998 			 1023
2604 			 2123 			 753
2354 			 1966 			 743
722 			 1683 			 248
779 			 1657 			 236
46 			 842 			 26
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 131
335 			 248 			 75
274 			 251 			 86
92 			 169 			 24
104 			 237 			 27
5 			 116 			 2
Max memory allocated: 14709633024; Memory allocated: 7157725184
Epoch [113/300] took 171.84795022010803s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6720499394467314, train accuracy: 0.29545233226214823
Val mean loss: 1.6925391511219303, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3898 			 1998 			 1047
2511 			 2123 			 735
2339 			 1966 			 744
713 			 1683 			 244
764 			 1657 			 241
44 			 842 			 23
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 130
336 			 248 			 74
270 			 251 			 79
99 			 169 			 24
102 			 237 			 25
5 			 116 			 2
Max memory allocated: 14709633024; Memory allocated: 7213693952
Epoch [114/300] took 171.93213748931885s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6729425247584548, train accuracy: 0.292920440159704
Val mean loss: 1.697993170924303, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3856 			 1998 			 1038
2634 			 2123 			 761
2256 			 1966 			 719
752 			 1683 			 246
725 			 1657 			 218
46 			 842 			 26
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 136
331 			 248 			 75
268 			 251 			 82
99 			 169 			 22
95 			 237 			 20
6 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7186069504
Epoch [115/300] took 172.32772278785706s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6713031716064501, train accuracy: 0.2984711266919856
Val mean loss: 1.6895740206648664, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3857 			 1998 			 1053
2533 			 2123 			 739
2321 			 1966 			 753
724 			 1683 			 246
787 			 1657 			 246
47 			 842 			 28
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 130
336 			 248 			 77
270 			 251 			 79
98 			 169 			 23
95 			 237 			 23
9 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7229029376
Epoch [116/300] took 171.71192598342896s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6725949594907672, train accuracy: 0.2958418541240627
Val mean loss: 1.6900525383832978, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3906 			 1998 			 1056
2483 			 2123 			 724
2357 			 1966 			 756
712 			 1683 			 249
773 			 1657 			 232
38 			 842 			 21
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 130
334 			 248 			 79
279 			 251 			 82
93 			 169 			 20
98 			 237 			 24
4 			 116 			 1
Max memory allocated: 14709633024; Memory allocated: 7268089856
Epoch [117/300] took 172.27798795700073s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6722734925160156, train accuracy: 0.29486804946927647
Val mean loss: 1.6849121000708602, val accuracy: 0.26635514018691586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3867 			 1998 			 1040
2528 			 2123 			 729
2311 			 1966 			 747
742 			 1683 			 248
771 			 1657 			 237
50 			 842 			 27
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 134
324 			 248 			 73
275 			 251 			 83
96 			 169 			 24
97 			 237 			 25
7 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7198391296
Epoch [118/300] took 172.155415058136s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6708704441135918, train accuracy: 0.2951601908657123
Val mean loss: 1.685582300511802, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3852 			 1998 			 1045
2577 			 2123 			 748
2238 			 1966 			 712
761 			 1683 			 256
800 			 1657 			 248
41 			 842 			 22
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 132
328 			 248 			 76
268 			 251 			 79
98 			 169 			 24
102 			 237 			 23
6 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7210294272
Epoch [119/300] took 172.2433886528015s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6705656549269536, train accuracy: 0.2966208978478917
Val mean loss: 1.6910925318555134, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3872 			 1998 			 1055
2456 			 2123 			 715
2315 			 1966 			 740
777 			 1683 			 259
800 			 1657 			 251
49 			 842 			 26
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
500 			 263 			 139
320 			 248 			 73
272 			 251 			 80
101 			 169 			 23
89 			 237 			 23
2 			 116 			 1
Max memory allocated: 14709633024; Memory allocated: 7209303040
Epoch [120/300] took 172.2431721687317s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6696891413299466, train accuracy: 0.2966208978478917
Val mean loss: 1.6869137170838147, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3906 			 1998 			 1056
2447 			 2123 			 721
2306 			 1966 			 737
769 			 1683 			 257
786 			 1657 			 243
55 			 842 			 32
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 127
332 			 248 			 73
276 			 251 			 81
98 			 169 			 24
97 			 237 			 26
8 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7232412672
Epoch [121/300] took 172.00279021263123s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6697871521625935, train accuracy: 0.2962313759859772
Val mean loss: 1.67931283974066, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3818 			 1998 			 1047
2538 			 2123 			 736
2325 			 1966 			 740
731 			 1683 			 251
805 			 1657 			 240
52 			 842 			 28
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 137
332 			 248 			 76
272 			 251 			 79
91 			 169 			 20
98 			 237 			 23
10 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7189116928
Epoch [122/300] took 172.55033588409424s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6702799641083335, train accuracy: 0.29671827831337033
Val mean loss: 1.69307751481126, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3910 			 1998 			 1064
2477 			 2123 			 717
2285 			 1966 			 738
751 			 1683 			 257
790 			 1657 			 243
56 			 842 			 28
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 130
336 			 248 			 76
275 			 251 			 81
98 			 169 			 24
102 			 237 			 22
6 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7199898624
Epoch [123/300] took 171.9829339981079s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6688461849622638, train accuracy: 0.29720518064076346
Val mean loss: 1.6865114235296481, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3848 			 1998 			 1043
2556 			 2123 			 747
2296 			 1966 			 747
754 			 1683 			 257
763 			 1657 			 229
52 			 842 			 29
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 132
331 			 248 			 77
274 			 251 			 82
94 			 169 			 23
99 			 237 			 21
10 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7257997312
Epoch [124/300] took 172.45246291160583s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6690731108002945, train accuracy: 0.2993475508812932
Val mean loss: 1.6855027646553227, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3892 			 1998 			 1062
2471 			 2123 			 731
2340 			 1966 			 756
730 			 1683 			 249
772 			 1657 			 241
64 			 842 			 35
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 141
326 			 248 			 76
270 			 251 			 83
95 			 169 			 24
94 			 237 			 22
8 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7244972032
Epoch [125/300] took 172.12663626670837s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.667882761108541, train accuracy: 0.2973999415717207
Val mean loss: 1.6980561657649715, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3907 			 1998 			 1050
2489 			 2123 			 739
2312 			 1966 			 749
736 			 1683 			 255
768 			 1657 			 226
57 			 842 			 35
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 128
335 			 248 			 79
276 			 251 			 82
93 			 169 			 20
105 			 237 			 25
8 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7186872320
Epoch [126/300] took 172.1810564994812s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6684233674379152, train accuracy: 0.29915278995033595
Val mean loss: 1.6863269544229276, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3892 			 1998 			 1063
2463 			 2123 			 723
2307 			 1966 			 750
761 			 1683 			 261
784 			 1657 			 241
62 			 842 			 34
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 263 			 132
327 			 248 			 78
274 			 251 			 80
101 			 169 			 24
89 			 237 			 20
10 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7211613184
Epoch [127/300] took 171.98657298088074s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6673813913470117, train accuracy: 0.29954231181225044
Val mean loss: 1.6911832646625797, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3892 			 1998 			 1061
2456 			 2123 			 717
2308 			 1966 			 750
756 			 1683 			 255
789 			 1657 			 254
68 			 842 			 39
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 130
334 			 248 			 75
272 			 251 			 79
97 			 169 			 23
99 			 237 			 23
9 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7199620096
Epoch [128/300] took 171.892906665802s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6675063252820403, train accuracy: 0.29808160483007107
Val mean loss: 1.6913022093656587, val accuracy: 0.25934579439252337

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3861 			 1998 			 1046
2428 			 2123 			 713
2328 			 1966 			 760
764 			 1683 			 259
831 			 1657 			 255
57 			 842 			 28
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 263 			 133
313 			 248 			 73
273 			 251 			 80
97 			 169 			 22
101 			 237 			 24
6 			 116 			 1
Max memory allocated: 14709633024; Memory allocated: 7240924160
Epoch [129/300] took 172.0692138671875s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6660603177138948, train accuracy: 0.29564709319310545
Val mean loss: 1.6886396786061728, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3870 			 1998 			 1036
2455 			 2123 			 721
2336 			 1966 			 758
765 			 1683 			 258
780 			 1657 			 234
63 			 842 			 29
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 135
324 			 248 			 75
271 			 251 			 80
99 			 169 			 23
95 			 237 			 23
4 			 116 			 1
Max memory allocated: 14709633024; Memory allocated: 7228800000
Epoch [130/300] took 172.37904930114746s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.666591730444602, train accuracy: 0.30002921413964356
Val mean loss: 1.6892915091863492, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3915 			 1998 			 1059
2413 			 2123 			 717
2323 			 1966 			 764
749 			 1683 			 254
805 			 1657 			 254
64 			 842 			 33
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 130
325 			 248 			 76
272 			 251 			 79
101 			 169 			 24
101 			 237 			 24
9 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7229406208
Epoch [131/300] took 172.66019749641418s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6664186890622907, train accuracy: 0.2992501704158146
Val mean loss: 1.700847212861224, val accuracy: 0.26479750778816197

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3909 			 1998 			 1048
2473 			 2123 			 731
2271 			 1966 			 741
772 			 1683 			 270
782 			 1657 			 249
62 			 842 			 34
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 135
323 			 248 			 77
268 			 251 			 78
101 			 169 			 24
100 			 237 			 24
6 			 116 			 2
Max memory allocated: 14709633024; Memory allocated: 7197079552
Epoch [132/300] took 171.89003157615662s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6659625100198192, train accuracy: 0.30032135553607947
Val mean loss: 1.6810202365968285, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3854 			 1998 			 1058
2439 			 2123 			 720
2289 			 1966 			 735
789 			 1683 			 273
832 			 1657 			 262
66 			 842 			 36
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 263 			 131
321 			 248 			 74
270 			 251 			 78
98 			 169 			 23
108 			 237 			 24
8 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7210580992
Epoch [133/300] took 171.74451065063477s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6655961668751322, train accuracy: 0.2993475508812932
Val mean loss: 1.685937811688679, val accuracy: 0.26791277258566976

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3867 			 1998 			 1053
2500 			 2123 			 744
2245 			 1966 			 732
795 			 1683 			 268
800 			 1657 			 243
62 			 842 			 34
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 135
323 			 248 			 74
266 			 251 			 78
104 			 169 			 25
99 			 237 			 26
12 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7200267264
Epoch [134/300] took 171.67991185188293s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6653929978516242, train accuracy: 0.29983445320868635
Val mean loss: 1.6887337201979102, val accuracy: 0.26635514018691586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 1998 			 1054
2415 			 2123 			 705
2291 			 1966 			 746
790 			 1683 			 269
844 			 1657 			 268
67 			 842 			 37
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 133
320 			 248 			 75
269 			 251 			 80
114 			 169 			 27
98 			 237 			 22
12 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7202446336
Epoch [135/300] took 171.84748125076294s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6640228278169007, train accuracy: 0.29954231181225044
Val mean loss: 1.6841971321803768, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3848 			 1998 			 1042
2450 			 2123 			 717
2268 			 1966 			 741
820 			 1683 			 276
811 			 1657 			 262
72 			 842 			 38
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 131
317 			 248 			 74
276 			 251 			 81
99 			 169 			 26
100 			 237 			 21
12 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7191336960
Epoch [136/300] took 172.30978226661682s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6647606486472013, train accuracy: 0.30032135553607947
Val mean loss: 1.6812856575337851, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3910 			 1998 			 1062
2443 			 2123 			 720
2263 			 1966 			 739
788 			 1683 			 275
790 			 1657 			 252
75 			 842 			 36
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 132
324 			 248 			 73
265 			 251 			 79
102 			 169 			 23
88 			 237 			 24
14 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7221787648
Epoch [137/300] took 171.8231213092804s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6635369511779594, train accuracy: 0.30178206251825884
Val mean loss: 1.6739045759526694, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3902 			 1998 			 1065
2424 			 2123 			 719
2293 			 1966 			 749
781 			 1683 			 275
798 			 1657 			 253
71 			 842 			 38
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
469 			 263 			 130
319 			 248 			 75
277 			 251 			 83
101 			 169 			 23
105 			 237 			 27
13 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7279230976
Epoch [138/300] took 172.42697644233704s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6637846168327926, train accuracy: 0.30090563832895123
Val mean loss: 1.6822433180925322, val accuracy: 0.26713395638629284

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3907 			 1998 			 1065
2438 			 2123 			 726
2254 			 1966 			 735
769 			 1683 			 264
832 			 1657 			 265
69 			 842 			 35
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 263 			 138
317 			 248 			 77
266 			 251 			 78
104 			 169 			 24
92 			 237 			 21
11 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7233633280
Epoch [139/300] took 172.02919363975525s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6634000506356499, train accuracy: 0.30002921413964356
Val mean loss: 1.6872013778221318, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3881 			 1998 			 1060
2495 			 2123 			 732
2266 			 1966 			 740
787 			 1683 			 273
772 			 1657 			 241
68 			 842 			 35
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 126
316 			 248 			 73
274 			 251 			 81
103 			 169 			 24
103 			 237 			 25
13 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7193180160
Epoch [140/300] took 172.08013939857483s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6628716534171892, train accuracy: 0.3011977797253871
Val mean loss: 1.6831301886860917, val accuracy: 0.26635514018691586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3912 			 1998 			 1057
2377 			 2123 			 707
2279 			 1966 			 745
800 			 1683 			 284
821 			 1657 			 261
80 			 842 			 39
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
492 			 263 			 133
315 			 248 			 74
261 			 251 			 78
104 			 169 			 25
101 			 237 			 27
11 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7233158144
Epoch [141/300] took 172.8306667804718s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6628814735145212, train accuracy: 0.3010030187944298
Val mean loss: 1.684166809407676, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3978 			 1998 			 1088
2418 			 2123 			 716
2219 			 1966 			 726
815 			 1683 			 281
762 			 1657 			 239
77 			 842 			 41
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 134
311 			 248 			 76
267 			 251 			 79
100 			 169 			 25
110 			 237 			 27
11 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7227358208
Epoch [142/300] took 173.1376621723175s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6623387292166736, train accuracy: 0.3036322913623527
Val mean loss: 1.6862224195061661, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3886 			 1998 			 1071
2402 			 2123 			 723
2288 			 1966 			 742
799 			 1683 			 273
810 			 1657 			 266
84 			 842 			 43
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 128
308 			 248 			 73
268 			 251 			 80
106 			 169 			 26
104 			 237 			 26
11 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7211400192
Epoch [143/300] took 172.23524737358093s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6618503796348691, train accuracy: 0.3051903788100107
Val mean loss: 1.682924823063176, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3924 			 1998 			 1078
2398 			 2123 			 729
2312 			 1966 			 764
775 			 1683 			 271
786 			 1657 			 251
74 			 842 			 41
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
464 			 263 			 133
323 			 248 			 76
274 			 251 			 80
102 			 169 			 26
107 			 237 			 30
14 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7248584704
Epoch [144/300] took 172.60626792907715s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.661906135045108, train accuracy: 0.30139254065634435
Val mean loss: 1.6882973269718449, val accuracy: 0.2616822429906542

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3892 			 1998 			 1067
2353 			 2123 			 707
2341 			 1966 			 753
788 			 1683 			 273
816 			 1657 			 255
79 			 842 			 40
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 127
310 			 248 			 71
278 			 251 			 81
100 			 169 			 26
106 			 237 			 25
15 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7227096064
Epoch [145/300] took 172.74335932731628s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.661096224903689, train accuracy: 0.3011977797253871
Val mean loss: 1.6842163568589745, val accuracy: 0.26557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3833 			 1998 			 1045
2424 			 2123 			 720
2227 			 1966 			 727
857 			 1683 			 298
837 			 1657 			 258
91 			 842 			 45
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 127
323 			 248 			 77
270 			 251 			 82
102 			 169 			 24
102 			 237 			 24
15 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7252656128
Epoch [146/300] took 172.55651688575745s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6607418349970167, train accuracy: 0.3019768234492161
Val mean loss: 1.6807961289475604, val accuracy: 0.26246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3849 			 1998 			 1049
2447 			 2123 			 722
2207 			 1966 			 723
851 			 1683 			 294
829 			 1657 			 265
86 			 842 			 48
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 128
327 			 248 			 76
271 			 251 			 79
100 			 169 			 24
102 			 237 			 23
12 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7221689344
Epoch [147/300] took 172.79029822349548s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.66043656414543, train accuracy: 0.30226896484565197
Val mean loss: 1.6805723905563354, val accuracy: 0.2554517133956386

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3977 			 1998 			 1083
2364 			 2123 			 704
2264 			 1966 			 743
799 			 1683 			 280
781 			 1657 			 249
84 			 842 			 45
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 123
319 			 248 			 73
271 			 251 			 78
101 			 169 			 23
108 			 237 			 27
10 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7225842688
Epoch [148/300] took 172.13620162010193s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6603803942879412, train accuracy: 0.30372967182783134
Val mean loss: 1.687125639217656, val accuracy: 0.2702492211838006

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3870 			 1998 			 1057
2415 			 2123 			 724
2286 			 1966 			 746
793 			 1683 			 285
825 			 1657 			 264
80 			 842 			 43
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 136
316 			 248 			 76
262 			 251 			 81
111 			 169 			 27
99 			 237 			 24
9 			 116 			 3
Max memory allocated: 14709633024; Memory allocated: 7207369728
Epoch [149/300] took 172.53977990150452s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6595347636956663, train accuracy: 0.30217158438017333
Val mean loss: 1.676259407183019, val accuracy: 0.26947040498442365

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3890 			 1998 			 1066
2430 			 2123 			 719
2240 			 1966 			 736
815 			 1683 			 280
798 			 1657 			 255
96 			 842 			 47
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 263 			 136
315 			 248 			 76
268 			 251 			 79
100 			 169 			 24
105 			 237 			 25
13 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7191967744
Epoch [150/300] took 172.44576358795166s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6594619164214328, train accuracy: 0.3036322913623527
Val mean loss: 1.676835859694132, val accuracy: 0.26557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3851 			 1998 			 1061
2432 			 2123 			 726
2281 			 1966 			 751
797 			 1683 			 277
814 			 1657 			 257
94 			 842 			 46
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 132
322 			 248 			 75
262 			 251 			 77
107 			 169 			 25
98 			 237 			 24
15 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7147771904
Epoch [151/300] took 172.01198983192444s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6587419149660247, train accuracy: 0.3048008569480962
Val mean loss: 1.68472205138788, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3858 			 1998 			 1066
2367 			 2123 			 714
2276 			 1966 			 741
821 			 1683 			 289
848 			 1657 			 271
99 			 842 			 49
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 132
302 			 248 			 70
274 			 251 			 81
107 			 169 			 26
104 			 237 			 24
12 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7227325440
Epoch [152/300] took 172.0679168701172s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.65884536003398, train accuracy: 0.3060668029993183
Val mean loss: 1.7000661565036308, val accuracy: 0.26635514018691586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3902 			 1998 			 1075
2334 			 2123 			 701
2270 			 1966 			 747
811 			 1683 			 289
859 			 1657 			 280
93 			 842 			 51
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
469 			 263 			 124
309 			 248 			 75
267 			 251 			 83
109 			 169 			 28
116 			 237 			 26
14 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7193655296
Epoch [153/300] took 172.44211983680725s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6593633225402358, train accuracy: 0.30353491089687407
Val mean loss: 1.6733625022376455, val accuracy: 0.26479750778816197

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3869 			 1998 			 1068
2311 			 2123 			 692
2287 			 1966 			 745
841 			 1683 			 293
862 			 1657 			 268
99 			 842 			 51
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 132
315 			 248 			 77
260 			 251 			 76
110 			 169 			 26
100 			 237 			 23
12 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7228177408
Epoch [154/300] took 171.6135094165802s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6571262280146282, train accuracy: 0.30840393417080536
Val mean loss: 1.6843289892847946, val accuracy: 0.26401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3923 			 1998 			 1081
2404 			 2123 			 731
2228 			 1966 			 746
834 			 1683 			 298
785 			 1657 			 262
95 			 842 			 49
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 129
318 			 248 			 73
270 			 251 			 81
103 			 169 			 27
107 			 237 			 24
12 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7203511296
Epoch [155/300] took 172.3418037891388s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6571741813439818, train accuracy: 0.3050929983445321
Val mean loss: 1.680716558200557, val accuracy: 0.2601246105919003

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3913 			 1998 			 1082
2362 			 2123 			 717
2262 			 1966 			 736
830 			 1683 			 300
812 			 1657 			 253
90 			 842 			 45
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 127
311 			 248 			 71
267 			 251 			 78
108 			 169 			 25
112 			 237 			 27
13 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7266648064
Epoch [156/300] took 171.81662940979004s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.656515480201935, train accuracy: 0.3058720420683611
Val mean loss: 1.6811022089748848, val accuracy: 0.26713395638629284

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3838 			 1998 			 1064
2403 			 2123 			 722
2285 			 1966 			 748
829 			 1683 			 294
829 			 1657 			 268
85 			 842 			 45
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 263 			 131
308 			 248 			 74
266 			 251 			 81
106 			 169 			 25
102 			 237 			 25
13 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7207083008
Epoch [157/300] took 171.53285479545593s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.656380129751758, train accuracy: 0.3078196513779336
Val mean loss: 1.6829179205545566, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3834 			 1998 			 1070
2406 			 2123 			 725
2260 			 1966 			 742
822 			 1683 			 290
839 			 1657 			 276
108 			 842 			 58
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 128
319 			 248 			 74
268 			 251 			 79
106 			 169 			 25
103 			 237 			 27
11 			 116 			 5
Max memory allocated: 14709633024; Memory allocated: 7288766464
Epoch [158/300] took 171.80849647521973s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.656064063960518, train accuracy: 0.3060668029993183
Val mean loss: 1.6847149686115543, val accuracy: 0.26557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3884 			 1998 			 1065
2339 			 2123 			 708
2267 			 1966 			 758
837 			 1683 			 296
842 			 1657 			 267
100 			 842 			 49
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 263 			 131
304 			 248 			 72
269 			 251 			 82
104 			 169 			 24
101 			 237 			 24
16 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7267106816
Epoch [159/300] took 172.22199010849s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6568399838569379, train accuracy: 0.3080144123088908
Val mean loss: 1.6769857232163592, val accuracy: 0.26713395638629284

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3875 			 1998 			 1076
2389 			 2123 			 731
2231 			 1966 			 737
843 			 1683 			 303
841 			 1657 			 268
90 			 842 			 48
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 132
316 			 248 			 77
262 			 251 			 80
109 			 169 			 27
96 			 237 			 21
10 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7213988864
Epoch [160/300] took 172.19264817237854s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.656142791112264, train accuracy: 0.3073327490505405
Val mean loss: 1.6751088456409733, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3851 			 1998 			 1067
2355 			 2123 			 717
2252 			 1966 			 745
841 			 1683 			 297
873 			 1657 			 283
97 			 842 			 47
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 135
310 			 248 			 75
267 			 251 			 80
110 			 169 			 28
106 			 237 			 25
16 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7248265216
Epoch [161/300] took 171.7268795967102s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6556599080748275, train accuracy: 0.3060668029993183
Val mean loss: 1.6873532824399995, val accuracy: 0.26713395638629284

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3853 			 1998 			 1061
2388 			 2123 			 727
2222 			 1966 			 735
877 			 1683 			 307
830 			 1657 			 269
99 			 842 			 44
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 130
313 			 248 			 75
261 			 251 			 82
113 			 169 			 26
103 			 237 			 23
13 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7194146816
Epoch [162/300] took 172.24016523361206s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6565924611789786, train accuracy: 0.3064563248612328
Val mean loss: 1.6798801625647195, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3907 			 1998 			 1071
2344 			 2123 			 710
2269 			 1966 			 759
823 			 1683 			 296
841 			 1657 			 266
85 			 842 			 45
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 138
298 			 248 			 71
266 			 251 			 81
109 			 169 			 29
112 			 237 			 34
14 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7218469888
Epoch [163/300] took 172.52773642539978s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6553711831755356, train accuracy: 0.3080144123088908
Val mean loss: 1.6763864086895455, val accuracy: 0.26479750778816197

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3940 			 1998 			 1080
2283 			 2123 			 708
2244 			 1966 			 747
837 			 1683 			 300
866 			 1657 			 280
99 			 842 			 48
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 263 			 131
313 			 248 			 72
262 			 251 			 82
106 			 169 			 26
99 			 237 			 22
14 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7215004672
Epoch [164/300] took 172.03270506858826s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.654848561480038, train accuracy: 0.3066510857921901
Val mean loss: 1.6792601230667858, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3864 			 1998 			 1073
2400 			 2123 			 722
2211 			 1966 			 738
853 			 1683 			 302
841 			 1657 			 265
100 			 842 			 49
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 135
310 			 248 			 77
256 			 251 			 77
112 			 169 			 27
108 			 237 			 25
16 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7228275712
Epoch [165/300] took 172.40190410614014s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.655196447981481, train accuracy: 0.30898821696367706
Val mean loss: 1.6866284347162015, val accuracy: 0.26791277258566976

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3890 			 1998 			 1084
2369 			 2123 			 729
2204 			 1966 			 740
869 			 1683 			 311
838 			 1657 			 262
99 			 842 			 47
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 129
317 			 248 			 77
261 			 251 			 80
111 			 169 			 26
104 			 237 			 25
14 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7198128128
Epoch [166/300] took 172.2660505771637s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.654361373167543, train accuracy: 0.3083065537053267
Val mean loss: 1.6771797319737876, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3875 			 1998 			 1073
2385 			 2123 			 726
2215 			 1966 			 737
851 			 1683 			 297
835 			 1657 			 277
108 			 842 			 56
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 131
310 			 248 			 78
263 			 251 			 80
110 			 169 			 27
106 			 237 			 26
18 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7245856768
Epoch [167/300] took 171.97451615333557s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6537058743361002, train accuracy: 0.30791703184341224
Val mean loss: 1.6781349211204342, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3930 			 1998 			 1090
2333 			 2123 			 714
2227 			 1966 			 738
860 			 1683 			 305
819 			 1657 			 268
100 			 842 			 47
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 136
308 			 248 			 71
266 			 251 			 83
113 			 169 			 29
109 			 237 			 30
12 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7355910144
Epoch [168/300] took 172.4544620513916s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6532821417597596, train accuracy: 0.3088908364981985
Val mean loss: 1.672009174416705, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3939 			 1998 			 1088
2329 			 2123 			 713
2176 			 1966 			 736
871 			 1683 			 310
843 			 1657 			 271
111 			 842 			 54
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 136
301 			 248 			 75
264 			 251 			 79
113 			 169 			 29
105 			 237 			 28
16 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7197341696
Epoch [169/300] took 171.76219391822815s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6533205282651005, train accuracy: 0.3114227286006427
Val mean loss: 1.6773122956113118, val accuracy: 0.26791277258566976

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3864 			 1998 			 1070
2338 			 2123 			 720
2235 			 1966 			 751
857 			 1683 			 311
865 			 1657 			 289
110 			 842 			 57
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 263 			 135
303 			 248 			 73
263 			 251 			 78
107 			 169 			 26
98 			 237 			 25
16 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7217642496
Epoch [170/300] took 172.8913118839264s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6529716862324986, train accuracy: 0.30966988022202746
Val mean loss: 1.6832232155450961, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3883 			 1998 			 1082
2287 			 2123 			 703
2276 			 1966 			 751
845 			 1683 			 302
862 			 1657 			 283
116 			 842 			 59
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 263 			 138
300 			 248 			 77
259 			 251 			 78
111 			 169 			 27
106 			 237 			 27
15 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7278706688
Epoch [171/300] took 171.82336282730103s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.652286867857722, train accuracy: 0.30850131463628394
Val mean loss: 1.6739222363727848, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3874 			 1998 			 1075
2337 			 2123 			 714
2240 			 1966 			 749
851 			 1683 			 303
856 			 1657 			 275
111 			 842 			 52
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 132
308 			 248 			 77
273 			 251 			 80
112 			 169 			 26
107 			 237 			 28
17 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7206812672
Epoch [172/300] took 171.6707067489624s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6518100485252072, train accuracy: 0.30879345603271985
Val mean loss: 1.681495808973545, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3855 			 1998 			 1066
2346 			 2123 			 713
2234 			 1966 			 751
870 			 1683 			 306
849 			 1657 			 277
115 			 842 			 58
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 137
307 			 248 			 74
266 			 251 			 80
112 			 169 			 29
101 			 237 			 25
12 			 116 			 4
Max memory allocated: 14709633024; Memory allocated: 7193409536
Epoch [173/300] took 172.02413988113403s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6519167954305252, train accuracy: 0.3074301295160191
Val mean loss: 1.6773475001497966, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3877 			 1998 			 1075
2338 			 2123 			 709
2204 			 1966 			 737
892 			 1683 			 318
848 			 1657 			 268
110 			 842 			 50
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 263 			 141
292 			 248 			 73
264 			 251 			 79
115 			 169 			 29
98 			 237 			 24
18 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7232445440
Epoch [174/300] took 172.03996467590332s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6514585913156052, train accuracy: 0.31005940208394195
Val mean loss: 1.6840776205062866, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3897 			 1998 			 1090
2321 			 2123 			 716
2251 			 1966 			 749
869 			 1683 			 310
825 			 1657 			 267
106 			 842 			 52
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 130
309 			 248 			 77
263 			 251 			 79
109 			 169 			 28
108 			 237 			 26
20 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7193425920
Epoch [175/300] took 172.15348935127258s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.651418174538657, train accuracy: 0.3086960755672412
Val mean loss: 1.683217993596705, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3889 			 1998 			 1067
2335 			 2123 			 720
2235 			 1966 			 746
855 			 1683 			 310
843 			 1657 			 273
112 			 842 			 54
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 135
305 			 248 			 74
260 			 251 			 81
115 			 169 			 29
106 			 237 			 25
18 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7213710336
Epoch [176/300] took 173.11542439460754s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6518699725468953, train accuracy: 0.3099620216184633
Val mean loss: 1.6869944246803843, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3893 			 1998 			 1081
2332 			 2123 			 707
2233 			 1966 			 755
874 			 1683 			 315
818 			 1657 			 266
119 			 842 			 59
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 263 			 141
300 			 248 			 76
261 			 251 			 80
113 			 169 			 30
99 			 237 			 25
16 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7193458688
Epoch [177/300] took 171.81371426582336s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6506543508571256, train accuracy: 0.31113058720420683
Val mean loss: 1.6845247018628005, val accuracy: 0.278816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3821 			 1998 			 1068
2267 			 2123 			 694
2290 			 1966 			 759
899 			 1683 			 321
877 			 1657 			 296
115 			 842 			 57
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 133
303 			 248 			 77
260 			 251 			 78
117 			 169 			 31
111 			 237 			 30
17 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7205501952
Epoch [178/300] took 172.1616027355194s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6504034327569408, train accuracy: 0.3099620216184633
Val mean loss: 1.686073782967358, val accuracy: 0.27102803738317754

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3878 			 1998 			 1084
2341 			 2123 			 714
2207 			 1966 			 736
881 			 1683 			 317
849 			 1657 			 275
113 			 842 			 57
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 263 			 136
304 			 248 			 75
258 			 251 			 78
112 			 169 			 29
107 			 237 			 23
14 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7224245248
Epoch [179/300] took 172.07062196731567s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6500832373479446, train accuracy: 0.3106436848768137
Val mean loss: 1.6694813966751099, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3860 			 1998 			 1074
2344 			 2123 			 721
2220 			 1966 			 744
889 			 1683 			 319
833 			 1657 			 273
123 			 842 			 59
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 263 			 137
299 			 248 			 76
256 			 251 			 79
111 			 169 			 29
110 			 237 			 26
14 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7215299584
Epoch [180/300] took 172.500629901886s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6507399824920845, train accuracy: 0.3078196513779336
Val mean loss: 1.6750081748497196, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3971 			 1998 			 1086
2248 			 2123 			 703
2221 			 1966 			 739
876 			 1683 			 309
831 			 1657 			 268
122 			 842 			 56
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 137
303 			 248 			 73
259 			 251 			 80
115 			 169 			 28
103 			 237 			 26
18 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7193155584
Epoch [181/300] took 172.34545922279358s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6497981399761925, train accuracy: 0.3128834355828221
Val mean loss: 1.6817688476748582, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3891 			 1998 			 1091
2279 			 2123 			 709
2237 			 1966 			 751
890 			 1683 			 317
859 			 1657 			 289
113 			 842 			 56
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 263 			 138
295 			 248 			 75
258 			 251 			 82
114 			 169 			 30
105 			 237 			 27
18 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7221328896
Epoch [182/300] took 171.98990845680237s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6496172931706794, train accuracy: 0.3094751192910702
Val mean loss: 1.6766070534543294, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3879 			 1998 			 1076
2285 			 2123 			 702
2203 			 1966 			 742
915 			 1683 			 325
877 			 1657 			 281
110 			 842 			 52
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 130
306 			 248 			 76
271 			 251 			 83
112 			 169 			 29
105 			 237 			 27
17 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7223639040
Epoch [183/300] took 171.69018840789795s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6489948977562496, train accuracy: 0.310838445807771
Val mean loss: 1.6748405113452818, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3859 			 1998 			 1070
2274 			 2123 			 709
2244 			 1966 			 750
900 			 1683 			 322
862 			 1657 			 280
130 			 842 			 61
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 131
306 			 248 			 74
263 			 251 			 82
116 			 169 			 30
108 			 237 			 25
17 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7255711744
Epoch [184/300] took 172.3182692527771s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6484677089708988, train accuracy: 0.31385724023760836
Val mean loss: 1.678202038857995, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3828 			 1998 			 1079
2328 			 2123 			 727
2275 			 1966 			 760
861 			 1683 			 314
849 			 1657 			 278
128 			 842 			 65
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 134
293 			 248 			 74
261 			 251 			 80
118 			 169 			 29
111 			 237 			 24
16 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7257505792
Epoch [185/300] took 173.07645297050476s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.649043316410338, train accuracy: 0.3121043918589931
Val mean loss: 1.6694534493655693, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3843 			 1998 			 1082
2284 			 2123 			 703
2223 			 1966 			 748
913 			 1683 			 330
881 			 1657 			 284
125 			 842 			 58
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 134
297 			 248 			 73
255 			 251 			 82
115 			 169 			 30
109 			 237 			 27
17 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7278804992
Epoch [186/300] took 172.92294549942017s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6483912156007001, train accuracy: 0.31093582627324956
Val mean loss: 1.681159909178571, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3838 			 1998 			 1067
2253 			 2123 			 694
2246 			 1966 			 754
911 			 1683 			 327
895 			 1657 			 292
126 			 842 			 59
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 135
303 			 248 			 73
256 			 251 			 80
116 			 169 			 31
103 			 237 			 29
20 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7213046784
Epoch [187/300] took 172.69066882133484s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6478908143682272, train accuracy: 0.3113253481351641
Val mean loss: 1.6763797765824853, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3937 			 1998 			 1087
2269 			 2123 			 711
2224 			 1966 			 744
867 			 1683 			 309
855 			 1657 			 287
117 			 842 			 59
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 263 			 136
298 			 248 			 74
260 			 251 			 82
111 			 169 			 29
92 			 237 			 24
19 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7305544704
Epoch [188/300] took 172.5256152153015s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6477082024482181, train accuracy: 0.3113253481351641
Val mean loss: 1.6766168809518582, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3900 			 1998 			 1083
2289 			 2123 			 708
2208 			 1966 			 744
914 			 1683 			 329
828 			 1657 			 270
130 			 842 			 63
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 131
306 			 248 			 76
265 			 251 			 82
112 			 169 			 28
107 			 237 			 27
19 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7197547520
Epoch [189/300] took 172.3216633796692s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6474881376432853, train accuracy: 0.31249391372090757
Val mean loss: 1.6843726809431867, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3889 			 1998 			 1083
2321 			 2123 			 721
2175 			 1966 			 743
891 			 1683 			 321
859 			 1657 			 271
134 			 842 			 70
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
488 			 263 			 139
294 			 248 			 75
260 			 251 			 81
121 			 169 			 30
103 			 237 			 26
18 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7151089664
Epoch [190/300] took 173.11091661453247s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6471945816111342, train accuracy: 0.3128834355828221
Val mean loss: 1.6740421405652675, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3912 			 1998 			 1095
2223 			 2123 			 695
2240 			 1966 			 760
898 			 1683 			 320
864 			 1657 			 282
132 			 842 			 61
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 136
288 			 248 			 72
265 			 251 			 82
116 			 169 			 29
107 			 237 			 27
17 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7255162880
Epoch [191/300] took 173.93427276611328s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.646116800397356, train accuracy: 0.31268867465186484
Val mean loss: 1.6955260590809147, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3893 			 1998 			 1095
2287 			 2123 			 702
2210 			 1966 			 740
915 			 1683 			 329
841 			 1657 			 285
123 			 842 			 60
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 263 			 134
296 			 248 			 72
258 			 251 			 82
115 			 169 			 32
107 			 237 			 26
18 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7211793408
Epoch [192/300] took 174.09409999847412s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6465816401246924, train accuracy: 0.3129808160483007
Val mean loss: 1.6877578380631237, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3860 			 1998 			 1087
2299 			 2123 			 702
2187 			 1966 			 736
929 			 1683 			 333
864 			 1657 			 291
130 			 842 			 65
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 263 			 128
300 			 248 			 74
257 			 251 			 79
119 			 169 			 31
108 			 237 			 24
21 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7201479680
Epoch [193/300] took 174.3435046672821s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6462076315627292, train accuracy: 0.3145389034959587
Val mean loss: 1.6876293420791626, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3865 			 1998 			 1081
2285 			 2123 			 713
2216 			 1966 			 758
925 			 1683 			 330
834 			 1657 			 278
144 			 842 			 70
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 141
294 			 248 			 72
254 			 251 			 80
116 			 169 			 31
110 			 237 			 27
19 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7243956224
Epoch [194/300] took 174.01503658294678s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6457506990135644, train accuracy: 0.3160969909436167
Val mean loss: 1.6692729665011894, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3842 			 1998 			 1087
2273 			 2123 			 720
2216 			 1966 			 752
927 			 1683 			 339
866 			 1657 			 276
145 			 842 			 72
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 139
306 			 248 			 79
262 			 251 			 83
117 			 169 			 31
105 			 237 			 30
20 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7201872896
Epoch [195/300] took 174.24106812477112s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6455594007842638, train accuracy: 0.31395462070308694
Val mean loss: 1.6778365926044743, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3850 			 1998 			 1084
2289 			 2123 			 715
2259 			 1966 			 758
888 			 1683 			 325
851 			 1657 			 281
132 			 842 			 61
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 263 			 132
294 			 248 			 73
261 			 251 			 82
122 			 169 			 30
99 			 237 			 25
19 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7193114624
Epoch [196/300] took 174.31523728370667s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6458872155608417, train accuracy: 0.3156100886162236
Val mean loss: 1.6744934291374394, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3857 			 1998 			 1081
2271 			 2123 			 719
2235 			 1966 			 757
909 			 1683 			 331
857 			 1657 			 287
140 			 842 			 66
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 133
295 			 248 			 71
262 			 251 			 83
117 			 169 			 28
110 			 237 			 26
23 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7192901632
Epoch [197/300] took 173.7227907180786s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6451448183564754, train accuracy: 0.3152205667543091
Val mean loss: 1.6807502391861706, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3805 			 1998 			 1066
2275 			 2123 			 714
2270 			 1966 			 769
915 			 1683 			 334
872 			 1657 			 288
132 			 842 			 66
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 263 			 138
285 			 248 			 76
260 			 251 			 81
117 			 169 			 32
102 			 237 			 27
18 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7205108736
Epoch [198/300] took 174.36674904823303s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6444108099952293, train accuracy: 0.3154153276852663
Val mean loss: 1.678826506544904, val accuracy: 0.27102803738317754

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3828 			 1998 			 1076
2303 			 2123 			 720
2229 			 1966 			 751
911 			 1683 			 334
872 			 1657 			 298
126 			 842 			 60
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 134
296 			 248 			 72
259 			 251 			 79
120 			 169 			 30
103 			 237 			 24
19 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7184824320
Epoch [199/300] took 174.3881106376648s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6454506146944943, train accuracy: 0.312396533255429
Val mean loss: 1.687057061893184, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3886 			 1998 			 1082
2360 			 2123 			 730
2177 			 1966 			 733
901 			 1683 			 327
818 			 1657 			 274
127 			 842 			 62
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
466 			 263 			 127
299 			 248 			 75
259 			 251 			 81
119 			 169 			 30
118 			 237 			 29
23 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7225252864
Epoch [200/300] took 174.4908013343811s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6444680066866295, train accuracy: 0.3160969909436167
Val mean loss: 1.6788186009337263, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3896 			 1998 			 1090
2264 			 2123 			 716
2211 			 1966 			 751
912 			 1683 			 335
849 			 1657 			 283
137 			 842 			 71
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
468 			 263 			 126
304 			 248 			 74
263 			 251 			 83
121 			 169 			 31
108 			 237 			 25
20 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7215463424
Epoch [201/300] took 173.06109237670898s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6428088250561295, train accuracy: 0.3143441425650015
Val mean loss: 1.676695829484521, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3804 			 1998 			 1071
2296 			 2123 			 715
2205 			 1966 			 740
910 			 1683 			 334
904 			 1657 			 297
150 			 842 			 71
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 138
290 			 248 			 75
262 			 251 			 82
118 			 169 			 29
114 			 237 			 30
23 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7198194688
Epoch [202/300] took 174.63053584098816s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6432558517218379, train accuracy: 0.3154153276852663
Val mean loss: 1.6727539475371198, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3872 			 1998 			 1091
2254 			 2123 			 701
2230 			 1966 			 756
913 			 1683 			 333
870 			 1657 			 292
130 			 842 			 66
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 133
300 			 248 			 74
261 			 251 			 81
118 			 169 			 29
108 			 237 			 27
15 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7188461568
Epoch [203/300] took 173.5809907913208s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6428134452516787, train accuracy: 0.31551270815074495
Val mean loss: 1.6751474985262242, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3818 			 1998 			 1065
2262 			 2123 			 716
2209 			 1966 			 748
957 			 1683 			 346
900 			 1657 			 303
123 			 842 			 62
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 136
290 			 248 			 71
259 			 251 			 79
125 			 169 			 30
109 			 237 			 25
20 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7200193536
Epoch [204/300] took 173.8635904788971s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6424485964938487, train accuracy: 0.31668127373648847
Val mean loss: 1.67141996651161, val accuracy: 0.26557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3811 			 1998 			 1077
2251 			 2123 			 703
2240 			 1966 			 762
926 			 1683 			 336
901 			 1657 			 299
140 			 842 			 75
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 263 			 133
291 			 248 			 73
258 			 251 			 78
121 			 169 			 28
102 			 237 			 21
18 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7217126400
Epoch [205/300] took 174.37126469612122s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6432589998126401, train accuracy: 0.3152205667543091
Val mean loss: 1.6758651529870383, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3865 			 1998 			 1085
2287 			 2123 			 708
2194 			 1966 			 748
936 			 1683 			 346
855 			 1657 			 284
132 			 842 			 66
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 137
298 			 248 			 74
254 			 251 			 77
122 			 169 			 30
107 			 237 			 27
18 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7200766976
Epoch [206/300] took 173.24687886238098s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6422362212451447, train accuracy: 0.316291751874574
Val mean loss: 1.6863726581015237, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3807 			 1998 			 1078
2287 			 2123 			 722
2233 			 1966 			 755
912 			 1683 			 332
889 			 1657 			 295
141 			 842 			 66
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 132
299 			 248 			 73
257 			 251 			 80
124 			 169 			 31
110 			 237 			 27
19 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7185758208
Epoch [207/300] took 174.509215593338s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6417848291426804, train accuracy: 0.31658389327100983
Val mean loss: 1.670281759122523, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3880 			 1998 			 1092
2327 			 2123 			 726
2125 			 1966 			 724
944 			 1683 			 348
858 			 1657 			 289
135 			 842 			 72
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 132
291 			 248 			 77
262 			 251 			 83
116 			 169 			 29
113 			 237 			 25
21 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7290830848
Epoch [208/300] took 173.71358370780945s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6411941913058081, train accuracy: 0.3154153276852663
Val mean loss: 1.6789185332088936, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3829 			 1998 			 1082
2312 			 2123 			 715
2198 			 1966 			 747
941 			 1683 			 342
844 			 1657 			 283
145 			 842 			 70
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 263 			 136
287 			 248 			 70
257 			 251 			 80
124 			 169 			 32
104 			 237 			 27
18 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7218134016
Epoch [209/300] took 173.38821625709534s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.640098358611823, train accuracy: 0.3157074690817022
Val mean loss: 1.6748653156001394, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3860 			 1998 			 1081
2239 			 2123 			 704
2277 			 1966 			 769
909 			 1683 			 334
850 			 1657 			 284
134 			 842 			 70
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 263 			 138
290 			 248 			 70
260 			 251 			 80
121 			 169 			 31
110 			 237 			 29
14 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7215987712
Epoch [210/300] took 174.50105357170105s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6418676380056458, train accuracy: 0.3167786542019671
Val mean loss: 1.6714449801096103, val accuracy: 0.278816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3883 			 1998 			 1091
2246 			 2123 			 713
2223 			 1966 			 758
920 			 1683 			 339
863 			 1657 			 284
134 			 842 			 68
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 137
288 			 248 			 73
258 			 251 			 81
123 			 169 			 31
108 			 237 			 27
20 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7190829056
Epoch [211/300] took 174.52747511863708s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.640329808832329, train accuracy: 0.3160969909436167
Val mean loss: 1.6666674701178945, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3883 			 1998 			 1085
2260 			 2123 			 710
2234 			 1966 			 757
907 			 1683 			 337
829 			 1657 			 279
156 			 842 			 78
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 141
296 			 248 			 72
260 			 251 			 81
121 			 169 			 32
99 			 237 			 22
17 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7186577408
Epoch [212/300] took 174.02537512779236s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6404954321287875, train accuracy: 0.3169734151329243
Val mean loss: 1.670606569546025, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3789 			 1998 			 1065
2275 			 2123 			 707
2212 			 1966 			 757
966 			 1683 			 355
882 			 1657 			 298
145 			 842 			 73
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 263 			 133
295 			 248 			 69
260 			 251 			 83
116 			 169 			 27
107 			 237 			 29
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7190657024
Epoch [213/300] took 174.19279289245605s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6413804615769432, train accuracy: 0.3148310448923946
Val mean loss: 1.6666774836982168, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3788 			 1998 			 1065
2315 			 2123 			 724
2181 			 1966 			 746
954 			 1683 			 342
885 			 1657 			 284
146 			 842 			 72
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 134
300 			 248 			 72
262 			 251 			 83
123 			 169 			 30
106 			 237 			 25
21 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7188625408
Epoch [214/300] took 174.49654865264893s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.639810396874805, train accuracy: 0.3192131658389327
Val mean loss: 1.6759893865120121, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3828 			 1998 			 1091
2246 			 2123 			 712
2236 			 1966 			 760
942 			 1683 			 349
870 			 1657 			 295
147 			 842 			 71
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 140
287 			 248 			 70
264 			 251 			 80
120 			 169 			 30
110 			 237 			 31
19 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7144454144
Epoch [215/300] took 175.1260678768158s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6396270838110618, train accuracy: 0.3180446002531892
Val mean loss: 1.6718821932629842, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3863 			 1998 			 1089
2227 			 2123 			 706
2202 			 1966 			 759
947 			 1683 			 350
886 			 1657 			 293
144 			 842 			 69
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 132
284 			 248 			 70
262 			 251 			 83
123 			 169 			 29
108 			 237 			 26
22 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7220853760
Epoch [216/300] took 174.30687284469604s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6391637689227998, train accuracy: 0.31989482909728306
Val mean loss: 1.6695563502428008, val accuracy: 0.278816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3813 			 1998 			 1084
2267 			 2123 			 717
2228 			 1966 			 764
942 			 1683 			 346
876 			 1657 			 301
143 			 842 			 73
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 138
289 			 248 			 73
260 			 251 			 79
126 			 169 			 31
105 			 237 			 28
22 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7154407424
Epoch [217/300] took 174.62984585762024s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6390722432983256, train accuracy: 0.32145291654494107
Val mean loss: 1.6763182093457478, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3783 			 1998 			 1078
2267 			 2123 			 724
2246 			 1966 			 772
974 			 1683 			 366
850 			 1657 			 285
149 			 842 			 76
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 128
297 			 248 			 72
260 			 251 			 82
126 			 169 			 31
112 			 237 			 25
17 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7199407104
Epoch [218/300] took 174.04915499687195s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6392188985771108, train accuracy: 0.3204791118901548
Val mean loss: 1.672893884705334, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3850 			 1998 			 1090
2260 			 2123 			 724
2202 			 1966 			 756
961 			 1683 			 355
838 			 1657 			 284
158 			 842 			 82
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 263 			 135
286 			 248 			 71
262 			 251 			 83
119 			 169 			 32
104 			 237 			 26
24 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7185881088
Epoch [219/300] took 173.30000066757202s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6381440890540957, train accuracy: 0.31989482909728306
Val mean loss: 1.6736923921399, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3745 			 1998 			 1064
2276 			 2123 			 728
2225 			 1966 			 759
969 			 1683 			 363
900 			 1657 			 298
154 			 842 			 73
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 132
294 			 248 			 74
260 			 251 			 82
122 			 169 			 30
114 			 237 			 28
20 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7279230976
Epoch [220/300] took 174.3305892944336s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.637750202992995, train accuracy: 0.32077125328659073
Val mean loss: 1.6714079350959965, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3852 			 1998 			 1098
2263 			 2123 			 718
2206 			 1966 			 757
938 			 1683 			 345
847 			 1657 			 295
163 			 842 			 81
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 138
288 			 248 			 69
262 			 251 			 84
120 			 169 			 32
110 			 237 			 30
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7202716672
Epoch [221/300] took 175.07389092445374s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.639242300734713, train accuracy: 0.3172655565293602
Val mean loss: 1.6712068028566314, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3837 			 1998 			 1079
2208 			 2123 			 697
2244 			 1966 			 765
955 			 1683 			 356
874 			 1657 			 291
151 			 842 			 70
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 135
294 			 248 			 74
255 			 251 			 80
120 			 169 			 30
108 			 237 			 29
23 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7229062144
Epoch [222/300] took 173.70204401016235s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6383233296908322, train accuracy: 0.3204791118901548
Val mean loss: 1.6694656726790638, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3783 			 1998 			 1076
2271 			 2123 			 719
2210 			 1966 			 762
950 			 1683 			 353
897 			 1657 			 300
158 			 842 			 81
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
478 			 263 			 136
292 			 248 			 69
256 			 251 			 81
121 			 169 			 32
115 			 237 			 29
22 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7191058432
Epoch [223/300] took 175.22672152519226s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.638150691243347, train accuracy: 0.3219398188723342
Val mean loss: 1.6771544683270339, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 1998 			 1086
2244 			 2123 			 722
2201 			 1966 			 759
962 			 1683 			 360
892 			 1657 			 304
150 			 842 			 75
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 134
300 			 248 			 73
250 			 251 			 78
128 			 169 			 31
110 			 237 			 27
19 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7198006272
Epoch [224/300] took 174.29205918312073s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6374981392209775, train accuracy: 0.3206738728211121
Val mean loss: 1.6826641181620157, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3842 			 1998 			 1096
2246 			 2123 			 709
2161 			 1966 			 746
994 			 1683 			 367
871 			 1657 			 291
155 			 842 			 84
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
478 			 263 			 131
293 			 248 			 76
255 			 251 			 80
127 			 169 			 29
106 			 237 			 25
25 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7252230144
Epoch [225/300] took 174.16586589813232s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6368993231069262, train accuracy: 0.31736293699483886
Val mean loss: 1.67363937598903, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3805 			 1998 			 1072
2235 			 2123 			 703
2194 			 1966 			 746
988 			 1683 			 361
887 			 1657 			 295
160 			 842 			 82
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 138
290 			 248 			 71
259 			 251 			 80
126 			 169 			 30
110 			 237 			 27
15 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7265599488
Epoch [226/300] took 174.4606649875641s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6370150448748628, train accuracy: 0.32008959002824033
Val mean loss: 1.672586836465975, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3832 			 1998 			 1085
2263 			 2123 			 714
2187 			 1966 			 760
991 			 1683 			 360
849 			 1657 			 293
147 			 842 			 75
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 142
290 			 248 			 73
248 			 251 			 77
125 			 169 			 31
110 			 237 			 27
20 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7186216960
Epoch [227/300] took 175.1996672153473s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6379780097171153, train accuracy: 0.31862888304606096
Val mean loss: 1.6717426427980748, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3784 			 1998 			 1080
2290 			 2123 			 722
2212 			 1966 			 755
952 			 1683 			 346
871 			 1657 			 287
160 			 842 			 82
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 136
291 			 248 			 74
261 			 251 			 82
124 			 169 			 31
114 			 237 			 27
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7227587584
Epoch [228/300] took 174.7309970855713s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6370872311131606, train accuracy: 0.32096601421754795
Val mean loss: 1.6763534749426492, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3808 			 1998 			 1079
2243 			 2123 			 720
2215 			 1966 			 764
965 			 1683 			 360
887 			 1657 			 296
151 			 842 			 77
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
492 			 263 			 137
288 			 248 			 72
258 			 251 			 81
122 			 169 			 32
108 			 237 			 28
16 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7215791104
Epoch [229/300] took 174.38561701774597s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.636305680527494, train accuracy: 0.3215502970104197
Val mean loss: 1.682624604643845, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3790 			 1998 			 1085
2254 			 2123 			 724
2196 			 1966 			 758
976 			 1683 			 363
890 			 1657 			 291
163 			 842 			 81
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 263 			 138
289 			 248 			 71
249 			 251 			 78
128 			 169 			 32
99 			 237 			 23
21 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7205010432
Epoch [230/300] took 174.0832200050354s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6357527908135054, train accuracy: 0.3219398188723342
Val mean loss: 1.6648351215734714, val accuracy: 0.2827102803738318

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3778 			 1998 			 1086
2243 			 2123 			 718
2200 			 1966 			 753
988 			 1683 			 363
909 			 1657 			 313
151 			 842 			 73
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 139
288 			 248 			 72
264 			 251 			 82
123 			 169 			 31
109 			 237 			 30
19 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7193163776
Epoch [231/300] took 174.3888237476349s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6358949633030877, train accuracy: 0.32057649235563346
Val mean loss: 1.6615497339062575, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3798 			 1998 			 1085
2287 			 2123 			 723
2173 			 1966 			 751
986 			 1683 			 365
862 			 1657 			 289
163 			 842 			 79
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 131
295 			 248 			 73
255 			 251 			 80
125 			 169 			 31
107 			 237 			 25
25 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7202012160
Epoch [232/300] took 173.6955533027649s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.634856262682383, train accuracy: 0.3215502970104197
Val mean loss: 1.668449119823735, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3749 			 1998 			 1068
2269 			 2123 			 725
2181 			 1966 			 760
998 			 1683 			 368
910 			 1657 			 301
162 			 842 			 80
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
496 			 263 			 139
289 			 248 			 70
254 			 251 			 78
125 			 169 			 31
99 			 237 			 26
21 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7236393984
Epoch [233/300] took 173.85405898094177s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6348625117001876, train accuracy: 0.32057649235563346
Val mean loss: 1.6723741816311348, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3806 			 1998 			 1077
2283 			 2123 			 724
2167 			 1966 			 749
975 			 1683 			 363
875 			 1657 			 299
163 			 842 			 80
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 137
287 			 248 			 68
261 			 251 			 83
126 			 169 			 31
108 			 237 			 23
22 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7190820864
Epoch [234/300] took 173.94183683395386s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6349609652040904, train accuracy: 0.32213457980329147
Val mean loss: 1.6744950224713582, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3826 			 1998 			 1094
2231 			 2123 			 720
2180 			 1966 			 747
998 			 1683 			 370
880 			 1657 			 297
154 			 842 			 80
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 137
301 			 248 			 73
257 			 251 			 80
129 			 169 			 33
107 			 237 			 25
20 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7227292672
Epoch [235/300] took 174.78914999961853s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6357756864244692, train accuracy: 0.3211607751485052
Val mean loss: 1.6661854924225226, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3806 			 1998 			 1083
2219 			 2123 			 716
2195 			 1966 			 754
968 			 1683 			 361
919 			 1657 			 304
162 			 842 			 80
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 134
285 			 248 			 69
257 			 251 			 81
122 			 169 			 31
110 			 237 			 24
24 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7252197376
Epoch [236/300] took 174.0311999320984s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6348820917331541, train accuracy: 0.3226214821306846
Val mean loss: 1.6677031080897262, val accuracy: 0.27102803738317754

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3786 			 1998 			 1079
2255 			 2123 			 722
2165 			 1966 			 750
1006 			 1683 			 369
886 			 1657 			 307
171 			 842 			 86
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 263 			 136
288 			 248 			 68
257 			 251 			 78
126 			 169 			 32
96 			 237 			 24
22 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7200996352
Epoch [237/300] took 174.48281145095825s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6344374778486115, train accuracy: 0.3227188625961632
Val mean loss: 1.6640616131991874, val accuracy: 0.278816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 1998 			 1084
2231 			 2123 			 711
2171 			 1966 			 760
979 			 1683 			 365
901 			 1657 			 307
167 			 842 			 87
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 140
286 			 248 			 69
262 			 251 			 83
125 			 169 			 30
112 			 237 			 27
19 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7199161344
Epoch [238/300] took 175.16409134864807s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6341848755922643, train accuracy: 0.323303145389035
Val mean loss: 1.6706307137884744, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3877 			 1998 			 1107
2228 			 2123 			 719
2143 			 1966 			 739
1022 			 1683 			 384
845 			 1657 			 292
154 			 842 			 79
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 140
285 			 248 			 72
259 			 251 			 82
129 			 169 			 31
107 			 237 			 27
20 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7252983808
Epoch [239/300] took 174.70862221717834s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6338400168582285, train accuracy: 0.3227188625961632
Val mean loss: 1.679483596871539, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3831 			 1998 			 1099
2239 			 2123 			 711
2158 			 1966 			 752
987 			 1683 			 372
891 			 1657 			 298
163 			 842 			 82
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 135
284 			 248 			 71
257 			 251 			 81
124 			 169 			 30
113 			 237 			 28
21 			 116 			 6
Max memory allocated: 14709633024; Memory allocated: 7255965696
Epoch [240/300] took 174.0222520828247s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.633164996298674, train accuracy: 0.32534813516408606
Val mean loss: 1.6702863995621844, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3832 			 1998 			 1082
2200 			 2123 			 716
2168 			 1966 			 761
1021 			 1683 			 393
873 			 1657 			 301
175 			 842 			 88
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 263 			 134
281 			 248 			 70
250 			 251 			 77
128 			 169 			 33
104 			 237 			 26
24 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7290355712
Epoch [241/300] took 174.06228971481323s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.633665688312685, train accuracy: 0.32427695004382123
Val mean loss: 1.6636676235896786, val accuracy: 0.2881619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3840 			 1998 			 1092
2234 			 2123 			 729
2174 			 1966 			 757
1001 			 1683 			 381
859 			 1657 			 291
161 			 842 			 80
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 137
287 			 248 			 75
256 			 251 			 81
122 			 169 			 32
123 			 237 			 32
29 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7204748288
Epoch [242/300] took 174.83973908424377s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6331535648334063, train accuracy: 0.32291362352712044
Val mean loss: 1.665722567860673, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3819 			 1998 			 1099
2248 			 2123 			 720
2164 			 1966 			 741
989 			 1683 			 375
875 			 1657 			 297
174 			 842 			 84
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 263 			 137
285 			 248 			 71
249 			 251 			 79
128 			 169 			 30
111 			 237 			 30
22 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7207738368
Epoch [243/300] took 174.048433303833s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6327667362593417, train accuracy: 0.3239848086473853
Val mean loss: 1.669594209368636, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3779 			 1998 			 1074
2235 			 2123 			 723
2214 			 1966 			 766
970 			 1683 			 368
907 			 1657 			 308
164 			 842 			 88
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 138
285 			 248 			 73
259 			 251 			 79
130 			 169 			 31
111 			 237 			 31
17 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7225056256
Epoch [244/300] took 173.77052807807922s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6323763347489069, train accuracy: 0.3245690914402571
Val mean loss: 1.66055358037716, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3824 			 1998 			 1100
2220 			 2123 			 716
2150 			 1966 			 746
1016 			 1683 			 379
886 			 1657 			 306
173 			 842 			 86
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 133
289 			 248 			 70
256 			 251 			 80
126 			 169 			 30
118 			 237 			 30
25 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7194818560
Epoch [245/300] took 174.59207344055176s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6323177365127755, train accuracy: 0.3234979063199922
Val mean loss: 1.6757168246478569, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3832 			 1998 			 1094
2235 			 2123 			 717
2170 			 1966 			 758
993 			 1683 			 370
885 			 1657 			 303
154 			 842 			 80
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 135
289 			 248 			 71
262 			 251 			 78
127 			 169 			 31
120 			 237 			 32
16 			 116 			 7
Max memory allocated: 14709633024; Memory allocated: 7154407424
Epoch [246/300] took 174.0356719493866s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.631412315220105, train accuracy: 0.3239848086473853
Val mean loss: 1.6679443004654675, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3811 			 1998 			 1093
2239 			 2123 			 709
2162 			 1966 			 755
1008 			 1683 			 380
882 			 1657 			 307
167 			 842 			 83
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
478 			 263 			 144
286 			 248 			 68
260 			 251 			 81
125 			 169 			 31
114 			 237 			 27
21 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7205108736
Epoch [247/300] took 174.23712587356567s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6319510554227503, train accuracy: 0.3250559937676502
Val mean loss: 1.6623923691307627, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3770 			 1998 			 1084
2210 			 2123 			 708
2211 			 1966 			 767
999 			 1683 			 379
907 			 1657 			 311
172 			 842 			 89
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
496 			 263 			 141
283 			 248 			 68
256 			 251 			 80
124 			 169 			 32
107 			 237 			 30
18 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7236312064
Epoch [248/300] took 174.39756870269775s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6311111851273297, train accuracy: 0.32213457980329147
Val mean loss: 1.6681449791280234, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 1998 			 1084
2204 			 2123 			 703
2206 			 1966 			 757
995 			 1683 			 375
874 			 1657 			 299
170 			 842 			 90
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 263 			 140
283 			 248 			 70
253 			 251 			 82
125 			 169 			 30
108 			 237 			 28
22 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7161042944
Epoch [249/300] took 173.93434476852417s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6311248288347713, train accuracy: 0.32602979842243646
Val mean loss: 1.6664194217542323, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3752 			 1998 			 1090
2260 			 2123 			 719
2188 			 1966 			 762
1023 			 1683 			 383
882 			 1657 			 308
164 			 842 			 86
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 139
291 			 248 			 71
254 			 251 			 81
124 			 169 			 31
112 			 237 			 28
18 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7196751872
Epoch [250/300] took 174.03984189033508s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6297398218856052, train accuracy: 0.3263219398188723
Val mean loss: 1.6731223798379666, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3772 			 1998 			 1095
2278 			 2123 			 729
2190 			 1966 			 763
968 			 1683 			 364
895 			 1657 			 310
166 			 842 			 90
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 134
288 			 248 			 74
250 			 251 			 75
127 			 169 			 30
122 			 237 			 32
26 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7205960704
Epoch [251/300] took 174.4119417667389s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6312359805419065, train accuracy: 0.32486123283669294
Val mean loss: 1.6726859517213775, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3814 			 1998 			 1094
2201 			 2123 			 710
2174 			 1966 			 760
1010 			 1683 			 385
901 			 1657 			 302
169 			 842 			 85
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 134
289 			 248 			 71
262 			 251 			 80
126 			 169 			 31
113 			 237 			 29
24 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7189059584
Epoch [252/300] took 174.8512053489685s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6310001277477941, train accuracy: 0.32554289609504333
Val mean loss: 1.674292587652439, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 1998 			 1097
2200 			 2123 			 714
2162 			 1966 			 746
1015 			 1683 			 385
900 			 1657 			 310
172 			 842 			 91
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 136
278 			 248 			 67
254 			 251 			 78
130 			 169 			 32
110 			 237 			 27
21 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7236500480
Epoch [253/300] took 174.32265043258667s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6306623446978512, train accuracy: 0.3237900477164281
Val mean loss: 1.6606541523119298, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3806 			 1998 			 1088
2250 			 2123 			 722
2170 			 1966 			 752
1002 			 1683 			 377
871 			 1657 			 294
170 			 842 			 92
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
469 			 263 			 132
293 			 248 			 73
257 			 251 			 80
131 			 169 			 32
110 			 237 			 28
24 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7186102272
Epoch [254/300] took 174.6135573387146s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6303373151850478, train accuracy: 0.3246664719057357
Val mean loss: 1.6652651472789486, val accuracy: 0.26947040498442365

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3817 			 1998 			 1100
2200 			 2123 			 709
2174 			 1966 			 753
1009 			 1683 			 382
894 			 1657 			 308
175 			 842 			 82
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 132
288 			 248 			 70
259 			 251 			 80
131 			 169 			 31
110 			 237 			 24
24 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7224237056
Epoch [255/300] took 174.34105348587036s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.629672368367513, train accuracy: 0.3261271788879151
Val mean loss: 1.6728776635193243, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3794 			 1998 			 1084
2206 			 2123 			 710
2202 			 1966 			 770
1006 			 1683 			 382
895 			 1657 			 317
166 			 842 			 86
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 263 			 140
291 			 248 			 70
256 			 251 			 77
126 			 169 			 31
110 			 237 			 26
20 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7237229568
Epoch [256/300] took 174.18622398376465s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6293141600498902, train accuracy: 0.32622455935339373
Val mean loss: 1.6859393701320742, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3732 			 1998 			 1084
2234 			 2123 			 720
2186 			 1966 			 754
1026 			 1683 			 391
912 			 1657 			 313
179 			 842 			 88
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
478 			 263 			 129
289 			 248 			 74
255 			 251 			 79
126 			 169 			 32
111 			 237 			 26
25 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7191377920
Epoch [257/300] took 173.99811935424805s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6285472982026334, train accuracy: 0.32680884214626543
Val mean loss: 1.6610264952589826, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3776 			 1998 			 1089
2200 			 2123 			 715
2147 			 1966 			 755
1048 			 1683 			 392
928 			 1657 			 316
170 			 842 			 89
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 141
284 			 248 			 71
260 			 251 			 82
128 			 169 			 32
104 			 237 			 27
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7190861824
Epoch [258/300] took 174.39602661132812s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.629221394054615, train accuracy: 0.3226214821306846
Val mean loss: 1.6642273373720122, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3771 			 1998 			 1074
2241 			 2123 			 713
2148 			 1966 			 740
1040 			 1683 			 385
890 			 1657 			 310
179 			 842 			 91
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 139
291 			 248 			 71
252 			 251 			 77
132 			 169 			 32
100 			 237 			 26
27 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7208762368
Epoch [259/300] took 173.87279438972473s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6284452127147686, train accuracy: 0.32554289609504333
Val mean loss: 1.6795593267533837, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3744 			 1998 			 1079
2255 			 2123 			 721
2150 			 1966 			 754
1033 			 1683 			 392
911 			 1657 			 309
176 			 842 			 88
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 139
289 			 248 			 72
258 			 251 			 78
127 			 169 			 30
109 			 237 			 27
19 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7151089664
Epoch [260/300] took 173.7448592185974s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6285152353601664, train accuracy: 0.3266140812153082
Val mean loss: 1.6686657986989835, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3740 			 1998 			 1094
2247 			 2123 			 726
2186 			 1966 			 754
1039 			 1683 			 391
889 			 1657 			 306
168 			 842 			 83
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
464 			 263 			 133
295 			 248 			 73
252 			 251 			 77
134 			 169 			 33
113 			 237 			 30
26 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7207050240
Epoch [261/300] took 173.8062915802002s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6270066822800682, train accuracy: 0.3266140812153082
Val mean loss: 1.6706151467997854, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3773 			 1998 			 1087
2177 			 2123 			 705
2180 			 1966 			 759
1039 			 1683 			 395
921 			 1657 			 316
179 			 842 			 92
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 144
290 			 248 			 73
254 			 251 			 81
123 			 169 			 30
109 			 237 			 31
21 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7157725184
Epoch [262/300] took 174.61816000938416s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6289742572285304, train accuracy: 0.32778264680105174
Val mean loss: 1.6678984252417959, val accuracy: 0.2827102803738318

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3785 			 1998 			 1100
2198 			 2123 			 704
2168 			 1966 			 761
1049 			 1683 			 398
887 			 1657 			 312
182 			 842 			 91
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 263 			 139
284 			 248 			 72
257 			 251 			 83
128 			 169 			 31
111 			 237 			 30
21 			 116 			 8
Max memory allocated: 14709633024; Memory allocated: 7245561856
Epoch [263/300] took 174.25015664100647s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6274465341062931, train accuracy: 0.32622455935339373
Val mean loss: 1.6731075426427329, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3812 			 1998 			 1102
2231 			 2123 			 716
2156 			 1966 			 752
1024 			 1683 			 385
863 			 1657 			 299
183 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 263 			 136
290 			 248 			 71
255 			 251 			 79
122 			 169 			 30
113 			 237 			 30
25 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7316325376
Epoch [264/300] took 174.06910276412964s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6276779119099412, train accuracy: 0.32836692959392344
Val mean loss: 1.6556607484817505, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3771 			 1998 			 1097
2219 			 2123 			 726
2156 			 1966 			 750
1030 			 1683 			 392
905 			 1657 			 316
188 			 842 			 91
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 134
293 			 248 			 72
251 			 251 			 80
132 			 169 			 31
111 			 237 			 26
22 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7229930496
Epoch [265/300] took 174.39311242103577s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6272582413622896, train accuracy: 0.32564027656052197
Val mean loss: 1.6787108502736905, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3807 			 1998 			 1085
2174 			 2123 			 701
2187 			 1966 			 766
1025 			 1683 			 383
902 			 1657 			 320
174 			 842 			 89
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 135
289 			 248 			 69
255 			 251 			 78
126 			 169 			 31
109 			 237 			 26
25 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7198455808
Epoch [266/300] took 174.5741765499115s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6272780468159376, train accuracy: 0.3285616905248807
Val mean loss: 1.671672498307577, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3752 			 1998 			 1094
2246 			 2123 			 716
2161 			 1966 			 765
1031 			 1683 			 394
888 			 1657 			 309
191 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 263 			 141
283 			 248 			 71
249 			 251 			 79
133 			 169 			 33
95 			 237 			 22
22 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7212309504
Epoch [267/300] took 174.33988189697266s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6273923165330262, train accuracy: 0.3278800272665303
Val mean loss: 1.668165451142846, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3753 			 1998 			 1075
2211 			 2123 			 713
2136 			 1966 			 757
1062 			 1683 			 402
927 			 1657 			 323
180 			 842 			 97
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 133
280 			 248 			 68
257 			 251 			 82
127 			 169 			 32
113 			 237 			 28
25 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7199620096
Epoch [268/300] took 174.3860421180725s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6272047743247677, train accuracy: 0.32515337423312884
Val mean loss: 1.6690081765012044, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3800 			 1998 			 1089
2237 			 2123 			 713
2115 			 1966 			 749
1055 			 1683 			 401
896 			 1657 			 305
166 			 842 			 82
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
459 			 263 			 129
291 			 248 			 72
262 			 251 			 82
128 			 169 			 29
117 			 237 			 31
27 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7212104704
Epoch [269/300] took 174.29399919509888s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6258713315209123, train accuracy: 0.3273931249391372
Val mean loss: 1.6589003248912533, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3803 			 1998 			 1088
2183 			 2123 			 706
2185 			 1966 			 762
1012 			 1683 			 387
900 			 1657 			 316
186 			 842 			 103
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
459 			 263 			 132
293 			 248 			 71
256 			 251 			 79
136 			 169 			 30
112 			 237 			 29
28 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7200873472
Epoch [270/300] took 174.0117564201355s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6261024022028083, train accuracy: 0.3266140812153082
Val mean loss: 1.6706546661330433, val accuracy: 0.2827102803738318

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3766 			 1998 			 1078
2214 			 2123 			 711
2130 			 1966 			 747
1066 			 1683 			 403
904 			 1657 			 320
189 			 842 			 95
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 263 			 140
287 			 248 			 71
256 			 251 			 82
128 			 169 			 31
105 			 237 			 27
23 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7190009856
Epoch [271/300] took 173.968519449234s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6265466068392602, train accuracy: 0.32729574447365856
Val mean loss: 1.6642812926594803, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3797 			 1998 			 1100
2179 			 2123 			 702
2149 			 1966 			 748
1058 			 1683 			 405
913 			 1657 			 318
173 			 842 			 88
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
469 			 263 			 134
289 			 248 			 72
256 			 251 			 76
134 			 169 			 31
112 			 237 			 29
24 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7229946880
Epoch [272/300] took 174.01052832603455s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6261595171931376, train accuracy: 0.3285616905248807
Val mean loss: 1.6727001754249013, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3705 			 1998 			 1078
2219 			 2123 			 715
2169 			 1966 			 758
1080 			 1683 			 403
905 			 1657 			 323
191 			 842 			 97
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 263 			 132
295 			 248 			 75
254 			 251 			 80
135 			 169 			 30
115 			 237 			 26
23 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7201618944
Epoch [273/300] took 173.94951510429382s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6244945982906307, train accuracy: 0.32671146168078685
Val mean loss: 1.66140967462121, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3737 			 1998 			 1072
2219 			 2123 			 714
2157 			 1966 			 750
1053 			 1683 			 402
905 			 1657 			 318
198 			 842 			 99
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 137
287 			 248 			 71
256 			 251 			 80
124 			 169 			 30
110 			 237 			 27
23 			 116 			 9
Max memory allocated: 14709633024; Memory allocated: 7198914560
Epoch [274/300] took 174.73803567886353s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6247337313827324, train accuracy: 0.32953549517966696
Val mean loss: 1.664978440214948, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3764 			 1998 			 1089
2248 			 2123 			 734
2138 			 1966 			 748
1059 			 1683 			 399
882 			 1657 			 318
178 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 263 			 139
293 			 248 			 70
256 			 251 			 80
127 			 169 			 33
98 			 237 			 21
26 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7161042944
Epoch [275/300] took 174.5991566181183s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6247036627891278, train accuracy: 0.3259324179569578
Val mean loss: 1.6714294189360084, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3774 			 1998 			 1089
2242 			 2123 			 718
2158 			 1966 			 752
1044 			 1683 			 396
860 			 1657 			 296
191 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
459 			 263 			 135
297 			 248 			 77
250 			 251 			 80
139 			 169 			 32
114 			 237 			 33
25 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7197604864
Epoch [276/300] took 174.442702293396s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6249541883528047, train accuracy: 0.32749050540461583
Val mean loss: 1.67433691606289, val accuracy: 0.2842679127725857

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3764 			 1998 			 1087
2235 			 2123 			 719
2149 			 1966 			 752
1050 			 1683 			 397
895 			 1657 			 316
176 			 842 			 92
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 138
288 			 248 			 71
247 			 251 			 79
138 			 169 			 34
112 			 237 			 30
26 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7210613760
Epoch [277/300] took 174.68766736984253s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6243742819515716, train accuracy: 0.32671146168078685
Val mean loss: 1.6602039569761695, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3772 			 1998 			 1098
2227 			 2123 			 710
2157 			 1966 			 748
1051 			 1683 			 401
879 			 1657 			 305
183 			 842 			 93
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 139
293 			 248 			 76
247 			 251 			 79
134 			 169 			 30
104 			 237 			 26
24 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7206378496
Epoch [278/300] took 174.03667783737183s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.62500696724449, train accuracy: 0.3258350374914792
Val mean loss: 1.6600611384322004, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3773 			 1998 			 1078
2213 			 2123 			 709
2150 			 1966 			 748
1054 			 1683 			 404
905 			 1657 			 318
174 			 842 			 89
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 133
291 			 248 			 74
254 			 251 			 79
131 			 169 			 33
109 			 237 			 27
24 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7220132864
Epoch [279/300] took 174.2024211883545s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6238541591947324, train accuracy: 0.3298276365761028
Val mean loss: 1.6605653646515637, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3745 			 1998 			 1083
2274 			 2123 			 742
2103 			 1966 			 743
1071 			 1683 			 409
887 			 1657 			 311
189 			 842 			 99
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 133
292 			 248 			 71
253 			 251 			 79
138 			 169 			 32
107 			 237 			 24
24 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7202593792
Epoch [280/300] took 174.0725758075714s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6239568381294656, train accuracy: 0.3276852663355731
Val mean loss: 1.6705038896421107, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3769 			 1998 			 1082
2236 			 2123 			 716
2125 			 1966 			 749
1061 			 1683 			 405
896 			 1657 			 317
182 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 263 			 131
292 			 248 			 72
257 			 251 			 81
135 			 169 			 32
111 			 237 			 29
27 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7198415872
Epoch [281/300] took 173.97197437286377s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6238052176537914, train accuracy: 0.32885383192131656
Val mean loss: 1.657729875750658, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3768 			 1998 			 1082
2221 			 2123 			 722
2077 			 1966 			 739
1105 			 1683 			 417
901 			 1657 			 311
197 			 842 			 106
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
456 			 263 			 129
295 			 248 			 72
260 			 251 			 81
136 			 169 			 31
109 			 237 			 32
28 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7227292672
Epoch [282/300] took 173.9785759449005s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.622454456079786, train accuracy: 0.32914597331775247
Val mean loss: 1.6661492760588483, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3717 			 1998 			 1070
2208 			 2123 			 722
2159 			 1966 			 758
1075 			 1683 			 410
920 			 1657 			 322
190 			 842 			 98
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 134
295 			 248 			 73
251 			 251 			 80
131 			 169 			 32
103 			 237 			 27
29 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7205141504
Epoch [283/300] took 173.65875697135925s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.622304289140434, train accuracy: 0.3311909630928036
Val mean loss: 1.6677361465081937, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3760 			 1998 			 1105
2194 			 2123 			 719
2181 			 1966 			 769
1069 			 1683 			 396
882 			 1657 			 321
183 			 842 			 91
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 263 			 134
295 			 248 			 72
258 			 251 			 77
138 			 169 			 31
100 			 237 			 25
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7225318400
Epoch [284/300] took 173.88736152648926s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6226875770871885, train accuracy: 0.3298276365761028
Val mean loss: 1.6701648235321045, val accuracy: 0.2757009345794392

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3736 			 1998 			 1084
2250 			 2123 			 738
2141 			 1966 			 747
1066 			 1683 			 410
891 			 1657 			 313
185 			 842 			 95
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 263 			 135
294 			 248 			 74
250 			 251 			 77
133 			 169 			 30
109 			 237 			 27
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7199292416
Epoch [285/300] took 174.55532383918762s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6235209981971812, train accuracy: 0.3276852663355731
Val mean loss: 1.6673117701600237, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3741 			 1998 			 1073
2235 			 2123 			 722
2174 			 1966 			 769
1046 			 1683 			 393
878 			 1657 			 312
195 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 263 			 144
291 			 248 			 74
252 			 251 			 76
135 			 169 			 31
104 			 237 			 27
22 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7186814976
Epoch [286/300] took 174.02450108528137s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6220839131286955, train accuracy: 0.3285616905248807
Val mean loss: 1.6630529746776674, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3698 			 1998 			 1074
2294 			 2123 			 733
2105 			 1966 			 742
1082 			 1683 			 419
885 			 1657 			 308
205 			 842 			 98
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 133
291 			 248 			 74
259 			 251 			 81
130 			 169 			 32
107 			 237 			 25
26 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7245594624
Epoch [287/300] took 174.37528204917908s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6225743921374978, train accuracy: 0.32914597331775247
Val mean loss: 1.6663280405649326, val accuracy: 0.278816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3781 			 1998 			 1105
2214 			 2123 			 713
2105 			 1966 			 742
1089 			 1683 			 415
889 			 1657 			 309
191 			 842 			 96
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 138
288 			 248 			 71
252 			 251 			 78
135 			 169 			 32
104 			 237 			 28
23 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7198563328
Epoch [288/300] took 174.0991427898407s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6215653289515652, train accuracy: 0.32904859285227384
Val mean loss: 1.6618381680511847, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3751 			 1998 			 1086
2219 			 2123 			 718
2135 			 1966 			 750
1073 			 1683 			 409
905 			 1657 			 317
186 			 842 			 99
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 139
286 			 248 			 72
255 			 251 			 81
134 			 169 			 31
107 			 237 			 27
25 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7157725184
Epoch [289/300] took 174.18248414993286s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6214568692947102, train accuracy: 0.33382023566072644
Val mean loss: 1.6646332798934564, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3768 			 1998 			 1101
2180 			 2123 			 716
2175 			 1966 			 769
1072 			 1683 			 413
879 			 1657 			 325
195 			 842 			 104
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
468 			 263 			 136
293 			 248 			 71
248 			 251 			 80
139 			 169 			 31
112 			 237 			 28
24 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7236000768
Epoch [290/300] took 173.96559309959412s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6211680630657161, train accuracy: 0.3315804849547181
Val mean loss: 1.676231538377157, val accuracy: 0.2733644859813084

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3708 			 1998 			 1094
2220 			 2123 			 730
2129 			 1966 			 749
1080 			 1683 			 404
932 			 1657 			 330
200 			 842 			 98
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 263 			 135
289 			 248 			 69
252 			 251 			 78
132 			 169 			 32
107 			 237 			 27
28 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7201012736
Epoch [291/300] took 174.038747549057s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6207428357311497, train accuracy: 0.33235952867854707
Val mean loss: 1.664717767296768, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3770 			 1998 			 1101
2176 			 2123 			 718
2151 			 1966 			 766
1087 			 1683 			 414
891 			 1657 			 313
194 			 842 			 101
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 263 			 135
289 			 248 			 72
262 			 251 			 83
131 			 169 			 31
114 			 237 			 31
26 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7355033600
Epoch [292/300] took 174.8979992866516s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.62173417869758, train accuracy: 0.32826954912844486
Val mean loss: 1.666214323625332, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3780 			 1998 			 1085
2191 			 2123 			 715
2138 			 1966 			 751
1081 			 1683 			 410
882 			 1657 			 306
197 			 842 			 104
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 139
289 			 248 			 75
245 			 251 			 79
130 			 169 			 31
102 			 237 			 25
27 			 116 			 10
Max memory allocated: 14709633024; Memory allocated: 7237999616
Epoch [293/300] took 174.4853494167328s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6214946746083434, train accuracy: 0.32826954912844486
Val mean loss: 1.6659375748983243, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3715 			 1998 			 1066
2220 			 2123 			 724
2157 			 1966 			 760
1073 			 1683 			 408
907 			 1657 			 318
197 			 842 			 95
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 263 			 136
283 			 248 			 69
260 			 251 			 83
123 			 169 			 29
105 			 237 			 27
30 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7265665024
Epoch [294/300] took 174.0374960899353s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6203206721867356, train accuracy: 0.3313857240237608
Val mean loss: 1.6797155781490047, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3724 			 1998 			 1075
2208 			 2123 			 730
2182 			 1966 			 765
1059 			 1683 			 409
900 			 1657 			 319
196 			 842 			 105
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 133
287 			 248 			 71
252 			 251 			 78
134 			 169 			 32
114 			 237 			 27
25 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7224105984
Epoch [295/300] took 174.2982575893402s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.620273982995767, train accuracy: 0.3329438114714188
Val mean loss: 1.6734191150200077, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3783 			 1998 			 1111
2176 			 2123 			 714
2146 			 1966 			 767
1070 			 1683 			 410
907 			 1657 			 319
187 			 842 			 98
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
468 			 263 			 133
292 			 248 			 71
247 			 251 			 81
134 			 169 			 35
118 			 237 			 29
25 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7157725184
Epoch [296/300] took 173.1967854499817s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6196001931514323, train accuracy: 0.3335280942642906
Val mean loss: 1.6734506734987584, val accuracy: 0.2772585669781931

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3727 			 1998 			 1094
2229 			 2123 			 729
2137 			 1966 			 758
1073 			 1683 			 413
896 			 1657 			 323
207 			 842 			 108
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 133
285 			 248 			 69
249 			 251 			 80
134 			 169 			 31
116 			 237 			 30
29 			 116 			 13
Max memory allocated: 14709633024; Memory allocated: 7239613440
Epoch [297/300] took 172.52059888839722s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6202348582098418, train accuracy: 0.3346966598500341
Val mean loss: 1.6635965137946895, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3709 			 1998 			 1095
2228 			 2123 			 729
2129 			 1966 			 757
1089 			 1683 			 418
902 			 1657 			 334
212 			 842 			 104
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
465 			 263 			 132
292 			 248 			 73
253 			 251 			 79
134 			 169 			 32
113 			 237 			 27
27 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7191230464
Epoch [298/300] took 171.78113889694214s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6192248595466494, train accuracy: 0.3294381147141883
Val mean loss: 1.6632273575154746, val accuracy: 0.27258566978193144

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3717 			 1998 			 1075
2252 			 2123 			 732
2105 			 1966 			 746
1080 			 1683 			 411
924 			 1657 			 319
191 			 842 			 100
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 129
279 			 248 			 67
251 			 251 			 81
137 			 169 			 32
118 			 237 			 30
27 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7131182080
Epoch [299/300] took 172.88483333587646s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6201735434131088, train accuracy: 0.3327490505404616
Val mean loss: 1.6689585505462274, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3708 			 1998 			 1094
2216 			 2123 			 726
2127 			 1966 			 756
1080 			 1683 			 414
937 			 1657 			 324
201 			 842 			 103
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
459 			 263 			 131
298 			 248 			 75
250 			 251 			 80
131 			 169 			 31
121 			 237 			 33
25 			 116 			 11
Max memory allocated: 14709633024; Memory allocated: 7196711936
Epoch [300/300] took 173.7128415107727s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 300, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-06, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.620253541387873, train accuracy: 0.3316778654201967
Val mean loss: 1.65952517346638, val accuracy: 0.2749221183800623

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3702 			 1998 			 1069
2248 			 2123 			 747
2111 			 1966 			 755
1117 			 1683 			 423
896 			 1657 			 312
195 			 842 			 100
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 263 			 133
294 			 248 			 72
251 			 251 			 78
132 			 169 			 31
108 			 237 			 27
28 			 116 			 12
Max memory allocated: 14709633024; Memory allocated: 7187814400
Training finished! Training for 300 epochs took: 51904.97163796425s
Training loss: [1.794460190048099, 1.784844375473688, 1.7785707730741886, 1.7733047985213568, 1.769204806315936, 1.7666149484777005, 1.763355994521643, 1.7611116839346486, 1.7590982360631877, 1.7571437637382579, 1.7551231165169927, 1.7534735793265226, 1.751270854955893, 1.7500483428949136, 1.7487440918836268, 1.7468023909215245, 1.7448331448147973, 1.742899836038132, 1.7415643581348788, 1.7398093864553814, 1.7378282521001276, 1.7368804647172351, 1.7351681632787639, 1.7337038747246762, 1.7329037616557421, 1.732436575622202, 1.730905142528617, 1.7290569105623668, 1.728166095935667, 1.727304178234944, 1.7257181495149558, 1.7253680333170192, 1.7236377346181424, 1.722307576940067, 1.7211928022242038, 1.720208500775964, 1.7197939840804009, 1.7186024530654385, 1.7175943253567656, 1.7163017928785995, 1.715934452609481, 1.7142551584035808, 1.7139097842100626, 1.712354922220343, 1.7123656614547207, 1.7109786019518367, 1.7098598844165742, 1.7096903944312598, 1.7081505628389733, 1.7077360951640523, 1.7067184875315966, 1.7062772297042181, 1.705326128600171, 1.704887356342185, 1.704462385994623, 1.7030011976248007, 1.7021512625002044, 1.701341555125988, 1.7016488324815982, 1.699991178289752, 1.6997915079289136, 1.6991785419321506, 1.6979390119095086, 1.6975497278469003, 1.6963724588679376, 1.6964420165599692, 1.6960364231068026, 1.6955869851454024, 1.6947164164153958, 1.6935277000023197, 1.6929111814944544, 1.6931223018889858, 1.6918331258393522, 1.6916703962462714, 1.690915574165891, 1.68999098320245, 1.689870201167288, 1.6889646027318415, 1.6888035075315433, 1.688227483788012, 1.6880345095726559, 1.6871410645428477, 1.686567781870239, 1.6854556962337077, 1.6860460236065113, 1.6856292460195001, 1.684307162635423, 1.6838302159235115, 1.6833152919543495, 1.6834030106802966, 1.6823765050585024, 1.6823393344136413, 1.6817287511171952, 1.681078585508828, 1.6806198674198995, 1.6804888099896202, 1.6800808330933996, 1.6787074477501747, 1.6790786079157178, 1.6787339842579447, 1.6781456099121, 1.6773341047429593, 1.677266391266915, 1.6777735034996104, 1.6765304261650251, 1.6756340358116173, 1.6750477028784352, 1.6753233708325206, 1.6749236728543433, 1.6740800068014507, 1.673991557222289, 1.6732005166858899, 1.6720499394467314, 1.6729425247584548, 1.6713031716064501, 1.6725949594907672, 1.6722734925160156, 1.6708704441135918, 1.6705656549269536, 1.6696891413299466, 1.6697871521625935, 1.6702799641083335, 1.6688461849622638, 1.6690731108002945, 1.667882761108541, 1.6684233674379152, 1.6673813913470117, 1.6675063252820403, 1.6660603177138948, 1.666591730444602, 1.6664186890622907, 1.6659625100198192, 1.6655961668751322, 1.6653929978516242, 1.6640228278169007, 1.6647606486472013, 1.6635369511779594, 1.6637846168327926, 1.6634000506356499, 1.6628716534171892, 1.6628814735145212, 1.6623387292166736, 1.6618503796348691, 1.661906135045108, 1.661096224903689, 1.6607418349970167, 1.66043656414543, 1.6603803942879412, 1.6595347636956663, 1.6594619164214328, 1.6587419149660247, 1.65884536003398, 1.6593633225402358, 1.6571262280146282, 1.6571741813439818, 1.656515480201935, 1.656380129751758, 1.656064063960518, 1.6568399838569379, 1.656142791112264, 1.6556599080748275, 1.6565924611789786, 1.6553711831755356, 1.654848561480038, 1.655196447981481, 1.654361373167543, 1.6537058743361002, 1.6532821417597596, 1.6533205282651005, 1.6529716862324986, 1.652286867857722, 1.6518100485252072, 1.6519167954305252, 1.6514585913156052, 1.651418174538657, 1.6518699725468953, 1.6506543508571256, 1.6504034327569408, 1.6500832373479446, 1.6507399824920845, 1.6497981399761925, 1.6496172931706794, 1.6489948977562496, 1.6484677089708988, 1.649043316410338, 1.6483912156007001, 1.6478908143682272, 1.6477082024482181, 1.6474881376432853, 1.6471945816111342, 1.646116800397356, 1.6465816401246924, 1.6462076315627292, 1.6457506990135644, 1.6455594007842638, 1.6458872155608417, 1.6451448183564754, 1.6444108099952293, 1.6454506146944943, 1.6444680066866295, 1.6428088250561295, 1.6432558517218379, 1.6428134452516787, 1.6424485964938487, 1.6432589998126401, 1.6422362212451447, 1.6417848291426804, 1.6411941913058081, 1.640098358611823, 1.6418676380056458, 1.640329808832329, 1.6404954321287875, 1.6413804615769432, 1.639810396874805, 1.6396270838110618, 1.6391637689227998, 1.6390722432983256, 1.6392188985771108, 1.6381440890540957, 1.637750202992995, 1.639242300734713, 1.6383233296908322, 1.638150691243347, 1.6374981392209775, 1.6368993231069262, 1.6370150448748628, 1.6379780097171153, 1.6370872311131606, 1.636305680527494, 1.6357527908135054, 1.6358949633030877, 1.634856262682383, 1.6348625117001876, 1.6349609652040904, 1.6357756864244692, 1.6348820917331541, 1.6344374778486115, 1.6341848755922643, 1.6338400168582285, 1.633164996298674, 1.633665688312685, 1.6331535648334063, 1.6327667362593417, 1.6323763347489069, 1.6323177365127755, 1.631412315220105, 1.6319510554227503, 1.6311111851273297, 1.6311248288347713, 1.6297398218856052, 1.6312359805419065, 1.6310001277477941, 1.6306623446978512, 1.6303373151850478, 1.629672368367513, 1.6293141600498902, 1.6285472982026334, 1.629221394054615, 1.6284452127147686, 1.6285152353601664, 1.6270066822800682, 1.6289742572285304, 1.6274465341062931, 1.6276779119099412, 1.6272582413622896, 1.6272780468159376, 1.6273923165330262, 1.6272047743247677, 1.6258713315209123, 1.6261024022028083, 1.6265466068392602, 1.6261595171931376, 1.6244945982906307, 1.6247337313827324, 1.6247036627891278, 1.6249541883528047, 1.6243742819515716, 1.62500696724449, 1.6238541591947324, 1.6239568381294656, 1.6238052176537914, 1.622454456079786, 1.622304289140434, 1.6226875770871885, 1.6235209981971812, 1.6220839131286955, 1.6225743921374978, 1.6215653289515652, 1.6214568692947102, 1.6211680630657161, 1.6207428357311497, 1.62173417869758, 1.6214946746083434, 1.6203206721867356, 1.620273982995767, 1.6196001931514323, 1.6202348582098418, 1.6192248595466494, 1.6201735434131088, 1.620253541387873]
Validation loss: [1.7971536211851167, 1.7818984781823508, 1.7799701661598393, 1.777080806290231, 1.7799117099948045, 1.7727523954903208, 1.7689996085515836, 1.7703110125006698, 1.760550164594883, 1.7663747275747903, 1.7581700435498866, 1.7663351064775048, 1.7562354250652035, 1.7552284845491735, 1.7617937791638258, 1.7550991221172054, 1.7491589842773065, 1.7510076790321163, 1.7476150059118503, 1.748122389723615, 1.7516140472598192, 1.7428695661265676, 1.7467045318789598, 1.7430703465531512, 1.7438636872826554, 1.739037086323994, 1.7335656997634143, 1.7377279182759726, 1.7369615479213436, 1.7380121917259403, 1.733890539262353, 1.739220084213629, 1.7289019154339302, 1.7297721490627382, 1.7278517397438609, 1.7249893269887784, 1.7267555201925882, 1.7270278000250094, 1.7240965279137217, 1.727600865247773, 1.7241370299967325, 1.7204673958987724, 1.7272085532909487, 1.7244133367771055, 1.7221824337796467, 1.7222628593444824, 1.7237990861985741, 1.7117931115918044, 1.7135724120023774, 1.7158175125354673, 1.7170344591140747, 1.7216270231619113, 1.7078255531264515, 1.7223766809556542, 1.709995051709617, 1.7219717182764194, 1.7123760101271839, 1.7163444030575636, 1.7096592624013016, 1.7129289580554496, 1.7154307336342045, 1.71001278191078, 1.713798043204517, 1.704654757569476, 1.713744951457512, 1.7125331163406372, 1.7079356792496472, 1.70585245911668, 1.7018658300725424, 1.7122830123436161, 1.7086653651260748, 1.708045622197593, 1.7065181790328607, 1.713012605178647, 1.703014652903487, 1.7170707627040585, 1.70663792912553, 1.69644367113346, 1.6958971575992863, 1.7022231875396356, 1.7112912899110375, 1.7025802775127132, 1.700043311933192, 1.6971043290161505, 1.6991755729768334, 1.7030763684249506, 1.7009474068153194, 1.6980136284014073, 1.6917173978759021, 1.6977739479483627, 1.6969064125200597, 1.694773554801941, 1.6983530579543695, 1.692317700967556, 1.6972368664857818, 1.7003080903030023, 1.6913845510017582, 1.6982930898666382, 1.6924448216833718, 1.700163541770563, 1.6991318813184413, 1.6916341287333791, 1.703212493803443, 1.6889806055441134, 1.6931319556585172, 1.6919998308507407, 1.6914641566392852, 1.6897517704382174, 1.6957694757275465, 1.6885889972128518, 1.6898488620432413, 1.6842421613088467, 1.6925391511219303, 1.697993170924303, 1.6895740206648664, 1.6900525383832978, 1.6849121000708602, 1.685582300511802, 1.6910925318555134, 1.6869137170838147, 1.67931283974066, 1.69307751481126, 1.6865114235296481, 1.6855027646553227, 1.6980561657649715, 1.6863269544229276, 1.6911832646625797, 1.6913022093656587, 1.6886396786061728, 1.6892915091863492, 1.700847212861224, 1.6810202365968285, 1.685937811688679, 1.6887337201979102, 1.6841971321803768, 1.6812856575337851, 1.6739045759526694, 1.6822433180925322, 1.6872013778221318, 1.6831301886860917, 1.684166809407676, 1.6862224195061661, 1.682924823063176, 1.6882973269718449, 1.6842163568589745, 1.6807961289475604, 1.6805723905563354, 1.687125639217656, 1.676259407183019, 1.676835859694132, 1.68472205138788, 1.7000661565036308, 1.6733625022376455, 1.6843289892847946, 1.680716558200557, 1.6811022089748848, 1.6829179205545566, 1.6847149686115543, 1.6769857232163592, 1.6751088456409733, 1.6873532824399995, 1.6798801625647195, 1.6763864086895455, 1.6792601230667858, 1.6866284347162015, 1.6771797319737876, 1.6781349211204342, 1.672009174416705, 1.6773122956113118, 1.6832232155450961, 1.6739222363727848, 1.681495808973545, 1.6773475001497966, 1.6840776205062866, 1.683217993596705, 1.6869944246803843, 1.6845247018628005, 1.686073782967358, 1.6694813966751099, 1.6750081748497196, 1.6817688476748582, 1.6766070534543294, 1.6748405113452818, 1.678202038857995, 1.6694534493655693, 1.681159909178571, 1.6763797765824853, 1.6766168809518582, 1.6843726809431867, 1.6740421405652675, 1.6955260590809147, 1.6877578380631237, 1.6876293420791626, 1.6692729665011894, 1.6778365926044743, 1.6744934291374394, 1.6807502391861706, 1.678826506544904, 1.687057061893184, 1.6788186009337263, 1.676695829484521, 1.6727539475371198, 1.6751474985262242, 1.67141996651161, 1.6758651529870383, 1.6863726581015237, 1.670281759122523, 1.6789185332088936, 1.6748653156001394, 1.6714449801096103, 1.6666674701178945, 1.670606569546025, 1.6666774836982168, 1.6759893865120121, 1.6718821932629842, 1.6695563502428008, 1.6763182093457478, 1.672893884705334, 1.6736923921399, 1.6714079350959965, 1.6712068028566314, 1.6694656726790638, 1.6771544683270339, 1.6826641181620157, 1.67363937598903, 1.672586836465975, 1.6717426427980748, 1.6763534749426492, 1.682624604643845, 1.6648351215734714, 1.6615497339062575, 1.668449119823735, 1.6723741816311348, 1.6744950224713582, 1.6661854924225226, 1.6677031080897262, 1.6640616131991874, 1.6706307137884744, 1.679483596871539, 1.6702863995621844, 1.6636676235896786, 1.665722567860673, 1.669594209368636, 1.66055358037716, 1.6757168246478569, 1.6679443004654675, 1.6623923691307627, 1.6681449791280234, 1.6664194217542323, 1.6731223798379666, 1.6726859517213775, 1.674292587652439, 1.6606541523119298, 1.6652651472789486, 1.6728776635193243, 1.6859393701320742, 1.6610264952589826, 1.6642273373720122, 1.6795593267533837, 1.6686657986989835, 1.6706151467997854, 1.6678984252417959, 1.6731075426427329, 1.6556607484817505, 1.6787108502736905, 1.671672498307577, 1.668165451142846, 1.6690081765012044, 1.6589003248912533, 1.6706546661330433, 1.6642812926594803, 1.6727001754249013, 1.66140967462121, 1.664978440214948, 1.6714294189360084, 1.67433691606289, 1.6602039569761695, 1.6600611384322004, 1.6605653646515637, 1.6705038896421107, 1.657729875750658, 1.6661492760588483, 1.6677361465081937, 1.6701648235321045, 1.6673117701600237, 1.6630529746776674, 1.6663280405649326, 1.6618381680511847, 1.6646332798934564, 1.676231538377157, 1.664717767296768, 1.666214323625332, 1.6659375748983243, 1.6797155781490047, 1.6734191150200077, 1.6734506734987584, 1.6635965137946895, 1.6632273575154746, 1.6689585505462274, 1.65952517346638]
Training accuracy: [0.18297789463433636, 0.18765215697731036, 0.1925211802512416, 0.19865614957639496, 0.1956373551465576, 0.1991430519037881, 0.20001947609309573, 0.20216184633362547, 0.2057649235563346, 0.203330411919369, 0.20508326029798424, 0.2088810984516506, 0.21141299055409485, 0.21170513195053073, 0.21345798032914598, 0.2116077514850521, 0.2147239263803681, 0.21540558963871848, 0.2139448826565391, 0.2182296231375986, 0.2193981887233421, 0.22085889570552147, 0.22183270036030772, 0.2249488752556237, 0.22475411432466647, 0.22592267991040998, 0.23049956178790534, 0.2283571915473756, 0.22855195247833285, 0.23001265946051222, 0.23196026877008472, 0.2330314538903496, 0.23624500925114422, 0.2349790631999221, 0.2357581069237511, 0.2384847599571526, 0.2384847599571526, 0.2392638036809816, 0.24189307624890447, 0.2431590223001266, 0.2458856753335281, 0.24685947998831434, 0.2482228065050151, 0.2478332846431006, 0.25231278605511737, 0.2554289609504333, 0.25289706884798907, 0.25591586327782645, 0.258642516311228, 0.26244035446489433, 0.26321939818872336, 0.2626351153958516, 0.26487486610185995, 0.26662771448047523, 0.2661408121530821, 0.2702307917031843, 0.27256792287467135, 0.27256792287467135, 0.2731522056675431, 0.2740286298568507, 0.27490505404615834, 0.27695004382120947, 0.2758788587009446, 0.2756840977699873, 0.2756840977699873, 0.2761710000973805, 0.27957931638913236, 0.2806505015093972, 0.28045574057843997, 0.2794819359236537, 0.27957931638913236, 0.28191644756061934, 0.28123478430226895, 0.28435095919758496, 0.2826954912844483, 0.28435095919758496, 0.28561690524880706, 0.2844483396630636, 0.28347453500827735, 0.28668809036907195, 0.2855195247833285, 0.2852273833868926, 0.2840588178011491, 0.28698023176550785, 0.2875645145583796, 0.2892199824715162, 0.2872723731619437, 0.289025221540559, 0.2883435582822086, 0.28912260200603757, 0.2907780699191742, 0.2897068847989093, 0.289025221540559, 0.29107021131561006, 0.28863569967864444, 0.29058330898821694, 0.2894147434024735, 0.2927256792287467, 0.28931736293699484, 0.2922387769013536, 0.29194663550491773, 0.29126497224656733, 0.29243353783231085, 0.2892199824715162, 0.2896095043334307, 0.2914597331775246, 0.2949654299347551, 0.29369948388353295, 0.294478527607362, 0.29330996202161846, 0.2951601908657123, 0.2949654299347551, 0.29545233226214823, 0.292920440159704, 0.2984711266919856, 0.2958418541240627, 0.29486804946927647, 0.2951601908657123, 0.2966208978478917, 0.2966208978478917, 0.2962313759859772, 0.29671827831337033, 0.29720518064076346, 0.2993475508812932, 0.2973999415717207, 0.29915278995033595, 0.29954231181225044, 0.29808160483007107, 0.29564709319310545, 0.30002921413964356, 0.2992501704158146, 0.30032135553607947, 0.2993475508812932, 0.29983445320868635, 0.29954231181225044, 0.30032135553607947, 0.30178206251825884, 0.30090563832895123, 0.30002921413964356, 0.3011977797253871, 0.3010030187944298, 0.3036322913623527, 0.3051903788100107, 0.30139254065634435, 0.3011977797253871, 0.3019768234492161, 0.30226896484565197, 0.30372967182783134, 0.30217158438017333, 0.3036322913623527, 0.3048008569480962, 0.3060668029993183, 0.30353491089687407, 0.30840393417080536, 0.3050929983445321, 0.3058720420683611, 0.3078196513779336, 0.3060668029993183, 0.3080144123088908, 0.3073327490505405, 0.3060668029993183, 0.3064563248612328, 0.3080144123088908, 0.3066510857921901, 0.30898821696367706, 0.3083065537053267, 0.30791703184341224, 0.3088908364981985, 0.3114227286006427, 0.30966988022202746, 0.30850131463628394, 0.30879345603271985, 0.3074301295160191, 0.31005940208394195, 0.3086960755672412, 0.3099620216184633, 0.31113058720420683, 0.3099620216184633, 0.3106436848768137, 0.3078196513779336, 0.3128834355828221, 0.3094751192910702, 0.310838445807771, 0.31385724023760836, 0.3121043918589931, 0.31093582627324956, 0.3113253481351641, 0.3113253481351641, 0.31249391372090757, 0.3128834355828221, 0.31268867465186484, 0.3129808160483007, 0.3145389034959587, 0.3160969909436167, 0.31395462070308694, 0.3156100886162236, 0.3152205667543091, 0.3154153276852663, 0.312396533255429, 0.3160969909436167, 0.3143441425650015, 0.3154153276852663, 0.31551270815074495, 0.31668127373648847, 0.3152205667543091, 0.316291751874574, 0.31658389327100983, 0.3154153276852663, 0.3157074690817022, 0.3167786542019671, 0.3160969909436167, 0.3169734151329243, 0.3148310448923946, 0.3192131658389327, 0.3180446002531892, 0.31989482909728306, 0.32145291654494107, 0.3204791118901548, 0.31989482909728306, 0.32077125328659073, 0.3172655565293602, 0.3204791118901548, 0.3219398188723342, 0.3206738728211121, 0.31736293699483886, 0.32008959002824033, 0.31862888304606096, 0.32096601421754795, 0.3215502970104197, 0.3219398188723342, 0.32057649235563346, 0.3215502970104197, 0.32057649235563346, 0.32213457980329147, 0.3211607751485052, 0.3226214821306846, 0.3227188625961632, 0.323303145389035, 0.3227188625961632, 0.32534813516408606, 0.32427695004382123, 0.32291362352712044, 0.3239848086473853, 0.3245690914402571, 0.3234979063199922, 0.3239848086473853, 0.3250559937676502, 0.32213457980329147, 0.32602979842243646, 0.3263219398188723, 0.32486123283669294, 0.32554289609504333, 0.3237900477164281, 0.3246664719057357, 0.3261271788879151, 0.32622455935339373, 0.32680884214626543, 0.3226214821306846, 0.32554289609504333, 0.3266140812153082, 0.3266140812153082, 0.32778264680105174, 0.32622455935339373, 0.32836692959392344, 0.32564027656052197, 0.3285616905248807, 0.3278800272665303, 0.32515337423312884, 0.3273931249391372, 0.3266140812153082, 0.32729574447365856, 0.3285616905248807, 0.32671146168078685, 0.32953549517966696, 0.3259324179569578, 0.32749050540461583, 0.32671146168078685, 0.3258350374914792, 0.3298276365761028, 0.3276852663355731, 0.32885383192131656, 0.32914597331775247, 0.3311909630928036, 0.3298276365761028, 0.3276852663355731, 0.3285616905248807, 0.32914597331775247, 0.32904859285227384, 0.33382023566072644, 0.3315804849547181, 0.33235952867854707, 0.32826954912844486, 0.32826954912844486, 0.3313857240237608, 0.3329438114714188, 0.3335280942642906, 0.3346966598500341, 0.3294381147141883, 0.3327490505404616, 0.3316778654201967]
Validation accuracy: [0.18925233644859812, 0.1939252336448598, 0.19626168224299065, 0.19626168224299065, 0.1954828660436137, 0.20015576323987538, 0.20171339563862928, 0.1923676012461059, 0.19314641744548286, 0.20249221183800623, 0.19937694704049844, 0.19626168224299065, 0.1970404984423676, 0.20794392523364486, 0.20482866043613707, 0.20794392523364486, 0.20327102803738317, 0.205607476635514, 0.2087227414330218, 0.21651090342679127, 0.20327102803738317, 0.20794392523364486, 0.21651090342679127, 0.21495327102803738, 0.20950155763239875, 0.2071651090342679, 0.21105919003115264, 0.20950155763239875, 0.2087227414330218, 0.2118380062305296, 0.21962616822429906, 0.21651090342679127, 0.2118380062305296, 0.21417445482866043, 0.21495327102803738, 0.21806853582554517, 0.2235202492211838, 0.22118380062305296, 0.22585669781931464, 0.22897196261682243, 0.220404984423676, 0.22819314641744548, 0.2266355140186916, 0.22819314641744548, 0.23208722741433022, 0.24143302180685358, 0.23753894080996885, 0.24299065420560748, 0.24454828660436137, 0.24610591900311526, 0.2515576323987539, 0.2507788161993769, 0.2507788161993769, 0.2538940809968847, 0.26479750778816197, 0.2515576323987539, 0.2538940809968847, 0.25778816199376947, 0.2554517133956386, 0.2538940809968847, 0.25, 0.25778816199376947, 0.2570093457943925, 0.2585669781931464, 0.2531152647975078, 0.25934579439252337, 0.2570093457943925, 0.2585669781931464, 0.2562305295950156, 0.2507788161993769, 0.26246105919003115, 0.2562305295950156, 0.2546728971962617, 0.2562305295950156, 0.2570093457943925, 0.2554517133956386, 0.2570093457943925, 0.2554517133956386, 0.25778816199376947, 0.2546728971962617, 0.2601246105919003, 0.25778816199376947, 0.25934579439252337, 0.2570093457943925, 0.2515576323987539, 0.26246105919003115, 0.25934579439252337, 0.2601246105919003, 0.2562305295950156, 0.2546728971962617, 0.26246105919003115, 0.26401869158878505, 0.2585669781931464, 0.2554517133956386, 0.2601246105919003, 0.2538940809968847, 0.26479750778816197, 0.25934579439252337, 0.26791277258566976, 0.2616822429906542, 0.26791277258566976, 0.2562305295950156, 0.2562305295950156, 0.26635514018691586, 0.26246105919003115, 0.26401869158878505, 0.2616822429906542, 0.2616822429906542, 0.25934579439252337, 0.26557632398753894, 0.26401869158878505, 0.26869158878504673, 0.2601246105919003, 0.2632398753894081, 0.2616822429906542, 0.2616822429906542, 0.26635514018691586, 0.2632398753894081, 0.26401869158878505, 0.2601246105919003, 0.26401869158878505, 0.26246105919003115, 0.26401869158878505, 0.27258566978193144, 0.26246105919003115, 0.2632398753894081, 0.2601246105919003, 0.25934579439252337, 0.26246105919003115, 0.26401869158878505, 0.26479750778816197, 0.2601246105919003, 0.26791277258566976, 0.26635514018691586, 0.2632398753894081, 0.26246105919003115, 0.26869158878504673, 0.26713395638629284, 0.2601246105919003, 0.26635514018691586, 0.26869158878504673, 0.2616822429906542, 0.2749221183800623, 0.2616822429906542, 0.26557632398753894, 0.26246105919003115, 0.2554517133956386, 0.2702492211838006, 0.26947040498442365, 0.26557632398753894, 0.2632398753894081, 0.26635514018691586, 0.26479750778816197, 0.26401869158878505, 0.2601246105919003, 0.26713395638629284, 0.2632398753894081, 0.26557632398753894, 0.26713395638629284, 0.2733644859813084, 0.26713395638629284, 0.2811526479750779, 0.26479750778816197, 0.2718068535825545, 0.26791277258566976, 0.27258566978193144, 0.2764797507788162, 0.2772585669781931, 0.26791277258566976, 0.2780373831775701, 0.2733644859813084, 0.2718068535825545, 0.2757009345794392, 0.27258566978193144, 0.2757009345794392, 0.2811526479750779, 0.278816199376947, 0.27102803738317754, 0.2757009345794392, 0.2757009345794392, 0.279595015576324, 0.2757009345794392, 0.2733644859813084, 0.2718068535825545, 0.2764797507788162, 0.2803738317757009, 0.2764797507788162, 0.2757009345794392, 0.2811526479750779, 0.2757009345794392, 0.27414330218068533, 0.26869158878504673, 0.279595015576324, 0.28894080996884736, 0.27258566978193144, 0.27258566978193144, 0.2819314641744548, 0.27102803738317754, 0.2733644859813084, 0.2718068535825545, 0.2834890965732087, 0.2733644859813084, 0.2718068535825545, 0.26557632398753894, 0.2757009345794392, 0.2749221183800623, 0.2764797507788162, 0.2757009345794392, 0.2757009345794392, 0.278816199376947, 0.2780373831775701, 0.27414330218068533, 0.2764797507788162, 0.2803738317757009, 0.2718068535825545, 0.278816199376947, 0.26869158878504673, 0.279595015576324, 0.2757009345794392, 0.2834890965732087, 0.2780373831775701, 0.2780373831775701, 0.2749221183800623, 0.27414330218068533, 0.2757009345794392, 0.279595015576324, 0.2811526479750779, 0.2780373831775701, 0.2749221183800623, 0.2827102803738318, 0.2749221183800623, 0.2757009345794392, 0.27414330218068533, 0.2780373831775701, 0.2718068535825545, 0.27102803738317754, 0.278816199376947, 0.2819314641744548, 0.2733644859813084, 0.2733644859813084, 0.2881619937694704, 0.2780373831775701, 0.2803738317757009, 0.2757009345794392, 0.2757009345794392, 0.2811526479750779, 0.2803738317757009, 0.279595015576324, 0.279595015576324, 0.2772585669781931, 0.2772585669781931, 0.2718068535825545, 0.2764797507788162, 0.26947040498442365, 0.2757009345794392, 0.27258566978193144, 0.2834890965732087, 0.2772585669781931, 0.2764797507788162, 0.279595015576324, 0.28582554517133957, 0.2827102803738318, 0.2780373831775701, 0.2764797507788162, 0.27258566978193144, 0.2764797507788162, 0.2749221183800623, 0.2757009345794392, 0.27414330218068533, 0.2827102803738318, 0.2749221183800623, 0.2764797507788162, 0.2757009345794392, 0.2749221183800623, 0.28582554517133957, 0.2842679127725857, 0.2811526479750779, 0.2780373831775701, 0.27258566978193144, 0.2772585669781931, 0.2772585669781931, 0.2772585669781931, 0.27258566978193144, 0.2757009345794392, 0.2819314641744548, 0.2772585669781931, 0.278816199376947, 0.2803738317757009, 0.2772585669781931, 0.2733644859813084, 0.2819314641744548, 0.279595015576324, 0.2780373831775701, 0.27414330218068533, 0.2819314641744548, 0.2772585669781931, 0.2764797507788162, 0.27258566978193144, 0.2811526479750779, 0.2749221183800623]
Accuracy plot saved at '13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397/accuracy_13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397.png'
Loss plot saved at '13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397/loss_13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397.png'
Checkpoint saved at '13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397/checkpoint_13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397.pth'
Best checkpoint saved at '13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397/best_checkpoint_13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397.pth'
Output logfile saved at 13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397/output_log_13B_Llama_1e-6_300_SimpleLinearHead_1710702231.8470397.txt
