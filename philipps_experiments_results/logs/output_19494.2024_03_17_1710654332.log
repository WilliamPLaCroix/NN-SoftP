
=============
== PyTorch ==
=============

NVIDIA Release 24.01 (build 80741402)
PyTorch Version 2.2.0a0+81ea7a4

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

NOTE: CUDA Forward Compatibility mode ENABLED.
  Using CUDA 12.3 driver version 545.23.08 with kernel driver version 525.85.12.
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

Language Model has hidden_size: 5120
freezing Model... (AutoModel)
Running on device: cuda
Epoch [1/500] took 172.153165102005s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7730096823701234, train accuracy: 0.19739020352517286
Val mean loss: 1.7552053317791079, val accuracy: 0.19470404984423675

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1550 			 1998 			 314
6782 			 2123 			 1383
1294 			 1966 			 243
107 			 1683 			 19
24 			 1657 			 5
512 			 842 			 63
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
132 			 263 			 26
879 			 248 			 168
249 			 251 			 47
7 			 169 			 2
17 			 237 			 7
0 			 116 			 0
Max memory allocated: 13743068672; Memory allocated: 7160672768
Epoch [2/500] took 172.64329266548157s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7442781550119228, train accuracy: 0.21462654591488947
Val mean loss: 1.7491635607510079, val accuracy: 0.21105919003115264

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
1297 			 1998 			 309
7240 			 2123 			 1512
1358 			 1966 			 290
82 			 1683 			 19
292 			 1657 			 74
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
287 			 263 			 66
742 			 248 			 142
218 			 251 			 53
8 			 169 			 1
29 			 237 			 9
0 			 116 			 0
Max memory allocated: 13743068672; Memory allocated: 7211334656
Epoch [3/500] took 172.46937799453735s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7307670238976167, train accuracy: 0.23897166228454572
Val mean loss: 1.7373295818887107, val accuracy: 0.2250778816199377

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2568 			 1998 			 642
5463 			 2123 			 1223
1703 			 1966 			 436
103 			 1683 			 30
432 			 1657 			 123
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
383 			 263 			 101
683 			 248 			 137
171 			 251 			 39
9 			 169 			 1
38 			 237 			 11
0 			 116 			 0
Max memory allocated: 13743068672; Memory allocated: 7229324288
Epoch [4/500] took 172.7016532421112s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7214172651463209, train accuracy: 0.2540656344337326
Val mean loss: 1.7327529104744517, val accuracy: 0.2468847352024922

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3295 			 1998 			 855
4658 			 2123 			 1120
1751 			 1966 			 472
112 			 1683 			 33
453 			 1657 			 129
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 108
672 			 248 			 147
178 			 251 			 43
18 			 169 			 3
51 			 237 			 16
0 			 116 			 0
Max memory allocated: 13743068672; Memory allocated: 7244922880
Epoch [5/500] took 172.82889223098755s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7121207725221865, train accuracy: 0.26244035446489433
Val mean loss: 1.7328534009979992, val accuracy: 0.25

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3158 			 1998 			 834
4110 			 2123 			 1020
2206 			 1966 			 611
198 			 1683 			 56
597 			 1657 			 174
0 			 842 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
541 			 263 			 141
481 			 248 			 109
197 			 251 			 53
11 			 169 			 1
54 			 237 			 17
0 			 116 			 0
Max memory allocated: 13743068672; Memory allocated: 7231847424
Epoch [6/500] took 171.73967289924622s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.7056860270158525, train accuracy: 0.26643295354951796
Val mean loss: 1.7154508741890513, val accuracy: 0.2562305295950156

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3887 			 1998 			 994
3510 			 2123 			 912
2018 			 1966 			 577
213 			 1683 			 68
639 			 1657 			 184
2 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
535 			 263 			 146
419 			 248 			 96
233 			 251 			 62
24 			 169 			 4
73 			 237 			 21
0 			 116 			 0
Max memory allocated: 14153026560; Memory allocated: 7230995456
Epoch [7/500] took 172.81486821174622s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6986169532823414, train accuracy: 0.27451553218424385
Val mean loss: 1.7180324473032138, val accuracy: 0.2538940809968847

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3974 			 1998 			 1035
3268 			 2123 			 881
2153 			 1966 			 640
253 			 1683 			 75
618 			 1657 			 187
3 			 842 			 1
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
539 			 263 			 141
322 			 248 			 74
315 			 251 			 84
34 			 169 			 6
74 			 237 			 21
0 			 116 			 0
Max memory allocated: 14153026560; Memory allocated: 7238523904
Epoch [8/500] took 173.1694700717926s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6935578161310927, train accuracy: 0.2752945759080728
Val mean loss: 1.7109605568211252, val accuracy: 0.2585669781931464

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4026 			 1998 			 1034
2641 			 2123 			 733
2601 			 1966 			 759
288 			 1683 			 102
709 			 1657 			 197
4 			 842 			 2
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
511 			 263 			 140
429 			 248 			 96
209 			 251 			 57
60 			 169 			 13
75 			 237 			 26
0 			 116 			 0
Max memory allocated: 14153026560; Memory allocated: 7240064000
Epoch [9/500] took 172.20017218589783s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6880532581115437, train accuracy: 0.2828902522154056
Val mean loss: 1.7030761212837406, val accuracy: 0.26479750778816197

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4156 			 1998 			 1080
2813 			 2123 			 785
2232 			 1966 			 692
409 			 1683 			 143
651 			 1657 			 201
8 			 842 			 4
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
492 			 263 			 139
368 			 248 			 92
257 			 251 			 69
77 			 169 			 15
90 			 237 			 25
0 			 116 			 0
Max memory allocated: 14153026560; Memory allocated: 7207697408
Epoch [10/500] took 172.89486408233643s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.683397488430653, train accuracy: 0.2855195247833285
Val mean loss: 1.6947608720965501, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4019 			 1998 			 1054
2635 			 2123 			 762
2376 			 1966 			 724
484 			 1683 			 159
736 			 1657 			 219
19 			 842 			 14
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
519 			 263 			 148
345 			 248 			 85
267 			 251 			 74
59 			 169 			 11
94 			 237 			 27
0 			 116 			 0
Max memory allocated: 14153026560; Memory allocated: 7199292416
Epoch [11/500] took 173.6234929561615s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6782646023224448, train accuracy: 0.28931736293699484
Val mean loss: 1.6955249483992414, val accuracy: 0.2570093457943925

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4029 			 1998 			 1061
2547 			 2123 			 733
2474 			 1966 			 758
441 			 1683 			 159
754 			 1657 			 243
24 			 842 			 17
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
499 			 263 			 135
365 			 248 			 90
220 			 251 			 58
98 			 169 			 17
100 			 237 			 29
2 			 116 			 1
Max memory allocated: 14153026560; Memory allocated: 7229783040
Epoch [12/500] took 172.63551878929138s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.674428669834434, train accuracy: 0.2951601908657123
Val mean loss: 1.694917446229516, val accuracy: 0.2632398753894081

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3975 			 1998 			 1058
2742 			 2123 			 801
1957 			 1966 			 642
738 			 1683 			 254
823 			 1657 			 253
34 			 842 			 23
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 263 			 134
280 			 248 			 70
354 			 251 			 100
49 			 169 			 9
96 			 237 			 24
3 			 116 			 1
Max memory allocated: 14153026560; Memory allocated: 7237213184
Epoch [13/500] took 172.77363634109497s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6707998499320675, train accuracy: 0.29369948388353295
Val mean loss: 1.6992407601054123, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4033 			 1998 			 1079
2452 			 2123 			 721
2391 			 1966 			 730
542 			 1683 			 194
812 			 1657 			 267
39 			 842 			 25
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
503 			 263 			 146
280 			 248 			 69
332 			 251 			 95
59 			 169 			 10
105 			 237 			 30
5 			 116 			 2
Max memory allocated: 14153026560; Memory allocated: 7228931072
Epoch [14/500] took 173.48800206184387s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6664332489358302, train accuracy: 0.29808160483007107
Val mean loss: 1.6885271799273607, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 1998 			 1046
2376 			 2123 			 708
2403 			 1966 			 761
699 			 1683 			 251
868 			 1657 			 255
61 			 842 			 40
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
510 			 263 			 146
318 			 248 			 82
284 			 251 			 83
74 			 169 			 14
93 			 237 			 30
5 			 116 			 2
Max memory allocated: 14153026560; Memory allocated: 7231757312
Epoch [15/500] took 172.7771873474121s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6630901194807153, train accuracy: 0.2966208978478917
Val mean loss: 1.6850947781306942, val accuracy: 0.26947040498442365

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4141 			 1998 			 1103
2382 			 2123 			 709
2342 			 1966 			 744
628 			 1683 			 234
723 			 1657 			 222
53 			 842 			 34
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 263 			 142
321 			 248 			 78
256 			 251 			 76
82 			 169 			 14
116 			 237 			 33
5 			 116 			 3
Max memory allocated: 14153026560; Memory allocated: 7141136384
Epoch [16/500] took 171.47707104682922s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.658561799013726, train accuracy: 0.3041191936897458
Val mean loss: 1.694299017510763, val accuracy: 0.2780373831775701

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3901 			 1998 			 1058
2423 			 2123 			 742
2152 			 1966 			 705
799 			 1683 			 297
914 			 1657 			 277
80 			 842 			 44
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
511 			 263 			 146
326 			 248 			 83
276 			 251 			 82
72 			 169 			 15
91 			 237 			 28
8 			 116 			 3
Max memory allocated: 14351809536; Memory allocated: 7205305344
Epoch [17/500] took 172.30515265464783s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6562097648222498, train accuracy: 0.30441133508618173
Val mean loss: 1.6907204942005436, val accuracy: 0.26869158878504673

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3871 			 1998 			 1064
2353 			 2123 			 713
2342 			 1966 			 753
763 			 1683 			 281
859 			 1657 			 264
81 			 842 			 51
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
528 			 263 			 149
329 			 248 			 83
249 			 251 			 71
88 			 169 			 20
77 			 237 			 18
13 			 116 			 4
Max memory allocated: 14351809536; Memory allocated: 7248035840
Epoch [18/500] took 173.37059426307678s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6534875159694398, train accuracy: 0.3050929983445321
Val mean loss: 1.7013307838905147, val accuracy: 0.2718068535825545

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4042 			 1998 			 1099
2379 			 2123 			 712
2171 			 1966 			 712
822 			 1683 			 302
761 			 1657 			 254
94 			 842 			 54
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
507 			 263 			 141
340 			 248 			 91
240 			 251 			 67
82 			 169 			 16
104 			 237 			 30
11 			 116 			 4
Max memory allocated: 14351809536; Memory allocated: 7217830912
Epoch [19/500] took 172.2133538722992s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6501032953321748, train accuracy: 0.3101567825494206
Val mean loss: 1.6895701245563786, val accuracy: 0.278816199376947

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3843 			 1998 			 1075
2405 			 2123 			 738
2292 			 1966 			 751
789 			 1683 			 296
846 			 1657 			 272
94 			 842 			 53
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
521 			 263 			 149
309 			 248 			 82
247 			 251 			 75
91 			 169 			 20
104 			 237 			 27
12 			 116 			 5
Max memory allocated: 14351809536; Memory allocated: 7267696640
Epoch [20/500] took 172.51262617111206s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6476494538078428, train accuracy: 0.31317557697925796
Val mean loss: 1.6797204744525072, val accuracy: 0.27414330218068533

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
4068 			 1998 			 1126
2403 			 2123 			 739
2094 			 1966 			 707
815 			 1683 			 314
781 			 1657 			 268
108 			 842 			 62
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 263 			 133
250 			 248 			 64
315 			 251 			 89
105 			 169 			 22
126 			 237 			 39
14 			 116 			 5
Max memory allocated: 14351809536; Memory allocated: 7235460096
Epoch [21/500] took 172.0280864238739s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6438785048660087, train accuracy: 0.31531794721978773
Val mean loss: 1.682787438718284, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3736 			 1998 			 1052
2243 			 2123 			 699
2396 			 1966 			 786
823 			 1683 			 322
946 			 1657 			 308
125 			 842 			 71
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
513 			 263 			 152
346 			 248 			 93
192 			 251 			 60
139 			 169 			 33
72 			 237 			 21
22 			 116 			 9
Max memory allocated: 14351809536; Memory allocated: 7241317376
Epoch [22/500] took 172.1688358783722s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6412702954818155, train accuracy: 0.31736293699483886
Val mean loss: 1.6802628185690902, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3988 			 1998 			 1120
2261 			 2123 			 724
2175 			 1966 			 721
974 			 1683 			 371
741 			 1657 			 250
130 			 842 			 73
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
454 			 263 			 133
349 			 248 			 91
219 			 251 			 67
121 			 169 			 25
117 			 237 			 34
24 			 116 			 12
Max memory allocated: 14351809536; Memory allocated: 7286374400
Epoch [23/500] took 172.63952445983887s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6398203610631163, train accuracy: 0.3202843509591976
Val mean loss: 1.6764100499269439, val accuracy: 0.2764797507788162

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3945 			 1998 			 1095
2341 			 2123 			 751
2067 			 1966 			 717
991 			 1683 			 374
794 			 1657 			 280
131 			 842 			 72
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 137
340 			 248 			 86
245 			 251 			 74
97 			 169 			 20
105 			 237 			 28
20 			 116 			 10
Max memory allocated: 14351809536; Memory allocated: 7221771264
Epoch [24/500] took 172.37320113182068s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6367044144330367, train accuracy: 0.32125815561398385
Val mean loss: 1.6751870469349186, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3801 			 1998 			 1078
2279 			 2123 			 723
2159 			 1966 			 726
991 			 1683 			 379
886 			 1657 			 314
153 			 842 			 79
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 150
316 			 248 			 82
260 			 251 			 81
96 			 169 			 19
104 			 237 			 30
22 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7187789824
Epoch [25/500] took 172.47140789031982s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6347250284806962, train accuracy: 0.32164767747589834
Val mean loss: 1.6785473707245617, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3868 			 1998 			 1092
2398 			 2123 			 758
2107 			 1966 			 726
949 			 1683 			 368
779 			 1657 			 273
168 			 842 			 86
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 263 			 142
272 			 248 			 74
252 			 251 			 81
120 			 169 			 30
120 			 237 			 32
16 			 116 			 7
Max memory allocated: 14351809536; Memory allocated: 7198669824
Epoch [26/500] took 172.97031998634338s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6319212323037264, train accuracy: 0.3246664719057357
Val mean loss: 1.6675397826404106, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3796 			 1998 			 1097
2160 			 2123 			 710
2341 			 1966 			 781
937 			 1683 			 365
884 			 1657 			 306
151 			 842 			 75
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 263 			 139
330 			 248 			 80
206 			 251 			 67
135 			 169 			 31
103 			 237 			 33
24 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7157725184
Epoch [27/500] took 173.30356287956238s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.630019164902399, train accuracy: 0.3258350374914792
Val mean loss: 1.6861132005365884, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3783 			 1998 			 1087
2331 			 2123 			 744
2127 			 1966 			 736
1048 			 1683 			 402
807 			 1657 			 290
173 			 842 			 87
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
508 			 263 			 149
288 			 248 			 76
238 			 251 			 79
124 			 169 			 30
105 			 237 			 28
21 			 116 			 10
Max memory allocated: 14351809536; Memory allocated: 7189641216
Epoch [28/500] took 172.94111466407776s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.626549649832776, train accuracy: 0.32719836400818
Val mean loss: 1.6688147812354854, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3814 			 1998 			 1092
2177 			 2123 			 704
2036 			 1966 			 715
1163 			 1683 			 444
911 			 1657 			 319
168 			 842 			 86
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 263 			 141
303 			 248 			 79
271 			 251 			 84
94 			 169 			 22
109 			 237 			 31
25 			 116 			 10
Max memory allocated: 14351809536; Memory allocated: 7199079424
Epoch [29/500] took 172.42269897460938s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6239054834359903, train accuracy: 0.3301197779725387
Val mean loss: 1.662739890377696, val accuracy: 0.279595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3722 			 1998 			 1082
2234 			 2123 			 733
2228 			 1966 			 772
997 			 1683 			 396
909 			 1657 			 315
179 			 842 			 92
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 263 			 135
292 			 248 			 75
271 			 251 			 85
103 			 169 			 24
115 			 237 			 29
26 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7191771136
Epoch [30/500] took 172.0546736717224s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6225217075734124, train accuracy: 0.3311909630928036
Val mean loss: 1.6732762877534075, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3684 			 1998 			 1082
2194 			 2123 			 717
2189 			 1966 			 760
1061 			 1683 			 411
958 			 1657 			 330
183 			 842 			 101
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 263 			 145
319 			 248 			 82
242 			 251 			 74
114 			 169 			 27
92 			 237 			 27
27 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7231896576
Epoch [31/500] took 172.43177771568298s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6198429582274962, train accuracy: 0.3320673872821112
Val mean loss: 1.6655101165538881, val accuracy: 0.2811526479750779

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3816 			 1998 			 1097
2275 			 2123 			 748
2145 			 1966 			 760
1021 			 1683 			 406
821 			 1657 			 298
191 			 842 			 101
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 263 			 131
304 			 248 			 77
225 			 251 			 78
143 			 169 			 35
112 			 237 			 29
27 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7266779136
Epoch [32/500] took 172.6604766845703s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6180428623039032, train accuracy: 0.33498880124646996
Val mean loss: 1.6778177720744436, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3767 			 1998 			 1103
2382 			 2123 			 783
1931 			 1966 			 707
1194 			 1683 			 454
793 			 1657 			 288
202 			 842 			 105
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
464 			 263 			 132
270 			 248 			 67
280 			 251 			 87
116 			 169 			 28
125 			 237 			 36
29 			 116 			 10
Max memory allocated: 14351809536; Memory allocated: 7192279040
Epoch [33/500] took 173.0467848777771s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6172189582545438, train accuracy: 0.3354757035738631
Val mean loss: 1.6614237936531626, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3707 			 1998 			 1096
2195 			 2123 			 726
2243 			 1966 			 791
1073 			 1683 			 426
849 			 1657 			 303
202 			 842 			 103
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
500 			 263 			 141
266 			 248 			 68
257 			 251 			 83
111 			 169 			 30
126 			 237 			 34
24 			 116 			 10
Max memory allocated: 14351809536; Memory allocated: 7207435264
Epoch [34/500] took 172.66136050224304s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6137297547123515, train accuracy: 0.3367416496250852
Val mean loss: 1.6550625533592411, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3731 			 1998 			 1092
2131 			 2123 			 716
2161 			 1966 			 773
1110 			 1683 			 437
941 			 1657 			 334
195 			 842 			 106
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
442 			 263 			 128
325 			 248 			 87
246 			 251 			 76
123 			 169 			 31
113 			 237 			 36
35 			 116 			 14
Max memory allocated: 14351809536; Memory allocated: 7217249280
Epoch [35/500] took 172.86472845077515s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.612459998264491, train accuracy: 0.33976044405492256
Val mean loss: 1.6627623017241315, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3606 			 1998 			 1072
2270 			 2123 			 760
2114 			 1966 			 779
1158 			 1683 			 445
901 			 1657 			 314
220 			 842 			 119
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
503 			 263 			 146
292 			 248 			 76
241 			 251 			 77
116 			 169 			 30
103 			 237 			 32
29 			 116 			 13
Max memory allocated: 14351809536; Memory allocated: 7233911808
Epoch [36/500] took 172.08270120620728s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6096509267979322, train accuracy: 0.3382023566072646
Val mean loss: 1.6687202162858916, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3643 			 1998 			 1071
2392 			 2123 			 782
2133 			 1966 			 768
1101 			 1683 			 444
785 			 1657 			 298
215 			 842 			 110
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 263 			 143
303 			 248 			 75
217 			 251 			 71
123 			 169 			 34
116 			 237 			 32
27 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7191590912
Epoch [37/500] took 170.61313319206238s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6070007297480218, train accuracy: 0.34346090174311034
Val mean loss: 1.6736582081492355, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3746 			 1998 			 1099
2170 			 2123 			 744
2080 			 1966 			 772
1174 			 1683 			 478
909 			 1657 			 329
190 			 842 			 105
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 263 			 143
318 			 248 			 89
212 			 251 			 71
126 			 169 			 33
107 			 237 			 32
30 			 116 			 15
Max memory allocated: 14351809536; Memory allocated: 7237614592
Epoch [38/500] took 172.02513670921326s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6059487812987, train accuracy: 0.3414159119680592
Val mean loss: 1.6609510096108042, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3599 			 1998 			 1069
2174 			 2123 			 735
2079 			 1966 			 757
1234 			 1683 			 484
980 			 1657 			 348
203 			 842 			 113
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 263 			 145
352 			 248 			 91
227 			 251 			 73
112 			 169 			 29
71 			 237 			 20
35 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7216315392
Epoch [39/500] took 171.90542340278625s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6040487957892018, train accuracy: 0.34394780407050346
Val mean loss: 1.6617010366625902, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3637 			 1998 			 1090
2411 			 2123 			 801
2130 			 1966 			 778
1132 			 1683 			 454
718 			 1657 			 284
241 			 842 			 125
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
445 			 263 			 127
303 			 248 			 77
235 			 251 			 76
132 			 169 			 33
133 			 237 			 38
36 			 116 			 15
Max memory allocated: 14351809536; Memory allocated: 7154407424
Epoch [40/500] took 171.2788543701172s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.602136438138017, train accuracy: 0.3470639789658195
Val mean loss: 1.6580708143187732, val accuracy: 0.2803738317757009

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3677 			 1998 			 1090
2178 			 2123 			 750
2013 			 1966 			 758
1199 			 1683 			 480
960 			 1657 			 358
242 			 842 			 128
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 263 			 134
262 			 248 			 64
261 			 251 			 88
131 			 169 			 34
94 			 237 			 26
38 			 116 			 14
Max memory allocated: 14351809536; Memory allocated: 7212940288
Epoch [41/500] took 171.6573784351349s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.6001306192897191, train accuracy: 0.3473561203622553
Val mean loss: 1.6729946107399174, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3664 			 1998 			 1106
2134 			 2123 			 732
2136 			 1966 			 794
1206 			 1683 			 481
881 			 1657 			 325
248 			 842 			 129
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
456 			 263 			 133
332 			 248 			 88
226 			 251 			 76
139 			 169 			 40
101 			 237 			 27
30 			 116 			 14
Max memory allocated: 14351809536; Memory allocated: 7203478528
Epoch [42/500] took 171.4769582748413s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5983640167200677, train accuracy: 0.34940111013730646
Val mean loss: 1.6592567868349029, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3664 			 1998 			 1107
2141 			 2123 			 744
2152 			 1966 			 798
1195 			 1683 			 481
891 			 1657 			 335
226 			 842 			 123
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
458 			 263 			 138
358 			 248 			 96
197 			 251 			 67
139 			 169 			 36
97 			 237 			 28
35 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7246610432
Epoch [43/500] took 171.0680525302887s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5966868656817998, train accuracy: 0.35095919758496447
Val mean loss: 1.6599845101193684, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3596 			 1998 			 1086
2344 			 2123 			 796
1988 			 1966 			 767
1233 			 1683 			 495
870 			 1657 			 334
238 			 842 			 126
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
456 			 263 			 132
305 			 248 			 80
265 			 251 			 88
126 			 169 			 35
98 			 237 			 29
34 			 116 			 15
Max memory allocated: 14351809536; Memory allocated: 7191918592
Epoch [44/500] took 170.59976816177368s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.595571133577935, train accuracy: 0.3496932515337423
Val mean loss: 1.6528829539694436, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3588 			 1998 			 1083
2130 			 2123 			 748
2210 			 1966 			 812
1200 			 1683 			 487
908 			 1657 			 334
233 			 842 			 127
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
443 			 263 			 128
328 			 248 			 86
208 			 251 			 69
150 			 169 			 40
117 			 237 			 35
38 			 116 			 15
Max memory allocated: 14351809536; Memory allocated: 7201209344
Epoch [45/500] took 170.54205703735352s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.592607289088478, train accuracy: 0.35417275294575906
Val mean loss: 1.6584869594108769, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3498 			 1998 			 1077
2319 			 2123 			 796
1977 			 1966 			 757
1258 			 1683 			 520
976 			 1657 			 357
241 			 842 			 130
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 263 			 129
321 			 248 			 86
228 			 251 			 74
141 			 169 			 38
92 			 237 			 25
40 			 116 			 14
Max memory allocated: 14351809536; Memory allocated: 7198849024
Epoch [46/500] took 172.75621223449707s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5924607433634013, train accuracy: 0.35018015386113543
Val mean loss: 1.6533316112146146, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3633 			 1998 			 1102
2260 			 2123 			 772
2012 			 1966 			 755
1226 			 1683 			 496
881 			 1657 			 338
257 			 842 			 133
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
435 			 263 			 128
353 			 248 			 95
239 			 251 			 80
127 			 169 			 37
90 			 237 			 28
40 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7157725184
Epoch [47/500] took 170.94837760925293s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5888662423671591, train accuracy: 0.35310156782549423
Val mean loss: 1.6621376014337308, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3602 			 1998 			 1099
2471 			 2123 			 842
2001 			 1966 			 761
1164 			 1683 			 481
777 			 1657 			 305
254 			 842 			 138
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
420 			 263 			 126
258 			 248 			 71
255 			 251 			 86
159 			 169 			 42
152 			 237 			 45
40 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7206484992
Epoch [48/500] took 170.95968317985535s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5878237771839367, train accuracy: 0.3547570357386308
Val mean loss: 1.6574060277241032, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3558 			 1998 			 1088
2176 			 2123 			 761
2102 			 1966 			 794
1252 			 1683 			 504
911 			 1657 			 351
270 			 842 			 145
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
432 			 263 			 122
276 			 248 			 71
243 			 251 			 80
149 			 169 			 38
144 			 237 			 37
40 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7249600512
Epoch [49/500] took 170.6618161201477s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5862274288759797, train accuracy: 0.3589443957542117
Val mean loss: 1.6547771197993582, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3492 			 1998 			 1083
2176 			 2123 			 769
2055 			 1966 			 787
1301 			 1683 			 528
992 			 1657 			 381
253 			 842 			 138
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 263 			 132
289 			 248 			 75
233 			 251 			 76
142 			 169 			 38
123 			 237 			 34
35 			 116 			 13
Max memory allocated: 14351809536; Memory allocated: 7217773568
Epoch [50/500] took 171.16378664970398s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5843055615915316, train accuracy: 0.35612036225533156
Val mean loss: 1.6627381225911582, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3605 			 1998 			 1103
2097 			 2123 			 755
2118 			 1966 			 804
1240 			 1683 			 506
943 			 1657 			 352
266 			 842 			 137
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
450 			 263 			 137
332 			 248 			 86
222 			 251 			 72
137 			 169 			 39
109 			 237 			 32
34 			 116 			 15
Max memory allocated: 14351809536; Memory allocated: 7209073664
Epoch [51/500] took 171.20893239974976s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.583284383250917, train accuracy: 0.35991820040899797
Val mean loss: 1.6561030643742258, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3507 			 1998 			 1100
2329 			 2123 			 808
1969 			 1966 			 762
1264 			 1683 			 525
949 			 1657 			 362
251 			 842 			 139
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
428 			 263 			 123
286 			 248 			 81
254 			 251 			 83
166 			 169 			 44
105 			 237 			 31
45 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7189575680
Epoch [52/500] took 171.02140402793884s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5817101269124825, train accuracy: 0.3608920050637842
Val mean loss: 1.6492474050056645, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3543 			 1998 			 1099
2182 			 2123 			 779
2153 			 1966 			 822
1253 			 1683 			 518
880 			 1657 			 348
258 			 842 			 140
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
446 			 263 			 127
288 			 248 			 79
232 			 251 			 76
153 			 169 			 42
128 			 237 			 38
37 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7186610176
Epoch [53/500] took 171.3662965297699s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5803150811299356, train accuracy: 0.3628396143733567
Val mean loss: 1.6602886857056036, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3474 			 1998 			 1096
2253 			 2123 			 800
1999 			 1966 			 778
1299 			 1683 			 531
970 			 1657 			 377
274 			 842 			 144
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 263 			 130
274 			 248 			 74
261 			 251 			 90
133 			 169 			 38
106 			 237 			 31
43 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7187789824
Epoch [54/500] took 170.06714534759521s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5770835130014151, train accuracy: 0.3632291362352712
Val mean loss: 1.6456808346073801, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3599 			 1998 			 1122
2116 			 2123 			 766
2151 			 1966 			 818
1238 			 1683 			 521
881 			 1657 			 350
284 			 842 			 153
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
412 			 263 			 119
313 			 248 			 83
238 			 251 			 77
147 			 169 			 40
133 			 237 			 36
41 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7198914560
Epoch [55/500] took 170.93392777442932s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.575850249822266, train accuracy: 0.3602103418054338
Val mean loss: 1.6579489853323959, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3503 			 1998 			 1106
2195 			 2123 			 768
2032 			 1966 			 776
1321 			 1683 			 541
937 			 1657 			 357
281 			 842 			 151
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
437 			 263 			 130
296 			 248 			 81
255 			 251 			 85
135 			 169 			 39
124 			 237 			 35
37 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7196620800
Epoch [56/500] took 171.24498867988586s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.575376225780475, train accuracy: 0.36488460414840784
Val mean loss: 1.6575419234066475, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3450 			 1998 			 1080
2318 			 2123 			 824
2069 			 1966 			 797
1213 			 1683 			 522
942 			 1657 			 374
277 			 842 			 150
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
466 			 263 			 133
261 			 248 			 71
254 			 251 			 87
152 			 169 			 43
113 			 237 			 29
38 			 116 			 14
Max memory allocated: 14351809536; Memory allocated: 7206321152
Epoch [57/500] took 171.61344194412231s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5741865724046653, train accuracy: 0.36576102833771545
Val mean loss: 1.6658092330141765, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3541 			 1998 			 1107
2085 			 2123 			 777
2096 			 1966 			 806
1343 			 1683 			 554
950 			 1657 			 372
254 			 842 			 140
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
446 			 263 			 125
311 			 248 			 86
239 			 251 			 80
134 			 169 			 37
114 			 237 			 35
40 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7208991744
Epoch [58/500] took 171.39541935920715s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.572476695631152, train accuracy: 0.3659557892686727
Val mean loss: 1.65528500370863, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3560 			 1998 			 1129
2160 			 2123 			 780
2069 			 1966 			 802
1200 			 1683 			 505
986 			 1657 			 385
294 			 842 			 157
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
412 			 263 			 122
312 			 248 			 84
250 			 251 			 83
153 			 169 			 43
114 			 237 			 31
43 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7317726208
Epoch [59/500] took 170.06538653373718s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.569545586161153, train accuracy: 0.36731911578537346
Val mean loss: 1.6590855586819533, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3392 			 1998 			 1077
2318 			 2123 			 829
2143 			 1966 			 830
1322 			 1683 			 547
810 			 1657 			 335
284 			 842 			 154
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
427 			 263 			 121
281 			 248 			 74
246 			 251 			 80
153 			 169 			 41
137 			 237 			 41
40 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7200996352
Epoch [60/500] took 170.46610307693481s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5696351383334008, train accuracy: 0.3704352906806895
Val mean loss: 1.6451991273135673, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3387 			 1998 			 1089
2263 			 2123 			 815
1975 			 1966 			 784
1360 			 1683 			 576
1001 			 1657 			 387
283 			 842 			 153
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
428 			 263 			 127
294 			 248 			 82
258 			 251 			 86
147 			 169 			 43
115 			 237 			 34
42 			 116 			 15
Max memory allocated: 14351809536; Memory allocated: 7228079104
Epoch [61/500] took 170.63163876533508s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5662918800134153, train accuracy: 0.3690719641639887
Val mean loss: 1.6454759778046026, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3492 			 1998 			 1101
2184 			 2123 			 806
2155 			 1966 			 845
1268 			 1683 			 531
873 			 1657 			 351
297 			 842 			 156
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
454 			 263 			 127
255 			 248 			 73
254 			 251 			 85
152 			 169 			 43
130 			 237 			 40
39 			 116 			 11
Max memory allocated: 14351809536; Memory allocated: 7256358912
Epoch [62/500] took 170.74399828910828s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.566246573056016, train accuracy: 0.3717012367319116
Val mean loss: 1.658507501206747, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3477 			 1998 			 1107
2121 			 2123 			 787
2102 			 1966 			 823
1313 			 1683 			 560
960 			 1657 			 377
296 			 842 			 163
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
431 			 263 			 127
315 			 248 			 82
216 			 251 			 72
161 			 169 			 44
120 			 237 			 36
41 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7190304768
Epoch [63/500] took 171.48401927947998s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5647528401787778, train accuracy: 0.37004576881877493
Val mean loss: 1.6533924835484202, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3432 			 1998 			 1098
2244 			 2123 			 804
2027 			 1966 			 802
1315 			 1683 			 549
972 			 1657 			 390
279 			 842 			 157
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
435 			 263 			 131
306 			 248 			 80
225 			 251 			 75
162 			 169 			 46
114 			 237 			 33
42 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7246348288
Epoch [64/500] took 171.11354875564575s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5636646929559679, train accuracy: 0.37199337812834743
Val mean loss: 1.6512267822172584, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3410 			 1998 			 1095
2133 			 2123 			 781
2085 			 1966 			 818
1400 			 1683 			 581
943 			 1657 			 382
298 			 842 			 163
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
423 			 263 			 124
330 			 248 			 91
218 			 251 			 74
144 			 169 			 41
123 			 237 			 40
46 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7346537472
Epoch [65/500] took 171.29941415786743s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.562068739041361, train accuracy: 0.37618073814392833
Val mean loss: 1.649469000537221, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3436 			 1998 			 1129
2261 			 2123 			 818
1983 			 1966 			 800
1334 			 1683 			 567
956 			 1657 			 382
299 			 842 			 167
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
437 			 263 			 126
287 			 248 			 81
257 			 251 			 86
141 			 169 			 42
120 			 237 			 32
42 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7184824320
Epoch [66/500] took 170.20354676246643s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5596810802121028, train accuracy: 0.3765702600058428
Val mean loss: 1.653275076935931, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3464 			 1998 			 1126
2120 			 2123 			 798
2165 			 1966 			 850
1298 			 1683 			 556
915 			 1657 			 372
307 			 842 			 165
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
445 			 263 			 127
282 			 248 			 76
232 			 251 			 77
155 			 169 			 45
130 			 237 			 39
40 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7227866112
Epoch [67/500] took 170.81707954406738s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.55836134796202, train accuracy: 0.37666764047132145
Val mean loss: 1.6483620405197144, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3421 			 1998 			 1109
2171 			 2123 			 814
1978 			 1966 			 793
1379 			 1683 			 591
1028 			 1657 			 399
292 			 842 			 162
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
407 			 263 			 118
271 			 248 			 77
263 			 251 			 86
162 			 169 			 44
142 			 237 			 42
39 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7189772288
Epoch [68/500] took 171.29363775253296s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5580561112763354, train accuracy: 0.37783620605706497
Val mean loss: 1.6426729254606294, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3333 			 1998 			 1087
2079 			 2123 			 782
2199 			 1966 			 866
1329 			 1683 			 566
1014 			 1657 			 409
315 			 842 			 170
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
434 			 263 			 127
304 			 248 			 85
233 			 251 			 77
156 			 169 			 46
113 			 237 			 36
44 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7207943168
Epoch [69/500] took 171.01679515838623s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5565854485532575, train accuracy: 0.38095238095238093
Val mean loss: 1.6640818409803437, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3381 			 1998 			 1109
2154 			 2123 			 809
2064 			 1966 			 835
1342 			 1683 			 576
1023 			 1657 			 407
305 			 842 			 176
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
450 			 263 			 126
306 			 248 			 80
244 			 251 			 81
142 			 169 			 41
94 			 237 			 29
48 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7207369728
Epoch [70/500] took 171.03909468650818s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5551500442986177, train accuracy: 0.3811471418833382
Val mean loss: 1.6482478409278682, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3474 			 1998 			 1141
2279 			 2123 			 849
1994 			 1966 			 804
1386 			 1683 			 588
841 			 1657 			 369
295 			 842 			 163
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
413 			 263 			 120
283 			 248 			 84
251 			 251 			 85
141 			 169 			 42
150 			 237 			 45
46 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7198145536
Epoch [71/500] took 171.0280725955963s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5523071029104547, train accuracy: 0.3826078488655176
Val mean loss: 1.6532214182179148, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3354 			 1998 			 1098
2143 			 2123 			 820
2067 			 1966 			 847
1329 			 1683 			 564
1059 			 1657 			 428
317 			 842 			 172
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
440 			 263 			 126
299 			 248 			 85
254 			 251 			 84
138 			 169 			 41
110 			 237 			 31
43 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7211695104
Epoch [72/500] took 171.45483589172363s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5530313721327025, train accuracy: 0.3823157074690817
Val mean loss: 1.6452187299728394, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3431 			 1998 			 1131
2218 			 2123 			 834
2073 			 1966 			 836
1333 			 1683 			 574
932 			 1657 			 394
282 			 842 			 157
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
433 			 263 			 125
290 			 248 			 85
248 			 251 			 81
144 			 169 			 44
124 			 237 			 41
45 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7206583296
Epoch [73/500] took 170.9931082725525s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5504647705042474, train accuracy: 0.3816340442107313
Val mean loss: 1.6488236276114858, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3410 			 1998 			 1125
2182 			 2123 			 820
2054 			 1966 			 823
1325 			 1683 			 573
989 			 1657 			 403
309 			 842 			 175
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
431 			 263 			 124
277 			 248 			 80
251 			 251 			 85
157 			 169 			 45
123 			 237 			 37
45 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7232871424
Epoch [74/500] took 171.49325680732727s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5494029997293823, train accuracy: 0.38757425260492745
Val mean loss: 1.649211363094609, val accuracy: 0.3060747663551402

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3297 			 1998 			 1111
2039 			 2123 			 787
2125 			 1966 			 849
1384 			 1683 			 595
1118 			 1657 			 468
306 			 842 			 170
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
443 			 263 			 127
322 			 248 			 92
236 			 251 			 80
150 			 169 			 45
86 			 237 			 30
47 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7219543040
Epoch [75/500] took 170.66282320022583s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5475811482961304, train accuracy: 0.3872821112084916
Val mean loss: 1.6515488217516643, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3273 			 1998 			 1094
2387 			 2123 			 898
1965 			 1966 			 817
1374 			 1683 			 599
940 			 1657 			 396
330 			 842 			 173
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
469 			 263 			 136
270 			 248 			 78
246 			 251 			 83
158 			 169 			 46
98 			 237 			 32
43 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7234649088
Epoch [76/500] took 170.68079686164856s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5470558843137319, train accuracy: 0.38406855584769695
Val mean loss: 1.6416862563389103, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3399 			 1998 			 1120
2154 			 2123 			 824
2147 			 1966 			 861
1332 			 1683 			 585
926 			 1657 			 384
311 			 842 			 170
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
449 			 263 			 132
277 			 248 			 81
235 			 251 			 80
157 			 169 			 46
119 			 237 			 36
47 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7188985856
Epoch [77/500] took 170.91123938560486s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5447926168501191, train accuracy: 0.38932710098354273
Val mean loss: 1.652675869988232, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3315 			 1998 			 1127
2220 			 2123 			 838
2078 			 1966 			 846
1345 			 1683 			 589
993 			 1657 			 420
318 			 842 			 178
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 263 			 131
250 			 248 			 69
242 			 251 			 80
164 			 169 			 46
112 			 237 			 38
44 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7198817280
Epoch [78/500] took 171.24409937858582s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5453196192084815, train accuracy: 0.3876716330704061
Val mean loss: 1.6561515941852476, val accuracy: 0.3099688473520249

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3446 			 1998 			 1151
2062 			 2123 			 799
2111 			 1966 			 849
1390 			 1683 			 609
952 			 1657 			 402
308 			 842 			 171
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
449 			 263 			 139
280 			 248 			 81
228 			 251 			 80
169 			 169 			 46
119 			 237 			 36
39 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7213628416
Epoch [79/500] took 171.40722107887268s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5439454684747713, train accuracy: 0.3880611549323206
Val mean loss: 1.6436767636275873, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3427 			 1998 			 1147
2070 			 2123 			 807
2036 			 1966 			 829
1384 			 1683 			 602
1049 			 1657 			 432
303 			 842 			 168
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
409 			 263 			 121
333 			 248 			 94
233 			 251 			 78
157 			 169 			 46
106 			 237 			 36
46 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7212792832
Epoch [80/500] took 170.83636689186096s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5414474389263402, train accuracy: 0.3874768721394488
Val mean loss: 1.6643134210167863, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3368 			 1998 			 1125
2282 			 2123 			 859
2013 			 1966 			 826
1381 			 1683 			 600
903 			 1657 			 391
322 			 842 			 178
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
421 			 263 			 121
276 			 248 			 77
266 			 251 			 88
147 			 169 			 41
124 			 237 			 39
50 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7192229888
Epoch [81/500] took 171.56352353096008s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.540087785676261, train accuracy: 0.3889375791216282
Val mean loss: 1.6553693108442353, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3215 			 1998 			 1094
2183 			 2123 			 836
2167 			 1966 			 865
1356 			 1683 			 591
1024 			 1657 			 427
324 			 842 			 181
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
448 			 263 			 124
284 			 248 			 81
236 			 251 			 81
156 			 169 			 46
118 			 237 			 36
42 			 116 			 16
Max memory allocated: 14351809536; Memory allocated: 7219002368
Epoch [82/500] took 171.51078391075134s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5394624159714887, train accuracy: 0.3890349595871068
Val mean loss: 1.6390189135946878, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3400 			 1998 			 1146
2161 			 2123 			 832
2075 			 1966 			 846
1309 			 1683 			 582
1015 			 1657 			 412
309 			 842 			 177
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
435 			 263 			 129
281 			 248 			 79
225 			 251 			 77
179 			 169 			 50
119 			 237 			 38
45 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7191779328
Epoch [83/500] took 171.74027729034424s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5390136969795107, train accuracy: 0.38932710098354273
Val mean loss: 1.6529440967048086, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3327 			 1998 			 1107
2166 			 2123 			 843
2063 			 1966 			 846
1397 			 1683 			 606
988 			 1657 			 417
328 			 842 			 179
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
413 			 263 			 118
279 			 248 			 78
242 			 251 			 81
177 			 169 			 49
127 			 237 			 44
46 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7192377344
Epoch [84/500] took 171.62545728683472s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.536643330553239, train accuracy: 0.3925406563443373
Val mean loss: 1.6533590177210367, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3354 			 1998 			 1140
2179 			 2123 			 844
1961 			 1966 			 817
1444 			 1683 			 618
1007 			 1657 			 424
324 			 842 			 188
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
422 			 263 			 121
271 			 248 			 77
248 			 251 			 84
170 			 169 			 47
126 			 237 			 43
47 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7191214080
Epoch [85/500] took 171.11199116706848s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5364331363517547, train accuracy: 0.39195637355146556
Val mean loss: 1.6561538649768364, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3279 			 1998 			 1104
2054 			 2123 			 808
2107 			 1966 			 858
1409 			 1683 			 613
1079 			 1657 			 445
341 			 842 			 197
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
445 			 263 			 130
292 			 248 			 83
252 			 251 			 85
149 			 169 			 44
100 			 237 			 35
46 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7196817408
Epoch [86/500] took 171.08317375183105s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5347836975739382, train accuracy: 0.39341708053364494
Val mean loss: 1.6532825783985416, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3289 			 1998 			 1126
2152 			 2123 			 845
2072 			 1966 			 856
1377 			 1683 			 604
1056 			 1657 			 427
323 			 842 			 182
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
443 			 263 			 132
308 			 248 			 84
247 			 251 			 82
154 			 169 			 45
88 			 237 			 30
44 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7192238080
Epoch [87/500] took 171.06487131118774s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.534781814364258, train accuracy: 0.3951699289122602
Val mean loss: 1.6501336330320777, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3465 			 1998 			 1173
2143 			 2123 			 834
2074 			 1966 			 862
1340 			 1683 			 591
924 			 1657 			 409
323 			 842 			 189
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
396 			 263 			 121
297 			 248 			 85
260 			 251 			 86
157 			 169 			 44
121 			 237 			 39
53 			 116 			 21
Max memory allocated: 14351809536; Memory allocated: 7214283776
Epoch [88/500] took 171.73137092590332s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5334911918343042, train accuracy: 0.39565683123965334
Val mean loss: 1.6451379177046985, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3277 			 1998 			 1126
2216 			 2123 			 865
2054 			 1966 			 847
1402 			 1683 			 615
975 			 1657 			 412
345 			 842 			 198
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
420 			 263 			 121
263 			 248 			 75
277 			 251 			 92
149 			 169 			 43
128 			 237 			 38
47 			 116 			 21
Max memory allocated: 14351809536; Memory allocated: 7198473216
Epoch [89/500] took 170.589173078537s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.529887145924791, train accuracy: 0.3971175382218327
Val mean loss: 1.6368967788975413, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3348 			 1998 			 1136
2048 			 2123 			 827
2106 			 1966 			 872
1376 			 1683 			 606
1068 			 1657 			 452
323 			 842 			 185
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
409 			 263 			 121
308 			 248 			 87
245 			 251 			 84
165 			 169 			 46
107 			 237 			 34
50 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7250411520
Epoch [90/500] took 171.607488155365s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.529521448589931, train accuracy: 0.3973122991527899
Val mean loss: 1.6461906171426541, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3318 			 1998 			 1132
2171 			 2123 			 852
2077 			 1966 			 863
1405 			 1683 			 622
977 			 1657 			 425
321 			 842 			 186
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
422 			 263 			 124
312 			 248 			 87
238 			 251 			 82
153 			 169 			 43
113 			 237 			 37
46 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7216995328
Epoch [91/500] took 171.99854350090027s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5287690155231322, train accuracy: 0.3981887233420976
Val mean loss: 1.6425682335365108, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3268 			 1998 			 1132
2200 			 2123 			 860
2128 			 1966 			 885
1330 			 1683 			 589
1004 			 1657 			 431
339 			 842 			 192
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
440 			 263 			 123
277 			 248 			 78
233 			 251 			 78
160 			 169 			 48
126 			 237 			 40
48 			 116 			 17
Max memory allocated: 14351809536; Memory allocated: 7211301888
Epoch [92/500] took 173.18207836151123s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.527709670898699, train accuracy: 0.3997468107897556
Val mean loss: 1.644905776512332, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3275 			 1998 			 1124
2128 			 2123 			 854
2052 			 1966 			 851
1420 			 1683 			 623
1052 			 1657 			 449
342 			 842 			 204
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
418 			 263 			 121
283 			 248 			 81
249 			 251 			 85
150 			 169 			 44
131 			 237 			 40
53 			 116 			 24
Max memory allocated: 14351809536; Memory allocated: 7231978496
Epoch [93/500] took 172.67644238471985s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5260901818765658, train accuracy: 0.3992599084623624
Val mean loss: 1.6547193294618188, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3359 			 1998 			 1154
2146 			 2123 			 851
2079 			 1966 			 873
1361 			 1683 			 604
991 			 1657 			 427
333 			 842 			 191
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
416 			 263 			 122
265 			 248 			 76
243 			 251 			 83
172 			 169 			 47
139 			 237 			 46
49 			 116 			 21
Max memory allocated: 14351809536; Memory allocated: 7216757760
Epoch [94/500] took 172.52044081687927s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5254247522799769, train accuracy: 0.4024734638231571
Val mean loss: 1.6453296004272089, val accuracy: 0.309190031152648

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3169 			 1998 			 1096
2154 			 2123 			 870
2134 			 1966 			 891
1414 			 1683 			 622
1055 			 1657 			 460
343 			 842 			 194
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
429 			 263 			 128
288 			 248 			 85
229 			 251 			 78
179 			 169 			 48
115 			 237 			 39
44 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7200160768
Epoch [95/500] took 172.75617742538452s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5239865341661876, train accuracy: 0.40042847404810594
Val mean loss: 1.6439967155456543, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3370 			 1998 			 1149
2112 			 2123 			 846
1989 			 1966 			 841
1471 			 1683 			 646
981 			 1657 			 434
346 			 842 			 196
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
418 			 263 			 118
287 			 248 			 79
255 			 251 			 87
150 			 169 			 43
125 			 237 			 40
49 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7190394880
Epoch [96/500] took 172.1810703277588s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5222169197979747, train accuracy: 0.4014022787028922
Val mean loss: 1.6391595311281157, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3222 			 1998 			 1120
2199 			 2123 			 872
2171 			 1966 			 896
1348 			 1683 			 603
994 			 1657 			 432
335 			 842 			 199
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
408 			 263 			 120
291 			 248 			 85
240 			 251 			 82
171 			 169 			 47
123 			 237 			 39
51 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7248191488
Epoch [97/500] took 172.96716976165771s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5225376689174093, train accuracy: 0.4060765410458662
Val mean loss: 1.6416381510292613, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3189 			 1998 			 1116
2095 			 2123 			 853
2156 			 1966 			 905
1409 			 1683 			 631
1061 			 1657 			 466
359 			 842 			 199
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
416 			 263 			 121
310 			 248 			 86
209 			 251 			 73
171 			 169 			 47
130 			 237 			 42
48 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7188797440
Epoch [98/500] took 172.22005105018616s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5198870971566791, train accuracy: 0.4047132145291655
Val mean loss: 1.6424484020326195, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3240 			 1998 			 1127
2207 			 2123 			 881
2028 			 1966 			 855
1423 			 1683 			 637
1026 			 1657 			 454
345 			 842 			 202
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
441 			 263 			 130
267 			 248 			 77
254 			 251 			 86
148 			 169 			 43
128 			 237 			 40
46 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7222574080
Epoch [99/500] took 172.7546546459198s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5206998653500994, train accuracy: 0.4038367903398578
Val mean loss: 1.6425359278190426, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3289 			 1998 			 1147
2134 			 2123 			 854
2057 			 1966 			 873
1384 			 1683 			 622
1058 			 1657 			 447
347 			 842 			 204
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
428 			 263 			 123
261 			 248 			 73
265 			 251 			 90
165 			 169 			 45
116 			 237 			 38
49 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7208598528
Epoch [100/500] took 173.36303067207336s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5201473878551495, train accuracy: 0.4068555847696952
Val mean loss: 1.6383753549761888, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3226 			 1998 			 1132
2122 			 2123 			 862
2145 			 1966 			 906
1430 			 1683 			 640
989 			 1657 			 430
357 			 842 			 208
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
424 			 263 			 128
276 			 248 			 75
249 			 251 			 84
153 			 169 			 44
133 			 237 			 41
49 			 116 			 23
Max memory allocated: 14351809536; Memory allocated: 7222393856
Epoch [101/500] took 172.94829654693604s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5173388519019724, train accuracy: 0.4068555847696952
Val mean loss: 1.6448764103214915, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3306 			 1998 			 1157
2182 			 2123 			 874
2053 			 1966 			 871
1387 			 1683 			 629
995 			 1657 			 439
346 			 842 			 208
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
426 			 263 			 116
271 			 248 			 79
243 			 251 			 78
165 			 169 			 47
130 			 237 			 43
49 			 116 			 19
Max memory allocated: 14351809536; Memory allocated: 7210515456
Epoch [102/500] took 172.59753131866455s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5166653754926545, train accuracy: 0.40782938942448144
Val mean loss: 1.6532418175441463, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3308 			 1998 			 1150
2028 			 2123 			 840
2118 			 1966 			 897
1407 			 1683 			 635
1058 			 1657 			 457
350 			 842 			 209
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
385 			 263 			 108
294 			 248 			 85
244 			 251 			 80
166 			 169 			 45
144 			 237 			 42
51 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7193671680
Epoch [103/500] took 172.481609582901s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5133161199427096, train accuracy: 0.4117246080436264
Val mean loss: 1.6436462518645496, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3169 			 1998 			 1137
2146 			 2123 			 872
2105 			 1966 			 901
1422 			 1683 			 638
1079 			 1657 			 472
348 			 842 			 208
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
401 			 263 			 115
275 			 248 			 77
245 			 251 			 82
165 			 169 			 47
143 			 237 			 46
55 			 116 			 25
Max memory allocated: 14351809536; Memory allocated: 7198096384
Epoch [104/500] took 172.69458937644958s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.513686245104234, train accuracy: 0.4129905540948486
Val mean loss: 1.6424616313562161, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3136 			 1998 			 1120
2169 			 2123 			 882
2043 			 1966 			 883
1452 			 1683 			 649
1110 			 1657 			 499
359 			 842 			 208
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
424 			 263 			 125
256 			 248 			 74
250 			 251 			 83
161 			 169 			 46
140 			 237 			 43
53 			 116 			 25
Max memory allocated: 14351809536; Memory allocated: 7207042048
Epoch [105/500] took 172.78664422035217s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5127469278941645, train accuracy: 0.4112377057162333
Val mean loss: 1.6469449677118442, val accuracy: 0.31386292834890966

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3307 			 1998 			 1157
2107 			 2123 			 860
2087 			 1966 			 900
1384 			 1683 			 626
1036 			 1657 			 471
348 			 842 			 209
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 121
280 			 248 			 83
242 			 251 			 83
172 			 169 			 47
134 			 237 			 44
56 			 116 			 25
Max memory allocated: 14351809536; Memory allocated: 7213980672
Epoch [106/500] took 172.2446300983429s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5116074530877799, train accuracy: 0.40860843314831047
Val mean loss: 1.642949616036764, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3211 			 1998 			 1127
2137 			 2123 			 878
2147 			 1966 			 904
1396 			 1683 			 627
984 			 1657 			 440
394 			 842 			 220
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
412 			 263 			 116
261 			 248 			 72
227 			 251 			 77
185 			 169 			 49
150 			 237 			 45
49 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7187019776
Epoch [107/500] took 172.88922786712646s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5100172420157079, train accuracy: 0.4127957931638913
Val mean loss: 1.6336247688386498, val accuracy: 0.31230529595015577

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3155 			 1998 			 1120
2123 			 2123 			 874
1971 			 1966 			 860
1502 			 1683 			 670
1182 			 1657 			 507
336 			 842 			 208
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
450 			 263 			 132
276 			 248 			 80
252 			 251 			 86
150 			 169 			 45
108 			 237 			 40
48 			 116 			 18
Max memory allocated: 14351809536; Memory allocated: 7212399616
Epoch [108/500] took 173.08492493629456s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.509394422127079, train accuracy: 0.4101665205959685
Val mean loss: 1.6448374608667886, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3224 			 1998 			 1135
2195 			 2123 			 890
2169 			 1966 			 916
1378 			 1683 			 628
950 			 1657 			 432
353 			 842 			 211
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
432 			 263 			 124
247 			 248 			 70
237 			 251 			 81
171 			 169 			 46
144 			 237 			 44
53 			 116 			 20
Max memory allocated: 14351809536; Memory allocated: 7198604288
Epoch [109/500] took 173.4076442718506s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.508238538774746, train accuracy: 0.4142565001460707
Val mean loss: 1.6508867130046938, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3216 			 1998 			 1140
2144 			 2123 			 887
2120 			 1966 			 908
1368 			 1683 			 638
1051 			 1657 			 467
370 			 842 			 214
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
423 			 263 			 119
265 			 248 			 72
232 			 251 			 80
178 			 169 			 48
139 			 237 			 44
47 			 116 			 21
Max memory allocated: 14351809536; Memory allocated: 7209139200
Epoch [110/500] took 172.47682571411133s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5072604139274526, train accuracy: 0.4142565001460707
Val mean loss: 1.6589059800636479, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3220 			 1998 			 1146
2016 			 2123 			 835
2153 			 1966 			 927
1408 			 1683 			 642
1100 			 1657 			 484
372 			 842 			 220
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 114
277 			 248 			 77
230 			 251 			 81
187 			 169 			 50
135 			 237 			 39
55 			 116 			 23
Max memory allocated: 14351809536; Memory allocated: 7202241536
Epoch [111/500] took 172.54901432991028s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5064960770146498, train accuracy: 0.41484078293894244
Val mean loss: 1.6482315296080055, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3152 			 1998 			 1139
2184 			 2123 			 896
2018 			 1966 			 871
1464 			 1683 			 661
1101 			 1657 			 486
350 			 842 			 207
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
425 			 263 			 123
286 			 248 			 81
229 			 251 			 78
171 			 169 			 47
119 			 237 			 42
54 			 116 			 21
Max memory allocated: 14351809536; Memory allocated: 7204977664
Epoch [112/500] took 172.82838439941406s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5047750955801515, train accuracy: 0.41678839224851494
Val mean loss: 1.6398219044615583, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3246 			 1998 			 1152
2038 			 2123 			 867
2138 			 1966 			 917
1416 			 1683 			 650
1064 			 1657 			 477
367 			 842 			 217
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
398 			 263 			 116
318 			 248 			 90
218 			 251 			 74
168 			 169 			 48
125 			 237 			 38
57 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7198735360
Epoch [113/500] took 172.8582148551941s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.505200648604895, train accuracy: 0.4158145875937287
Val mean loss: 1.6657655064652606, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3175 			 1998 			 1142
2245 			 2123 			 910
2029 			 1966 			 887
1422 			 1683 			 647
1037 			 1657 			 469
361 			 842 			 215
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
428 			 263 			 124
276 			 248 			 80
236 			 251 			 82
168 			 169 			 47
122 			 237 			 39
54 			 116 			 23
Max memory allocated: 14351809536; Memory allocated: 7199177728
Epoch [114/500] took 172.65471124649048s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5033292777813112, train accuracy: 0.41795695783425846
Val mean loss: 1.6336010839880966, val accuracy: 0.3029595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3267 			 1998 			 1175
1970 			 2123 			 837
2129 			 1966 			 913
1475 			 1683 			 666
1073 			 1657 			 487
355 			 842 			 214
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
388 			 263 			 110
322 			 248 			 89
236 			 251 			 84
163 			 169 			 48
121 			 237 			 35
54 			 116 			 23
Max memory allocated: 14351809536; Memory allocated: 7191115776
Epoch [115/500] took 172.55710220336914s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5016074054337736, train accuracy: 0.4178595773687798
Val mean loss: 1.644862413406372, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3090 			 1998 			 1113
2245 			 2123 			 920
1986 			 1966 			 869
1471 			 1683 			 678
1104 			 1657 			 495
373 			 842 			 216
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
412 			 263 			 121
277 			 248 			 78
261 			 251 			 88
150 			 169 			 42
135 			 237 			 44
49 			 116 			 21
Max memory allocated: 14351809536; Memory allocated: 7208819712
Epoch [116/500] took 172.6542444229126s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5009804496141237, train accuracy: 0.4210731327295745
Val mean loss: 1.6474893005882822, val accuracy: 0.3060747663551402

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3198 			 1998 			 1148
2043 			 2123 			 871
2224 			 1966 			 950
1343 			 1683 			 637
1102 			 1657 			 495
359 			 842 			 223
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 116
296 			 248 			 83
238 			 251 			 82
172 			 169 			 47
121 			 237 			 42
57 			 116 			 23
Max memory allocated: 14351809536; Memory allocated: 7226244096
Epoch [117/500] took 172.6873390674591s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.5005737494828173, train accuracy: 0.4217547959879248
Val mean loss: 1.644033853600665, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3197 			 1998 			 1162
2188 			 2123 			 916
2085 			 1966 			 914
1399 			 1683 			 652
1024 			 1657 			 468
376 			 842 			 219
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
391 			 263 			 116
279 			 248 			 80
237 			 251 			 80
181 			 169 			 48
144 			 237 			 44
52 			 116 			 22
Max memory allocated: 14351809536; Memory allocated: 7186946048
Epoch [118/500] took 172.5838189125061s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4992834470725134, train accuracy: 0.41961242574739505
Val mean loss: 1.645699201560602, val accuracy: 0.3146417445482866

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3209 			 1998 			 1148
2119 			 2123 			 894
1993 			 1966 			 889
1524 			 1683 			 687
1077 			 1657 			 483
347 			 842 			 208
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
373 			 263 			 114
282 			 248 			 79
281 			 251 			 95
156 			 169 			 44
133 			 237 			 44
59 			 116 			 28
Max memory allocated: 14351809536; Memory allocated: 7161042944
Epoch [119/500] took 171.68168830871582s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4969732029787106, train accuracy: 0.4224364592462752
Val mean loss: 1.6411042475118869, val accuracy: 0.3107476635514019

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3067 			 1998 			 1123
2052 			 2123 			 866
2249 			 1966 			 966
1422 			 1683 			 660
1081 			 1657 			 487
398 			 842 			 236
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
409 			 263 			 122
285 			 248 			 81
238 			 251 			 82
173 			 169 			 47
125 			 237 			 43
54 			 116 			 24
Max memory allocated: 14351809536; Memory allocated: 7222631424
Epoch [120/500] took 172.51674461364746s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4959461336195283, train accuracy: 0.42487097088324083
Val mean loss: 1.6456455602878477, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3125 			 1998 			 1139
2137 			 2123 			 905
2101 			 1966 			 922
1412 			 1683 			 656
1128 			 1657 			 522
366 			 842 			 219
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
443 			 263 			 122
277 			 248 			 78
219 			 251 			 73
179 			 169 			 50
118 			 237 			 40
48 			 116 			 19
Max memory allocated: 14709633024; Memory allocated: 7216241664
Epoch [121/500] took 172.94022393226624s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.495600929141416, train accuracy: 0.42097575226409584
Val mean loss: 1.6342067369600621, val accuracy: 0.31853582554517135

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3370 			 1998 			 1189
2024 			 2123 			 877
2005 			 1966 			 882
1477 			 1683 			 682
1042 			 1657 			 478
351 			 842 			 215
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 263 			 115
294 			 248 			 86
267 			 251 			 90
163 			 169 			 47
131 			 237 			 44
61 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7287013376
Epoch [122/500] took 172.556720495224s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4947854514433958, train accuracy: 0.4267211997273347
Val mean loss: 1.658042550086975, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3012 			 1998 			 1122
2228 			 2123 			 937
2138 			 1966 			 931
1455 			 1683 			 674
1031 			 1657 			 480
405 			 842 			 238
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
424 			 263 			 117
258 			 248 			 70
249 			 251 			 85
155 			 169 			 44
147 			 237 			 47
51 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7232928768
Epoch [123/500] took 172.1485469341278s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.492431903925269, train accuracy: 0.42467620995228356
Val mean loss: 1.641749728016737, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3137 			 1998 			 1144
2104 			 2123 			 890
2064 			 1966 			 910
1417 			 1683 			 664
1171 			 1657 			 526
376 			 842 			 227
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 118
257 			 248 			 73
259 			 251 			 88
168 			 169 			 46
139 			 237 			 45
61 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7185004544
Epoch [124/500] took 172.3346929550171s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.491661612118516, train accuracy: 0.4267211997273347
Val mean loss: 1.6340775460731694, val accuracy: 0.3130841121495327

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3283 			 1998 			 1188
2050 			 2123 			 883
2133 			 1966 			 933
1414 			 1683 			 657
1010 			 1657 			 487
379 			 842 			 234
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 108
296 			 248 			 84
253 			 251 			 86
167 			 169 			 46
155 			 237 			 50
63 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7193483264
Epoch [125/500] took 173.22029423713684s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.492160702791541, train accuracy: 0.42613691693446293
Val mean loss: 1.657186912327278, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3104 			 1998 			 1137
2101 			 2123 			 895
2107 			 1966 			 931
1424 			 1683 			 672
1157 			 1657 			 522
376 			 842 			 219
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
387 			 263 			 113
292 			 248 			 84
255 			 251 			 88
166 			 169 			 46
129 			 237 			 40
55 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7147771904
Epoch [126/500] took 172.93455243110657s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4908823695880973, train accuracy: 0.4251631122796767
Val mean loss: 1.640937840066305, val accuracy: 0.3130841121495327

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3146 			 1998 			 1149
2125 			 2123 			 907
2131 			 1966 			 925
1432 			 1683 			 671
1058 			 1657 			 492
377 			 842 			 222
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
381 			 263 			 117
289 			 248 			 82
245 			 251 			 85
171 			 169 			 46
139 			 237 			 46
59 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7268081664
Epoch [127/500] took 173.43122100830078s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.490349693461742, train accuracy: 0.4232155029701042
Val mean loss: 1.6403900559355573, val accuracy: 0.3060747663551402

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3161 			 1998 			 1155
2093 			 2123 			 889
2060 			 1966 			 910
1458 			 1683 			 676
1130 			 1657 			 501
367 			 842 			 215
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
383 			 263 			 108
271 			 248 			 79
265 			 251 			 91
178 			 169 			 47
130 			 237 			 46
57 			 116 			 22
Max memory allocated: 14709633024; Memory allocated: 7217888256
Epoch [128/500] took 173.81224846839905s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4910045594812553, train accuracy: 0.4272081020547278
Val mean loss: 1.661758318179991, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3193 			 1998 			 1164
2081 			 2123 			 903
2184 			 1966 			 947
1421 			 1683 			 667
1021 			 1657 			 478
369 			 842 			 228
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
369 			 263 			 111
306 			 248 			 87
232 			 251 			 82
174 			 169 			 46
145 			 237 			 47
58 			 116 			 23
Max memory allocated: 14709633024; Memory allocated: 7222836224
Epoch [129/500] took 172.92494106292725s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.486795235645734, train accuracy: 0.4293504722952576
Val mean loss: 1.6450449984248092, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3124 			 1998 			 1152
2165 			 2123 			 922
2074 			 1966 			 925
1416 			 1683 			 671
1093 			 1657 			 499
397 			 842 			 240
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
377 			 263 			 111
283 			 248 			 79
236 			 251 			 81
185 			 169 			 48
151 			 237 			 50
52 			 116 			 19
Max memory allocated: 14709633024; Memory allocated: 7291420672
Epoch [130/500] took 172.9573793411255s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4871848732511574, train accuracy: 0.42886356996786446
Val mean loss: 1.6463268733606107, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3117 			 1998 			 1146
2101 			 2123 			 898
2044 			 1966 			 908
1509 			 1683 			 695
1117 			 1657 			 518
381 			 842 			 239
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
398 			 263 			 117
284 			 248 			 78
251 			 251 			 85
161 			 169 			 47
131 			 237 			 42
59 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7204953088
Epoch [131/500] took 172.96096396446228s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4862545806670857, train accuracy: 0.4315902230012659
Val mean loss: 1.647124368969987, val accuracy: 0.309190031152648

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3097 			 1998 			 1141
2098 			 2123 			 907
2117 			 1966 			 942
1424 			 1683 			 676
1159 			 1657 			 535
374 			 842 			 231
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 117
290 			 248 			 85
237 			 251 			 82
175 			 169 			 46
129 			 237 			 44
53 			 116 			 23
Max memory allocated: 14709633024; Memory allocated: 7228177408
Epoch [132/500] took 172.95279669761658s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.484482954224322, train accuracy: 0.42798714577855684
Val mean loss: 1.6438781808062297, val accuracy: 0.3099688473520249

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3177 			 1998 			 1165
2120 			 2123 			 909
2110 			 1966 			 928
1477 			 1683 			 685
1005 			 1657 			 481
380 			 842 			 227
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
383 			 263 			 112
301 			 248 			 89
238 			 251 			 80
163 			 169 			 47
137 			 237 			 48
62 			 116 			 22
Max memory allocated: 14709633024; Memory allocated: 7255810048
Epoch [133/500] took 173.15396237373352s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.483662199008502, train accuracy: 0.43168760346674456
Val mean loss: 1.6401397571331118, val accuracy: 0.31542056074766356

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3169 			 1998 			 1167
2054 			 2123 			 893
2052 			 1966 			 923
1464 			 1683 			 688
1136 			 1657 			 525
394 			 842 			 237
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 115
303 			 248 			 85
282 			 251 			 94
145 			 169 			 44
124 			 237 			 42
58 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7201635328
Epoch [134/500] took 172.75825214385986s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4826122882581574, train accuracy: 0.4310059402083942
Val mean loss: 1.6502323266936512, val accuracy: 0.3060747663551402

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3137 			 1998 			 1153
2130 			 2123 			 911
2183 			 1966 			 964
1403 			 1683 			 671
1049 			 1657 			 505
367 			 842 			 222
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
367 			 263 			 108
294 			 248 			 82
234 			 251 			 79
170 			 169 			 46
154 			 237 			 49
65 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7198424064
Epoch [135/500] took 173.19267392158508s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4825709723980627, train accuracy: 0.4326614081215308
Val mean loss: 1.6238929556637276, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3040 			 1998 			 1133
2129 			 2123 			 913
2097 			 1966 			 938
1437 			 1683 			 680
1186 			 1657 			 546
380 			 842 			 233
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
385 			 263 			 109
289 			 248 			 79
246 			 251 			 86
173 			 169 			 46
130 			 237 			 42
61 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7211514880
Epoch [136/500] took 172.5401587486267s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4814420983056042, train accuracy: 0.43012951601908656
Val mean loss: 1.640791654586792, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3133 			 1998 			 1157
2159 			 2123 			 920
2083 			 1966 			 930
1475 			 1683 			 696
1042 			 1657 			 483
377 			 842 			 231
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
414 			 263 			 113
279 			 248 			 76
219 			 251 			 74
171 			 169 			 48
138 			 237 			 40
63 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7233387520
Epoch [137/500] took 172.6127371788025s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4803427955443242, train accuracy: 0.43451163696562467
Val mean loss: 1.6588100601987141, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3123 			 1998 			 1166
2138 			 2123 			 924
2058 			 1966 			 922
1454 			 1683 			 692
1101 			 1657 			 521
395 			 842 			 237
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
413 			 263 			 112
255 			 248 			 68
242 			 251 			 84
172 			 169 			 47
139 			 237 			 40
63 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7210630144
Epoch [138/500] took 173.41046476364136s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4800310365136167, train accuracy: 0.4335378323108384
Val mean loss: 1.6527402517272205, val accuracy: 0.3045171339563863

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3142 			 1998 			 1160
2050 			 2123 			 890
2130 			 1966 			 957
1436 			 1683 			 686
1130 			 1657 			 522
381 			 842 			 237
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
390 			 263 			 112
296 			 248 			 82
231 			 251 			 80
173 			 169 			 47
131 			 237 			 43
63 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7264256000
Epoch [139/500] took 172.98168659210205s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4781310614024368, train accuracy: 0.4341221151037102
Val mean loss: 1.651808985849706, val accuracy: 0.309190031152648

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3058 			 1998 			 1142
2142 			 2123 			 917
2003 			 1966 			 917
1546 			 1683 			 721
1144 			 1657 			 531
376 			 842 			 230
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
412 			 263 			 119
272 			 248 			 76
276 			 251 			 90
145 			 169 			 45
123 			 237 			 41
56 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7216905216
Epoch [140/500] took 173.163161277771s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.478212599442384, train accuracy: 0.43470639789658194
Val mean loss: 1.6461677056987112, val accuracy: 0.3060747663551402

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3075 			 1998 			 1153
2104 			 2123 			 912
2237 			 1966 			 984
1353 			 1683 			 663
1113 			 1657 			 518
387 			 842 			 234
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
420 			 263 			 124
264 			 248 			 75
235 			 251 			 82
187 			 169 			 50
121 			 237 			 37
57 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7269203968
Epoch [141/500] took 172.5856227874756s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4763996719942658, train accuracy: 0.4333430713798812
Val mean loss: 1.6517046660911747, val accuracy: 0.3099688473520249

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3179 			 1998 			 1172
2074 			 2123 			 906
2103 			 1966 			 938
1472 			 1683 			 705
1062 			 1657 			 495
379 			 842 			 234
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
392 			 263 			 113
286 			 248 			 80
247 			 251 			 83
164 			 169 			 45
134 			 237 			 50
61 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7228275712
Epoch [142/500] took 172.72305536270142s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4751405556253927, train accuracy: 0.43626448534423995
Val mean loss: 1.6361023129486456, val accuracy: 0.3045171339563863

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3112 			 1998 			 1157
2098 			 2123 			 920
2152 			 1966 			 954
1430 			 1683 			 686
1091 			 1657 			 526
386 			 842 			 237
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
379 			 263 			 109
304 			 248 			 83
228 			 251 			 81
174 			 169 			 48
142 			 237 			 46
57 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7157725184
Epoch [143/500] took 172.49597072601318s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4739657930124586, train accuracy: 0.4398675625669491
Val mean loss: 1.6734907627105713, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3052 			 1998 			 1159
2168 			 2123 			 942
2055 			 1966 			 941
1456 			 1683 			 696
1156 			 1657 			 543
382 			 842 			 236
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
385 			 263 			 113
280 			 248 			 76
239 			 251 			 82
178 			 169 			 46
142 			 237 			 47
60 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7207795712
Epoch [144/500] took 172.3455455303192s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4740356184611811, train accuracy: 0.4354854416204109
Val mean loss: 1.638505897870878, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3087 			 1998 			 1152
2115 			 2123 			 909
2078 			 1966 			 943
1468 			 1683 			 700
1136 			 1657 			 536
385 			 842 			 232
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
374 			 263 			 111
299 			 248 			 82
247 			 251 			 81
163 			 169 			 47
134 			 237 			 44
67 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7248961536
Epoch [145/500] took 173.80585861206055s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4733276879676034, train accuracy: 0.4403544648943422
Val mean loss: 1.6479528182890357, val accuracy: 0.3115264797507788

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3093 			 1998 			 1171
2113 			 2123 			 924
2177 			 1966 			 974
1419 			 1683 			 688
1090 			 1657 			 529
377 			 842 			 236
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
385 			 263 			 115
303 			 248 			 86
212 			 251 			 74
179 			 169 			 49
143 			 237 			 49
62 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7203847168
Epoch [146/500] took 173.1050808429718s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4727615006616182, train accuracy: 0.4380173337228552
Val mean loss: 1.65297692287259, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3176 			 1998 			 1183
2061 			 2123 			 915
2051 			 1966 			 927
1484 			 1683 			 709
1120 			 1657 			 528
377 			 842 			 236
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 102
285 			 248 			 81
253 			 251 			 87
184 			 169 			 47
141 			 237 			 47
69 			 116 			 31
Max memory allocated: 14709633024; Memory allocated: 7193556992
Epoch [147/500] took 173.81978750228882s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4714259529410865, train accuracy: 0.4407439867562567
Val mean loss: 1.6389833427057034, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3015 			 1998 			 1135
2122 			 2123 			 926
2141 			 1966 			 972
1469 			 1683 			 709
1113 			 1657 			 534
409 			 842 			 250
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
386 			 263 			 112
285 			 248 			 82
234 			 251 			 83
177 			 169 			 49
143 			 237 			 43
59 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7221345280
Epoch [148/500] took 172.84777665138245s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4694574235755706, train accuracy: 0.4395754211705132
Val mean loss: 1.6599427577925892, val accuracy: 0.3099688473520249

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2983 			 1998 			 1139
2154 			 2123 			 936
2099 			 1966 			 948
1485 			 1683 			 710
1137 			 1657 			 537
411 			 842 			 244
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
416 			 263 			 123
267 			 248 			 73
237 			 251 			 84
169 			 169 			 49
139 			 237 			 46
56 			 116 			 23
Max memory allocated: 14709633024; Memory allocated: 7199849472
Epoch [149/500] took 173.97491121292114s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4710812475822426, train accuracy: 0.4430811179277437
Val mean loss: 1.6454361764396108, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3198 			 1998 			 1211
2037 			 2123 			 903
2107 			 1966 			 956
1449 			 1683 			 705
1096 			 1657 			 538
382 			 842 			 237
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
390 			 263 			 116
327 			 248 			 90
214 			 251 			 74
168 			 169 			 47
128 			 237 			 42
57 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7189411840
Epoch [150/500] took 173.18667912483215s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.468390573965055, train accuracy: 0.44210731327295744
Val mean loss: 1.646947436216401, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3029 			 1998 			 1150
2136 			 2123 			 942
2110 			 1966 			 959
1460 			 1683 			 708
1141 			 1657 			 541
393 			 842 			 240
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
373 			 263 			 109
300 			 248 			 83
225 			 251 			 80
190 			 169 			 49
136 			 237 			 47
60 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7207820288
Epoch [151/500] took 172.84217858314514s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4662191563306197, train accuracy: 0.4433732593241796
Val mean loss: 1.6592227656666825, val accuracy: 0.31230529595015577

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3129 			 1998 			 1176
2031 			 2123 			 911
2113 			 1966 			 967
1460 			 1683 			 710
1141 			 1657 			 544
395 			 842 			 245
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
381 			 263 			 115
303 			 248 			 85
228 			 251 			 80
185 			 169 			 50
123 			 237 			 42
64 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7213186048
Epoch [152/500] took 172.7532274723053s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4656485345133368, train accuracy: 0.4415230304800857
Val mean loss: 1.6500983499899142, val accuracy: 0.31230529595015577

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3006 			 1998 			 1139
2147 			 2123 			 939
2027 			 1966 			 929
1509 			 1683 			 725
1170 			 1657 			 548
410 			 842 			 254
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
401 			 263 			 117
303 			 248 			 85
237 			 251 			 85
164 			 169 			 47
119 			 237 			 41
60 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7249960960
Epoch [153/500] took 172.63883113861084s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4639809618115054, train accuracy: 0.4447365858408803
Val mean loss: 1.6479670274548415, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3098 			 1998 			 1181
2090 			 2123 			 925
2159 			 1966 			 975
1445 			 1683 			 704
1079 			 1657 			 536
398 			 842 			 246
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
406 			 263 			 120
282 			 248 			 75
228 			 251 			 77
176 			 169 			 50
137 			 237 			 41
55 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7198783488
Epoch [154/500] took 173.02034401893616s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4640343902267028, train accuracy: 0.44541824909923067
Val mean loss: 1.6397752878142566, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3093 			 1998 			 1175
2157 			 2123 			 959
1984 			 1966 			 928
1497 			 1683 			 722
1151 			 1657 			 543
387 			 842 			 247
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
394 			 263 			 115
265 			 248 			 74
271 			 251 			 89
173 			 169 			 49
119 			 237 			 43
62 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7210572800
Epoch [155/500] took 173.26272749900818s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.462839216458092, train accuracy: 0.44298373746226505
Val mean loss: 1.6538164528404795, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3046 			 1998 			 1164
2115 			 2123 			 930
2134 			 1966 			 965
1484 			 1683 			 717
1083 			 1657 			 527
407 			 842 			 246
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
383 			 263 			 114
263 			 248 			 70
257 			 251 			 88
178 			 169 			 47
140 			 237 			 46
63 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7215594496
Epoch [156/500] took 173.34373569488525s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4640582677359892, train accuracy: 0.44298373746226505
Val mean loss: 1.6511545908160326, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3028 			 1998 			 1146
2121 			 2123 			 940
2123 			 1966 			 959
1457 			 1683 			 710
1124 			 1657 			 538
416 			 842 			 256
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 115
265 			 248 			 72
251 			 251 			 86
177 			 169 			 48
131 			 237 			 40
60 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7213587456
Epoch [157/500] took 172.41494369506836s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.461458834903634, train accuracy: 0.4466841951504528
Val mean loss: 1.6472466079200185, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3025 			 1998 			 1168
2068 			 2123 			 927
2159 			 1966 			 981
1483 			 1683 			 720
1146 			 1657 			 546
388 			 842 			 245
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
424 			 263 			 125
297 			 248 			 78
212 			 251 			 75
175 			 169 			 49
124 			 237 			 41
52 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7253606400
Epoch [158/500] took 173.3964879512787s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4620610973173955, train accuracy: 0.44541824909923067
Val mean loss: 1.6331621641066016, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3087 			 1998 			 1185
2195 			 2123 			 956
1983 			 1966 			 925
1509 			 1683 			 731
1096 			 1657 			 533
399 			 842 			 244
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
400 			 263 			 116
267 			 248 			 73
261 			 251 			 89
161 			 169 			 46
138 			 237 			 46
57 			 116 			 22
Max memory allocated: 14709633024; Memory allocated: 7192295424
Epoch [159/500] took 172.36419105529785s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4594911923661038, train accuracy: 0.4488265653909826
Val mean loss: 1.6634264399365681, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3049 			 1998 			 1169
2025 			 2123 			 913
2139 			 1966 			 986
1457 			 1683 			 714
1204 			 1657 			 576
395 			 842 			 251
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 108
298 			 248 			 80
246 			 251 			 82
179 			 169 			 49
135 			 237 			 48
65 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7209745408
Epoch [160/500] took 172.34822297096252s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4583119384224912, train accuracy: 0.44872918492550395
Val mean loss: 1.6669636819420792, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3063 			 1998 			 1176
2160 			 2123 			 957
2091 			 1966 			 964
1484 			 1683 			 725
1063 			 1657 			 537
408 			 842 			 249
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 105
290 			 248 			 79
248 			 251 			 87
176 			 169 			 48
149 			 237 			 49
65 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7187208192
Epoch [161/500] took 172.47745537757874s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4571038324884908, train accuracy: 0.4488265653909826
Val mean loss: 1.6479492856235038, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2903 			 1998 			 1131
2109 			 2123 			 947
2193 			 1966 			 995
1452 			 1683 			 709
1177 			 1657 			 569
435 			 842 			 258
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
417 			 263 			 118
296 			 248 			 77
217 			 251 			 75
168 			 169 			 46
134 			 237 			 46
52 			 116 			 23
Max memory allocated: 14709633024; Memory allocated: 7205207040
Epoch [162/500] took 172.71344232559204s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4568720005011633, train accuracy: 0.4472684779433246
Val mean loss: 1.6497362823021122, val accuracy: 0.31386292834890966

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3075 			 1998 			 1170
2125 			 2123 			 943
2079 			 1966 			 971
1487 			 1683 			 723
1122 			 1657 			 546
381 			 842 			 240
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
378 			 263 			 115
285 			 248 			 78
245 			 251 			 85
173 			 169 			 47
138 			 237 			 48
65 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7251255296
Epoch [163/500] took 173.64802742004395s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.457927142348245, train accuracy: 0.4485344239945467
Val mean loss: 1.6357459556765672, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3070 			 1998 			 1177
2098 			 2123 			 941
2077 			 1966 			 962
1500 			 1683 			 731
1128 			 1657 			 553
396 			 842 			 242
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
392 			 263 			 118
284 			 248 			 76
237 			 251 			 81
182 			 169 			 49
127 			 237 			 45
62 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7228570624
Epoch [164/500] took 172.090900182724s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4552747100313133, train accuracy: 0.4486318044600253
Val mean loss: 1.6603123734637004, val accuracy: 0.3045171339563863

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3058 			 1998 			 1177
2155 			 2123 			 957
2044 			 1966 			 951
1475 			 1683 			 722
1116 			 1657 			 544
421 			 842 			 256
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
385 			 263 			 112
257 			 248 			 67
260 			 251 			 90
176 			 169 			 48
143 			 237 			 48
63 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7243611136
Epoch [165/500] took 172.17926120758057s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.456140620314815, train accuracy: 0.4473658584088032
Val mean loss: 1.640655023295705, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3050 			 1998 			 1165
2019 			 2123 			 918
2115 			 1966 			 969
1509 			 1683 			 734
1175 			 1657 			 558
401 			 842 			 250
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 263 			 109
312 			 248 			 86
234 			 251 			 81
166 			 169 			 46
140 			 237 			 43
64 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7272284160
Epoch [166/500] took 170.92530965805054s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4533394601114813, train accuracy: 0.4523322621482131
Val mean loss: 1.6691585517511136, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3071 			 1998 			 1201
2124 			 2123 			 952
2056 			 1966 			 956
1470 			 1683 			 717
1156 			 1657 			 570
392 			 842 			 249
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 109
285 			 248 			 72
267 			 251 			 90
168 			 169 			 47
141 			 237 			 47
66 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7264944128
Epoch [167/500] took 171.93662762641907s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4535972908649861, train accuracy: 0.4490213263219398
Val mean loss: 1.6495064380692273, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2989 			 1998 			 1147
2122 			 2123 			 947
2175 			 1966 			 991
1438 			 1683 			 712
1148 			 1657 			 562
397 			 842 			 252
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
369 			 263 			 110
287 			 248 			 78
226 			 251 			 78
195 			 169 			 51
139 			 237 			 43
68 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7199849472
Epoch [168/500] took 171.9034378528595s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.452559179606096, train accuracy: 0.45418249099230695
Val mean loss: 1.6378705152651158, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3025 			 1998 			 1181
2086 			 2123 			 939
2038 			 1966 			 960
1522 			 1683 			 743
1172 			 1657 			 575
426 			 842 			 266
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
390 			 263 			 110
304 			 248 			 80
237 			 251 			 79
162 			 169 			 46
128 			 237 			 43
63 			 116 			 23
Max memory allocated: 14709633024; Memory allocated: 7188944896
Epoch [169/500] took 171.17129039764404s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4496881713005612, train accuracy: 0.4542798714577856
Val mean loss: 1.6442316828704462, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3075 			 1998 			 1185
2146 			 2123 			 963
2034 			 1966 			 953
1485 			 1683 			 740
1105 			 1657 			 561
424 			 842 			 263
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
377 			 263 			 111
277 			 248 			 74
271 			 251 			 91
160 			 169 			 47
134 			 237 			 46
65 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7245701120
Epoch [170/500] took 172.0916450023651s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4527402629733457, train accuracy: 0.44999513097672605
Val mean loss: 1.6551045819026668, val accuracy: 0.31230529595015577

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2924 			 1998 			 1135
2077 			 2123 			 938
2173 			 1966 			 996
1482 			 1683 			 735
1206 			 1657 			 571
407 			 842 			 246
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
411 			 263 			 123
307 			 248 			 82
240 			 251 			 84
154 			 169 			 46
117 			 237 			 42
55 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7202618368
Epoch [171/500] took 170.99010562896729s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4479975748656324, train accuracy: 0.45350082773395656
Val mean loss: 1.6477211481187402, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3138 			 1998 			 1206
2116 			 2123 			 960
2125 			 1966 			 989
1422 			 1683 			 716
1074 			 1657 			 537
394 			 842 			 249
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 107
312 			 248 			 83
222 			 251 			 79
180 			 169 			 48
151 			 237 			 50
63 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7214390272
Epoch [172/500] took 171.65410375595093s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4488356132002262, train accuracy: 0.45379296913039247
Val mean loss: 1.6471086507890282, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2985 			 1998 			 1166
2099 			 2123 			 950
2060 			 1966 			 966
1522 			 1683 			 748
1198 			 1657 			 577
405 			 842 			 253
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
370 			 263 			 107
318 			 248 			 86
241 			 251 			 82
161 			 169 			 46
131 			 237 			 44
63 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7193589760
Epoch [173/500] took 171.38554310798645s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4461694424768845, train accuracy: 0.45418249099230695
Val mean loss: 1.6397634919096784, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3002 			 1998 			 1173
2229 			 2123 			 998
2078 			 1966 			 973
1443 			 1683 			 719
1109 			 1657 			 549
408 			 842 			 252
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
376 			 263 			 110
254 			 248 			 68
273 			 251 			 90
173 			 169 			 50
146 			 237 			 45
62 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7237024768
Epoch [174/500] took 170.99534702301025s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4455023357801349, train accuracy: 0.4601226993865031
Val mean loss: 1.6523358240360166, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2953 			 1998 			 1169
2024 			 2123 			 940
2209 			 1966 			 1015
1472 			 1683 			 741
1178 			 1657 			 587
433 			 842 			 273
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
362 			 263 			 103
311 			 248 			 84
214 			 251 			 72
185 			 169 			 47
146 			 237 			 45
66 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7357114368
Epoch [175/500] took 171.4777717590332s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4471119820514573, train accuracy: 0.4562274807673581
Val mean loss: 1.6464581547713861, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2998 			 1998 			 1172
2113 			 2123 			 965
2016 			 1966 			 964
1520 			 1683 			 745
1207 			 1657 			 574
415 			 842 			 265
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
374 			 263 			 110
301 			 248 			 79
250 			 251 			 85
167 			 169 			 44
128 			 237 			 44
64 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7205338112
Epoch [176/500] took 171.21843099594116s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4453566854245194, train accuracy: 0.45389034959587105
Val mean loss: 1.6409144546927474, val accuracy: 0.3045171339563863

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2994 			 1998 			 1161
2151 			 2123 			 967
2088 			 1966 			 983
1488 			 1683 			 735
1129 			 1657 			 557
419 			 842 			 258
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
378 			 263 			 114
280 			 248 			 73
251 			 251 			 83
169 			 169 			 47
141 			 237 			 47
65 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7233993728
Epoch [177/500] took 171.83772110939026s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.445251858122995, train accuracy: 0.4562274807673581
Val mean loss: 1.644388809436705, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3028 			 1998 			 1180
2110 			 2123 			 962
2126 			 1966 			 992
1455 			 1683 			 731
1139 			 1657 			 560
411 			 842 			 260
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
366 			 263 			 109
272 			 248 			 65
247 			 251 			 83
185 			 169 			 50
143 			 237 			 47
71 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7228406784
Epoch [178/500] took 171.43966484069824s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4428644815337992, train accuracy: 0.45720128542214433
Val mean loss: 1.6565074775277115, val accuracy: 0.3076323987538941

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2966 			 1998 			 1176
2085 			 2123 			 954
2117 			 1966 			 986
1481 			 1683 			 736
1219 			 1657 			 580
401 			 842 			 263
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 113
316 			 248 			 87
216 			 251 			 77
191 			 169 			 51
124 			 237 			 40
65 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7211908096
Epoch [179/500] took 171.45590448379517s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4433045866333436, train accuracy: 0.45875937286980234
Val mean loss: 1.6412632668890603, val accuracy: 0.3045171339563863

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2935 			 1998 			 1153
2190 			 2123 			 994
2056 			 1966 			 971
1509 			 1683 			 753
1146 			 1657 			 574
433 			 842 			 266
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
391 			 263 			 117
272 			 248 			 72
260 			 251 			 87
171 			 169 			 48
129 			 237 			 43
61 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7261339648
Epoch [180/500] took 171.8467617034912s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4429194607838662, train accuracy: 0.45700652449118706
Val mean loss: 1.6430900881930095, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3094 			 1998 			 1202
2076 			 2123 			 959
2114 			 1966 			 987
1461 			 1683 			 732
1130 			 1657 			 562
394 			 842 			 251
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 100
255 			 248 			 68
259 			 251 			 87
186 			 169 			 49
157 			 237 			 51
71 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7265271808
Epoch [181/500] took 171.1435043811798s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4416573445002239, train accuracy: 0.4574934268185802
Val mean loss: 1.6411343434961831, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2885 			 1998 			 1135
2076 			 2123 			 958
2063 			 1966 			 974
1568 			 1683 			 771
1226 			 1657 			 592
451 			 842 			 268
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
393 			 263 			 115
289 			 248 			 76
247 			 251 			 84
164 			 169 			 47
132 			 237 			 41
59 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7235451904
Epoch [182/500] took 171.82460737228394s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.441015945788113, train accuracy: 0.4595384165936313
Val mean loss: 1.6496431972922347, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3057 			 1998 			 1205
2143 			 2123 			 972
2096 			 1966 			 986
1456 			 1683 			 736
1120 			 1657 			 565
397 			 842 			 255
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 105
279 			 248 			 73
236 			 251 			 79
194 			 169 			 50
147 			 237 			 46
70 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7254097920
Epoch [183/500] took 171.91847610473633s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4400048471314142, train accuracy: 0.45934365566267404
Val mean loss: 1.6553012190795526, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2940 			 1998 			 1169
2045 			 2123 			 947
2189 			 1966 			 1011
1470 			 1683 			 735
1232 			 1657 			 599
393 			 842 			 256
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 112
297 			 248 			 81
224 			 251 			 74
191 			 169 			 50
131 			 237 			 39
69 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7217552384
Epoch [184/500] took 171.80348658561707s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4394002142724962, train accuracy: 0.4595384165936313
Val mean loss: 1.6447175217837822, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2996 			 1998 			 1177
2117 			 2123 			 968
2078 			 1966 			 989
1525 			 1683 			 758
1106 			 1657 			 551
447 			 842 			 276
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 106
316 			 248 			 84
219 			 251 			 78
189 			 169 			 49
140 			 237 			 44
61 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7285391360
Epoch [185/500] took 171.46660661697388s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4367022061273689, train accuracy: 0.46245983055799006
Val mean loss: 1.6485064175070785, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2953 			 1998 			 1168
2203 			 2123 			 997
2015 			 1966 			 971
1501 			 1683 			 754
1185 			 1657 			 583
412 			 842 			 276
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
386 			 263 			 112
268 			 248 			 66
258 			 251 			 89
182 			 169 			 52
128 			 237 			 41
62 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7161042944
Epoch [186/500] took 170.91708087921143s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4357845289313533, train accuracy: 0.45807770961145194
Val mean loss: 1.6420966357719609, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3049 			 1998 			 1192
2020 			 2123 			 932
2215 			 1966 			 1020
1473 			 1683 			 739
1068 			 1657 			 549
444 			 842 			 272
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
335 			 263 			 100
305 			 248 			 84
212 			 251 			 75
206 			 169 			 55
160 			 237 			 51
66 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7205698560
Epoch [187/500] took 171.19568824768066s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.436056258151093, train accuracy: 0.4588567533352809
Val mean loss: 1.6491098258553483, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2884 			 1998 			 1146
2191 			 2123 			 979
1996 			 1966 			 958
1551 			 1683 			 765
1230 			 1657 			 602
417 			 842 			 262
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
394 			 263 			 119
262 			 248 			 67
266 			 251 			 89
166 			 169 			 47
132 			 237 			 44
64 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7207828480
Epoch [188/500] took 171.944091796875s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.436320697778482, train accuracy: 0.4634336352127763
Val mean loss: 1.653404250377562, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3049 			 1998 			 1210
2069 			 2123 			 962
2186 			 1966 			 1028
1423 			 1683 			 728
1138 			 1657 			 570
404 			 842 			 261
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
364 			 263 			 109
275 			 248 			 72
239 			 251 			 79
193 			 169 			 52
145 			 237 			 48
68 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7147771904
Epoch [189/500] took 171.91451501846313s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4353438686358966, train accuracy: 0.4601226993865031
Val mean loss: 1.6388465863902395, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2974 			 1998 			 1175
2116 			 2123 			 966
2060 			 1966 			 979
1521 			 1683 			 757
1175 			 1657 			 578
423 			 842 			 270
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
377 			 263 			 115
275 			 248 			 72
254 			 251 			 85
173 			 169 			 50
140 			 237 			 43
65 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7191869440
Epoch [190/500] took 171.22784757614136s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4325235016249422, train accuracy: 0.46479696172947704
Val mean loss: 1.6609603108429327, val accuracy: 0.3060747663551402

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2934 			 1998 			 1170
2182 			 2123 			 994
2064 			 1966 			 991
1482 			 1683 			 747
1193 			 1657 			 604
414 			 842 			 267
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 107
247 			 248 			 64
284 			 251 			 94
166 			 169 			 50
161 			 237 			 49
70 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7198489600
Epoch [191/500] took 170.86058521270752s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.432236339444312, train accuracy: 0.4617781672996397
Val mean loss: 1.6506525307166866, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2918 			 1998 			 1166
2008 			 2123 			 927
2179 			 1966 			 1020
1476 			 1683 			 739
1254 			 1657 			 613
434 			 842 			 277
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 105
303 			 248 			 79
237 			 251 			 81
174 			 169 			 49
135 			 237 			 42
63 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7191967744
Epoch [192/500] took 171.70641899108887s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.432881358627961, train accuracy: 0.4645048203330412
Val mean loss: 1.6402086717326467, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2912 			 1998 			 1171
2174 			 2123 			 998
2103 			 1966 			 1005
1524 			 1683 			 757
1131 			 1657 			 571
425 			 842 			 268
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
396 			 263 			 113
280 			 248 			 73
226 			 251 			 78
185 			 169 			 53
133 			 237 			 42
64 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7231314944
Epoch [193/500] took 171.44143199920654s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4312110686227912, train accuracy: 0.46314149381634045
Val mean loss: 1.6513794020908634, val accuracy: 0.3068535825545171

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2951 			 1998 			 1186
2089 			 2123 			 963
2082 			 1966 			 989
1561 			 1683 			 763
1164 			 1657 			 584
422 			 842 			 271
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
383 			 263 			 117
287 			 248 			 74
246 			 251 			 84
168 			 169 			 48
130 			 237 			 40
70 			 116 			 31
Max memory allocated: 14709633024; Memory allocated: 7197538304
Epoch [194/500] took 171.88189435005188s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4306566663248887, train accuracy: 0.46596552731522056
Val mean loss: 1.6591477626707496, val accuracy: 0.3045171339563863

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2997 			 1998 			 1188
2148 			 2123 			 992
2061 			 1966 			 994
1475 			 1683 			 753
1145 			 1657 			 578
443 			 842 			 280
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
394 			 263 			 115
266 			 248 			 72
251 			 251 			 83
172 			 169 			 50
138 			 237 			 45
63 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7206550528
Epoch [195/500] took 171.33602666854858s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4302320220388727, train accuracy: 0.46275197195442597
Val mean loss: 1.6514662213441802, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3086 			 1998 			 1207
1997 			 2123 			 941
2172 			 1966 			 1024
1453 			 1683 			 747
1142 			 1657 			 565
419 			 842 			 268
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 99
322 			 248 			 84
213 			 251 			 72
203 			 169 			 53
132 			 237 			 42
64 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7237237760
Epoch [196/500] took 171.07054328918457s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4283759196599324, train accuracy: 0.4660629077806992
Val mean loss: 1.6499188353375691, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2898 			 1998 			 1161
2143 			 2123 			 988
2106 			 1966 			 1008
1498 			 1683 			 755
1188 			 1657 			 590
436 			 842 			 284
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
364 			 263 			 104
288 			 248 			 75
220 			 251 			 75
206 			 169 			 55
138 			 237 			 44
68 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7209171968
Epoch [197/500] took 172.12318921089172s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.429285549300482, train accuracy: 0.4649917226604343
Val mean loss: 1.6437743814980113, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2924 			 1998 			 1168
2122 			 2123 			 988
2053 			 1966 			 982
1591 			 1683 			 779
1161 			 1657 			 597
418 			 842 			 261
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
393 			 263 			 114
281 			 248 			 73
249 			 251 			 85
165 			 169 			 49
131 			 237 			 41
65 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7200421888
Epoch [198/500] took 172.01188588142395s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4280149167943224, train accuracy: 0.46752361476287857
Val mean loss: 1.653458339412038, val accuracy: 0.3029595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2937 			 1998 			 1182
2167 			 2123 			 995
2052 			 1966 			 988
1503 			 1683 			 761
1171 			 1657 			 592
439 			 842 			 283
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
388 			 263 			 115
276 			 248 			 72
254 			 251 			 83
167 			 169 			 48
138 			 237 			 45
61 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7283146752
Epoch [199/500] took 171.81181383132935s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4268500719486368, train accuracy: 0.46752361476287857
Val mean loss: 1.637319803237915, val accuracy: 0.309190031152648

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2987 			 1998 			 1184
2085 			 2123 			 977
2154 			 1966 			 1031
1448 			 1683 			 735
1185 			 1657 			 604
410 			 842 			 270
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
371 			 263 			 111
275 			 248 			 72
242 			 251 			 84
177 			 169 			 48
147 			 237 			 50
72 			 116 			 32
Max memory allocated: 14709633024; Memory allocated: 7208975360
Epoch [200/500] took 171.500173330307s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4257063977072173, train accuracy: 0.4651864835913916
Val mean loss: 1.6447623299389351, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2937 			 1998 			 1176
2129 			 2123 			 983
2100 			 1966 			 1007
1484 			 1683 			 749
1185 			 1657 			 589
434 			 842 			 273
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
381 			 263 			 106
265 			 248 			 68
233 			 251 			 76
188 			 169 			 52
146 			 237 			 46
71 			 116 			 31
Max memory allocated: 14709633024; Memory allocated: 7189739520
Epoch [201/500] took 171.27917909622192s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.423742198127081, train accuracy: 0.4678157561593144
Val mean loss: 1.666146976191823, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2896 			 1998 			 1172
2063 			 2123 			 970
2119 			 1966 			 1011
1567 			 1683 			 781
1202 			 1657 			 602
422 			 842 			 268
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
391 			 263 			 116
291 			 248 			 76
221 			 251 			 76
183 			 169 			 50
135 			 237 			 43
63 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7218740224
Epoch [202/500] took 172.04962348937988s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4258860342227782, train accuracy: 0.46440743986756255
Val mean loss: 1.6534126677164218, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3074 			 1998 			 1213
2155 			 2123 			 992
2031 			 1966 			 985
1526 			 1683 			 763
1079 			 1657 			 554
404 			 842 			 262
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 111
277 			 248 			 71
257 			 251 			 85
178 			 169 			 49
143 			 237 			 45
64 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7240989696
Epoch [203/500] took 171.47501349449158s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4226170614872395, train accuracy: 0.47297692082968157
Val mean loss: 1.638149520245994, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2944 			 1998 			 1201
2108 			 2123 			 985
2104 			 1966 			 1022
1464 			 1683 			 754
1249 			 1657 			 634
400 			 842 			 261
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
366 			 263 			 109
277 			 248 			 73
251 			 251 			 86
178 			 169 			 49
141 			 237 			 44
71 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7212432384
Epoch [204/500] took 172.1651713848114s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4241856240037818, train accuracy: 0.46898432174505794
Val mean loss: 1.6614233487989845, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2976 			 1998 			 1190
2056 			 2123 			 975
2157 			 1966 			 1030
1474 			 1683 			 753
1167 			 1657 			 588
439 			 842 			 280
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 105
286 			 248 			 72
244 			 251 			 83
180 			 169 			 49
146 			 237 			 47
71 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7201266688
Epoch [205/500] took 172.8139123916626s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4244210512095894, train accuracy: 0.4684000389521862
Val mean loss: 1.6561746946195277, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2989 			 1998 			 1195
2134 			 2123 			 992
2108 			 1966 			 1012
1464 			 1683 			 751
1161 			 1657 			 589
413 			 842 			 271
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 105
291 			 248 			 76
231 			 251 			 75
190 			 169 			 51
149 			 237 			 49
65 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7196817408
Epoch [206/500] took 172.0056893825531s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4242996437898678, train accuracy: 0.4723926380368098
Val mean loss: 1.647010640400212, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2868 			 1998 			 1165
2086 			 2123 			 987
2101 			 1966 			 1017
1559 			 1683 			 791
1218 			 1657 			 613
437 			 842 			 278
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
375 			 263 			 107
309 			 248 			 80
239 			 251 			 79
170 			 169 			 49
128 			 237 			 40
63 			 116 			 25
Max memory allocated: 14709633024; Memory allocated: 7238941696
Epoch [207/500] took 171.11694145202637s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.419682049677008, train accuracy: 0.47015288733080146
Val mean loss: 1.6662596028025558, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2965 			 1998 			 1189
2071 			 2123 			 973
2113 			 1966 			 1024
1514 			 1683 			 773
1173 			 1657 			 595
433 			 842 			 274
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
370 			 263 			 109
303 			 248 			 81
241 			 251 			 79
167 			 169 			 47
133 			 237 			 43
70 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7226964992
Epoch [208/500] took 171.81629347801208s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.420588995066016, train accuracy: 0.4722952575713312
Val mean loss: 1.647079447420632, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2930 			 1998 			 1185
2178 			 2123 			 1007
2121 			 1966 			 1023
1416 			 1683 			 746
1212 			 1657 			 612
412 			 842 			 277
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
377 			 263 			 111
272 			 248 			 70
220 			 251 			 76
206 			 169 			 55
139 			 237 			 48
70 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7192295424
Epoch [209/500] took 171.78101634979248s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4199678886716611, train accuracy: 0.47249001850228844
Val mean loss: 1.661137580871582, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2940 			 1998 			 1191
2074 			 2123 			 981
2086 			 1966 			 1013
1583 			 1683 			 795
1137 			 1657 			 583
449 			 842 			 289
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
387 			 263 			 113
284 			 248 			 76
231 			 251 			 75
182 			 169 			 49
134 			 237 			 44
66 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7212137472
Epoch [210/500] took 171.5736062526703s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4189098315818287, train accuracy: 0.4725873989677671
Val mean loss: 1.6485792020472085, val accuracy: 0.308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2956 			 1998 			 1195
2092 			 2123 			 986
2131 			 1966 			 1026
1472 			 1683 			 762
1200 			 1657 			 610
418 			 842 			 274
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 104
314 			 248 			 86
223 			 251 			 75
193 			 169 			 53
147 			 237 			 48
69 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7279624192
Epoch [211/500] took 171.20223689079285s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4163589707787534, train accuracy: 0.47619047619047616
Val mean loss: 1.6593471038632277, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2818 			 1998 			 1163
2183 			 2123 			 1022
2043 			 1966 			 1000
1530 			 1683 			 781
1250 			 1657 			 632
445 			 842 			 292
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 103
299 			 248 			 77
237 			 251 			 76
186 			 169 			 50
135 			 237 			 45
73 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7186429952
Epoch [212/500] took 171.59987831115723s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4175128602535925, train accuracy: 0.4750219106047327
Val mean loss: 1.647648712483848, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2959 			 1998 			 1204
2142 			 2123 			 1010
2061 			 1966 			 1009
1494 			 1683 			 769
1163 			 1657 			 599
450 			 842 			 287
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
370 			 263 			 108
284 			 248 			 72
248 			 251 			 80
177 			 169 			 48
139 			 237 			 43
66 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7203535872
Epoch [213/500] took 171.97440457344055s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4172768013499608, train accuracy: 0.47356120362255333
Val mean loss: 1.6453755308942097, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2934 			 1998 			 1186
2141 			 2123 			 1005
2087 			 1966 			 1020
1523 			 1683 			 776
1170 			 1657 			 602
414 			 842 			 274
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
373 			 263 			 106
266 			 248 			 67
247 			 251 			 80
178 			 169 			 52
153 			 237 			 48
67 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7191123968
Epoch [214/500] took 171.56589937210083s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4163227471235758, train accuracy: 0.4739507254844678
Val mean loss: 1.6584226707132852, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2889 			 1998 			 1184
2135 			 2123 			 1006
2123 			 1966 			 1033
1479 			 1683 			 759
1211 			 1657 			 611
432 			 842 			 274
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
367 			 263 			 105
276 			 248 			 72
237 			 251 			 75
186 			 169 			 51
147 			 237 			 50
71 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7210933248
Epoch [215/500] took 171.5346794128418s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4151316019604883, train accuracy: 0.47726166131074105
Val mean loss: 1.6541106817198963, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2890 			 1998 			 1176
2100 			 2123 			 993
2020 			 1966 			 1007
1623 			 1683 			 823
1174 			 1657 			 609
462 			 842 			 293
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
374 			 263 			 108
296 			 248 			 77
249 			 251 			 81
162 			 169 			 48
134 			 237 			 44
69 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7198964736
Epoch [216/500] took 171.90560245513916s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.415287747190006, train accuracy: 0.4741454864154251
Val mean loss: 1.6460488511294853, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2930 			 1998 			 1198
2087 			 2123 			 979
2087 			 1966 			 1020
1513 			 1683 			 778
1201 			 1657 			 614
451 			 842 			 280
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 105
303 			 248 			 81
247 			 251 			 78
163 			 169 			 48
137 			 237 			 44
69 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7199308800
Epoch [217/500] took 171.31706833839417s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4144314549793706, train accuracy: 0.47424286688090367
Val mean loss: 1.6462477038546306, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2910 			 1998 			 1186
2189 			 2123 			 1024
2110 			 1966 			 1034
1505 			 1683 			 769
1129 			 1657 			 579
426 			 842 			 278
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 107
280 			 248 			 72
240 			 251 			 80
170 			 169 			 48
155 			 237 			 47
67 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7314588672
Epoch [218/500] took 171.4830288887024s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4121827466465602, train accuracy: 0.4793066510857922
Val mean loss: 1.6450562738790744, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2978 			 1998 			 1214
2083 			 2123 			 1001
2096 			 1966 			 1026
1462 			 1683 			 763
1220 			 1657 			 632
430 			 842 			 286
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
369 			 263 			 104
292 			 248 			 76
249 			 251 			 80
170 			 169 			 49
135 			 237 			 47
69 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7229062144
Epoch [219/500] took 171.12506818771362s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.410881469925616, train accuracy: 0.47599571525951895
Val mean loss: 1.6450365200275328, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2837 			 1998 			 1170
2111 			 2123 			 1006
2126 			 1966 			 1036
1535 			 1683 			 781
1220 			 1657 			 612
440 			 842 			 283
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 102
289 			 248 			 73
243 			 251 			 79
179 			 169 			 49
142 			 237 			 42
73 			 116 			 31
Max memory allocated: 14709633024; Memory allocated: 7199833088
Epoch [220/500] took 171.79962182044983s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4114998229938875, train accuracy: 0.4769695199143052
Val mean loss: 1.6544798438141985, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2943 			 1998 			 1206
2104 			 2123 			 1005
2106 			 1966 			 1021
1504 			 1683 			 769
1172 			 1657 			 610
440 			 842 			 287
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 105
309 			 248 			 80
238 			 251 			 76
171 			 169 			 49
148 			 237 			 45
67 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7213251584
Epoch [221/500] took 171.98354983329773s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4114201949021528, train accuracy: 0.47950141201674945
Val mean loss: 1.6425705653865164, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2872 			 1998 			 1191
2133 			 2123 			 1018
2071 			 1966 			 1020
1539 			 1683 			 790
1200 			 1657 			 614
454 			 842 			 291
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
373 			 263 			 110
289 			 248 			 76
246 			 251 			 81
160 			 169 			 48
148 			 237 			 47
68 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7284572160
Epoch [222/500] took 171.4364321231842s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4096552512356053, train accuracy: 0.47920927062031354
Val mean loss: 1.6344047494050933, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2899 			 1998 			 1188
2143 			 2123 			 1016
2083 			 1966 			 1021
1488 			 1683 			 774
1224 			 1657 			 635
432 			 842 			 287
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 109
298 			 248 			 76
247 			 251 			 79
172 			 169 			 49
137 			 237 			 45
71 			 116 			 32
Max memory allocated: 14709633024; Memory allocated: 7154407424
Epoch [223/500] took 171.1679286956787s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4093067939407729, train accuracy: 0.4809621189989288
Val mean loss: 1.6560806181372665, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2875 			 1998 			 1176
2167 			 2123 			 1028
2070 			 1966 			 1029
1517 			 1683 			 788
1188 			 1657 			 622
452 			 842 			 296
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
364 			 263 			 109
291 			 248 			 74
247 			 251 			 79
167 			 169 			 48
147 			 237 			 47
68 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7223262208
Epoch [224/500] took 172.4776918888092s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4070037893045728, train accuracy: 0.48115687992988604
Val mean loss: 1.6395780109777682, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2890 			 1998 			 1198
2149 			 2123 			 1019
2134 			 1966 			 1046
1499 			 1683 			 783
1183 			 1657 			 619
414 			 842 			 276
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
377 			 263 			 108
271 			 248 			 70
242 			 251 			 78
176 			 169 			 49
147 			 237 			 45
71 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7237540864
Epoch [225/500] took 172.28162384033203s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4059111414668717, train accuracy: 0.4824228259811082
Val mean loss: 1.6485419680432576, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2881 			 1998 			 1189
2094 			 2123 			 996
2054 			 1966 			 1023
1560 			 1683 			 809
1217 			 1657 			 638
463 			 842 			 299
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
367 			 263 			 106
284 			 248 			 75
251 			 251 			 79
176 			 169 			 49
138 			 237 			 44
68 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7157725184
Epoch [226/500] took 172.45934534072876s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4049825051863245, train accuracy: 0.4828123478430227
Val mean loss: 1.6506936084933397, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2900 			 1998 			 1197
2125 			 2123 			 1020
2111 			 1966 			 1037
1449 			 1683 			 772
1241 			 1657 			 639
443 			 842 			 293
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
374 			 263 			 106
295 			 248 			 75
243 			 251 			 78
175 			 169 			 49
127 			 237 			 40
70 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7201258496
Epoch [227/500] took 172.19045066833496s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.406218867807002, train accuracy: 0.4815464017918006
Val mean loss: 1.6459942736276767, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2879 			 1998 			 1190
2099 			 2123 			 1005
2100 			 1966 			 1041
1590 			 1683 			 808
1154 			 1657 			 610
447 			 842 			 291
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
362 			 263 			 105
311 			 248 			 80
242 			 251 			 78
161 			 169 			 45
141 			 237 			 45
67 			 116 			 24
Max memory allocated: 14709633024; Memory allocated: 7214283776
Epoch [228/500] took 171.79740834236145s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4058142696214242, train accuracy: 0.48144902132632195
Val mean loss: 1.6572024996687726, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2873 			 1998 			 1190
2146 			 2123 			 1027
2159 			 1966 			 1055
1479 			 1683 			 776
1183 			 1657 			 617
429 			 842 			 279
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
355 			 263 			 104
308 			 248 			 79
232 			 251 			 75
177 			 169 			 51
146 			 237 			 47
66 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7208156160
Epoch [229/500] took 171.2633810043335s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4039929288198643, train accuracy: 0.4836887720323303
Val mean loss: 1.6456046075355717, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2850 			 1998 			 1191
2176 			 2123 			 1037
2091 			 1966 			 1045
1522 			 1683 			 790
1179 			 1657 			 616
451 			 842 			 288
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 102
287 			 248 			 74
230 			 251 			 75
190 			 169 			 53
151 			 237 			 46
73 			 116 			 31
Max memory allocated: 14709633024; Memory allocated: 7194441728
Epoch [230/500] took 171.96931838989258s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4034905088282077, train accuracy: 0.4829097283085013
Val mean loss: 1.6494148591669595, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2897 			 1998 			 1194
2140 			 2123 			 1027
2015 			 1966 			 1011
1560 			 1683 			 815
1215 			 1657 			 623
442 			 842 			 289
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 105
292 			 248 			 74
255 			 251 			 78
169 			 169 			 46
139 			 237 			 43
69 			 116 			 31
Max memory allocated: 14709633024; Memory allocated: 7193737216
Epoch [231/500] took 171.3679428100586s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4031152766070263, train accuracy: 0.48057259713701433
Val mean loss: 1.654327828709672, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2889 			 1998 			 1185
2126 			 2123 			 1025
2155 			 1966 			 1058
1486 			 1683 			 778
1189 			 1657 			 607
424 			 842 			 282
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
375 			 263 			 109
272 			 248 			 73
245 			 251 			 77
179 			 169 			 48
148 			 237 			 48
65 			 116 			 27
Max memory allocated: 14709633024; Memory allocated: 7355033600
Epoch [232/500] took 171.70889401435852s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4035746887836873, train accuracy: 0.48339663063589444
Val mean loss: 1.6567920911602858, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2960 			 1998 			 1217
2115 			 2123 			 1014
2057 			 1966 			 1028
1543 			 1683 			 808
1172 			 1657 			 609
422 			 842 			 288
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 100
280 			 248 			 73
252 			 251 			 81
170 			 169 			 48
155 			 237 			 47
73 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7205469184
Epoch [233/500] took 171.05915236473083s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4029122750707133, train accuracy: 0.4829097283085013
Val mean loss: 1.655387660352195, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2989 			 1998 			 1220
2034 			 2123 			 991
2092 			 1966 			 1039
1510 			 1683 			 796
1195 			 1657 			 622
449 			 842 			 291
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 98
310 			 248 			 82
245 			 251 			 78
173 			 169 			 48
141 			 237 			 42
74 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7220362240
Epoch [234/500] took 171.52708339691162s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4014069313572204, train accuracy: 0.48651280553121046
Val mean loss: 1.688169729418871, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2828 			 1998 			 1192
2170 			 2123 			 1038
2128 			 1966 			 1056
1506 			 1683 			 792
1192 			 1657 			 624
445 			 842 			 294
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
380 			 263 			 106
279 			 248 			 71
229 			 251 			 73
184 			 169 			 50
145 			 237 			 47
67 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7206353920
Epoch [235/500] took 172.644366979599s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4015461429257259, train accuracy: 0.48495471808355245
Val mean loss: 1.644838536657938, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2951 			 1998 			 1218
2125 			 2123 			 1025
2074 			 1966 			 1030
1504 			 1683 			 794
1180 			 1657 			 619
435 			 842 			 294
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
366 			 263 			 106
281 			 248 			 72
231 			 251 			 76
181 			 169 			 53
153 			 237 			 48
72 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7271841792
Epoch [236/500] took 172.06368565559387s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.4003417031415897, train accuracy: 0.4857337618073814
Val mean loss: 1.6486507334360263, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2837 			 1998 			 1190
2050 			 2123 			 997
2133 			 1966 			 1062
1525 			 1683 			 798
1289 			 1657 			 654
435 			 842 			 287
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 105
306 			 248 			 77
218 			 251 			 75
193 			 169 			 54
136 			 237 			 40
71 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7215586304
Epoch [237/500] took 171.05141401290894s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3984231451218745, train accuracy: 0.4854416204109456
Val mean loss: 1.6444017916190914, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2854 			 1998 			 1191
2203 			 2123 			 1051
2028 			 1966 			 1025
1556 			 1683 			 815
1180 			 1657 			 615
448 			 842 			 288
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 107
291 			 248 			 76
249 			 251 			 76
169 			 169 			 48
141 			 237 			 43
69 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7236090880
Epoch [238/500] took 171.27790427207947s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3975571698488847, train accuracy: 0.48661018599668904
Val mean loss: 1.6507898249277255, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2942 			 1998 			 1224
2093 			 2123 			 1017
2142 			 1966 			 1049
1457 			 1683 			 778
1202 			 1657 			 634
433 			 842 			 295
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
332 			 263 			 99
292 			 248 			 77
230 			 251 			 76
203 			 169 			 55
149 			 237 			 48
78 			 116 			 33
Max memory allocated: 14709633024; Memory allocated: 7234223104
Epoch [239/500] took 171.87226343154907s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3970429473948256, train accuracy: 0.48729184925503943
Val mean loss: 1.650015601297704, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2815 			 1998 			 1178
2150 			 2123 			 1028
2007 			 1966 			 1025
1649 			 1683 			 850
1179 			 1657 			 613
469 			 842 			 310
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 105
273 			 248 			 70
258 			 251 			 81
174 			 169 			 47
153 			 237 			 48
67 			 116 			 29
Max memory allocated: 14709633024; Memory allocated: 7202642944
Epoch [240/500] took 171.57000136375427s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3978051645362117, train accuracy: 0.4835913915668517
Val mean loss: 1.6477943775130481, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2928 			 1998 			 1211
2090 			 2123 			 1017
2153 			 1966 			 1052
1454 			 1683 			 770
1212 			 1657 			 630
432 			 842 			 286
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 102
307 			 248 			 79
217 			 251 			 71
209 			 169 			 57
134 			 237 			 41
66 			 116 			 26
Max memory allocated: 14709633024; Memory allocated: 7240858624
Epoch [241/500] took 171.99472761154175s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3957455473896871, train accuracy: 0.48651280553121046
Val mean loss: 1.6496319131153385, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2777 			 1998 			 1166
2180 			 2123 			 1047
2006 			 1966 			 1016
1655 			 1683 			 846
1217 			 1657 			 631
434 			 842 			 290
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
377 			 263 			 108
263 			 248 			 69
264 			 251 			 85
165 			 169 			 48
144 			 237 			 45
71 			 116 			 28
Max memory allocated: 14709633024; Memory allocated: 7253745664
Epoch [242/500] took 171.3711633682251s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3943033604607034, train accuracy: 0.48427305482520205
Val mean loss: 1.6667963876956846, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2877 			 1998 			 1201
2095 			 2123 			 1013
2118 			 1966 			 1042
1510 			 1683 			 794
1227 			 1657 			 630
442 			 842 			 293
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 106
297 			 248 			 75
237 			 251 			 76
176 			 169 			 48
146 			 237 			 45
69 			 116 			 30
Max memory allocated: 14709633024; Memory allocated: 7248175104
Epoch [243/500] took 171.92379307746887s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3950998363465164, train accuracy: 0.48846041484078295
Val mean loss: 1.6469933347004215, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2906 			 1998 			 1220
2110 			 2123 			 1028
2061 			 1966 			 1039
1485 			 1683 			 789
1265 			 1657 			 648
442 			 842 			 292
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 103
284 			 248 			 73
260 			 251 			 83
177 			 169 			 47
139 			 237 			 43
70 			 116 			 30
Max memory allocated: 14711205888; Memory allocated: 7279591424
Epoch [244/500] took 171.5975022315979s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3946579479354193, train accuracy: 0.4868049469276463
Val mean loss: 1.6477724982471, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2828 			 1998 			 1185
2096 			 2123 			 1019
2119 			 1966 			 1052
1581 			 1683 			 828
1204 			 1657 			 622
441 			 842 			 293
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 106
313 			 248 			 81
235 			 251 			 78
163 			 169 			 48
144 			 237 			 45
68 			 116 			 28
Max memory allocated: 14711205888; Memory allocated: 7154407424
Epoch [245/500] took 171.61328148841858s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3937114406597577, train accuracy: 0.4876813711169539
Val mean loss: 1.6624266432552803, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2860 			 1998 			 1202
2131 			 2123 			 1025
2113 			 1966 			 1051
1498 			 1683 			 798
1224 			 1657 			 637
443 			 842 			 295
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 104
307 			 248 			 80
244 			 251 			 78
169 			 169 			 47
133 			 237 			 41
75 			 116 			 30
Max memory allocated: 14711205888; Memory allocated: 7187544064
Epoch [246/500] took 171.921226978302s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.392755506566009, train accuracy: 0.48777875158243256
Val mean loss: 1.6300494801707384, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2880 			 1998 			 1203
2202 			 2123 			 1056
2047 			 1966 			 1031
1529 			 1683 			 812
1162 			 1657 			 608
449 			 842 			 299
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 100
288 			 248 			 74
247 			 251 			 78
181 			 169 			 51
142 			 237 			 45
70 			 116 			 27
Max memory allocated: 14711205888; Memory allocated: 7229062144
Epoch [247/500] took 171.60187935829163s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3927768461429442, train accuracy: 0.4918687311325348
Val mean loss: 1.6568962655416348, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2857 			 1998 			 1209
2117 			 2123 			 1029
2093 			 1966 			 1053
1519 			 1683 			 813
1225 			 1657 			 644
458 			 842 			 303
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 102
286 			 248 			 75
254 			 251 			 81
173 			 169 			 47
143 			 237 			 44
72 			 116 			 29
Max memory allocated: 14711205888; Memory allocated: 7197276160
Epoch [248/500] took 172.34325981140137s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3919943355696967, train accuracy: 0.4891420780991333
Val mean loss: 1.6442686668256434, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2856 			 1998 			 1194
2098 			 2123 			 1023
2063 			 1966 			 1041
1550 			 1683 			 815
1251 			 1657 			 651
451 			 842 			 299
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 104
298 			 248 			 79
242 			 251 			 79
175 			 169 			 49
132 			 237 			 46
72 			 116 			 30
Max memory allocated: 14711205888; Memory allocated: 7189837824
Epoch [249/500] took 171.87707924842834s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3896566592272939, train accuracy: 0.49128444833966306
Val mean loss: 1.6544649600982666, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2861 			 1998 			 1208
2169 			 2123 			 1053
2117 			 1966 			 1064
1500 			 1683 			 806
1181 			 1657 			 624
441 			 842 			 290
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
346 			 263 			 100
287 			 248 			 76
242 			 251 			 76
178 			 169 			 49
153 			 237 			 50
78 			 116 			 33
Max memory allocated: 14711205888; Memory allocated: 7229717504
Epoch [250/500] took 172.05820965766907s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.391234967938836, train accuracy: 0.4924530139254066
Val mean loss: 1.6558974545176437, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2856 			 1998 			 1208
2156 			 2123 			 1049
2047 			 1966 			 1043
1555 			 1683 			 821
1196 			 1657 			 636
459 			 842 			 300
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
362 			 263 			 101
290 			 248 			 73
249 			 251 			 78
173 			 169 			 47
138 			 237 			 45
72 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7202077696
Epoch [251/500] took 171.90792417526245s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3883768606037366, train accuracy: 0.4915765897360989
Val mean loss: 1.651322396790109, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2799 			 1998 			 1190
2067 			 2123 			 1016
2137 			 1966 			 1064
1576 			 1683 			 831
1232 			 1657 			 646
458 			 842 			 301
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 263 			 109
288 			 248 			 77
242 			 251 			 79
173 			 169 			 50
147 			 237 			 44
66 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7238892544
Epoch [252/500] took 172.5788116455078s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3896966960942634, train accuracy: 0.49167397020157755
Val mean loss: 1.6515695612605026, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2824 			 1998 			 1192
2180 			 2123 			 1049
2069 			 1966 			 1047
1525 			 1683 			 819
1231 			 1657 			 645
440 			 842 			 297
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
364 			 263 			 108
267 			 248 			 70
254 			 251 			 81
169 			 169 			 50
158 			 237 			 50
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7293452288
Epoch [253/500] took 171.56384706497192s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3884742196846602, train accuracy: 0.4902132632193982
Val mean loss: 1.6448386674974023, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2841 			 1998 			 1194
2086 			 2123 			 1021
2089 			 1966 			 1052
1567 			 1683 			 826
1218 			 1657 			 635
468 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 107
285 			 248 			 74
254 			 251 			 80
169 			 169 			 47
148 			 237 			 48
67 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7225187328
Epoch [254/500] took 171.40931224822998s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3880243435084263, train accuracy: 0.49196611159801346
Val mean loss: 1.648406586995939, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2869 			 1998 			 1206
2113 			 2123 			 1036
2059 			 1966 			 1044
1546 			 1683 			 813
1233 			 1657 			 650
449 			 842 			 303
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 107
294 			 248 			 76
254 			 251 			 81
168 			 169 			 47
138 			 237 			 44
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7237778432
Epoch [255/500] took 171.40642619132996s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.386958818197993, train accuracy: 0.49011588275391954
Val mean loss: 1.6474313387056676, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2845 			 1998 			 1208
2177 			 2123 			 1050
2122 			 1966 			 1064
1484 			 1683 			 793
1215 			 1657 			 633
426 			 842 			 285
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 96
277 			 248 			 73
237 			 251 			 75
195 			 169 			 55
147 			 237 			 42
74 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7200881664
Epoch [256/500] took 171.63115119934082s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.387051034939252, train accuracy: 0.49040802415035545
Val mean loss: 1.6568091526264097, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2867 			 1998 			 1202
2098 			 2123 			 1023
2104 			 1966 			 1053
1526 			 1683 			 814
1211 			 1657 			 641
463 			 842 			 303
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 101
287 			 248 			 75
232 			 251 			 73
189 			 169 			 54
158 			 237 			 51
68 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7222819840
Epoch [257/500] took 172.16107726097107s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3854616913840034, train accuracy: 0.4948875255623722
Val mean loss: 1.662128416503348, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2744 			 1998 			 1187
2168 			 2123 			 1062
2113 			 1966 			 1062
1587 			 1683 			 829
1209 			 1657 			 643
448 			 842 			 299
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
379 			 263 			 107
285 			 248 			 77
223 			 251 			 73
181 			 169 			 52
147 			 237 			 47
69 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7201504256
Epoch [258/500] took 172.4795205593109s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3851557097331015, train accuracy: 0.49167397020157755
Val mean loss: 1.6426582045671416, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2936 			 1998 			 1229
2105 			 2123 			 1034
2082 			 1966 			 1046
1491 			 1683 			 808
1192 			 1657 			 629
463 			 842 			 303
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 103
271 			 248 			 69
242 			 251 			 77
180 			 169 			 53
158 			 237 			 50
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7201537024
Epoch [259/500] took 170.9535264968872s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.382888575952001, train accuracy: 0.49216087252897067
Val mean loss: 1.656738554559103, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2870 			 1998 			 1209
2084 			 2123 			 1024
2051 			 1966 			 1045
1570 			 1683 			 825
1252 			 1657 			 656
442 			 842 			 295
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 101
289 			 248 			 74
248 			 251 			 79
177 			 169 			 50
159 			 237 			 49
73 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7185741824
Epoch [260/500] took 171.43942975997925s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3816466847684152, train accuracy: 0.49556918882072254
Val mean loss: 1.6642172976237972, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2837 			 1998 			 1209
2114 			 2123 			 1036
2072 			 1966 			 1055
1562 			 1683 			 841
1243 			 1657 			 653
441 			 842 			 295
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
332 			 263 			 95
298 			 248 			 78
258 			 251 			 82
169 			 169 			 49
150 			 237 			 46
77 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7189706752
Epoch [261/500] took 172.01032304763794s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3837082096349413, train accuracy: 0.4945953841659363
Val mean loss: 1.6486214486564077, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2824 			 1998 			 1206
2142 			 2123 			 1051
2100 			 1966 			 1053
1512 			 1683 			 815
1227 			 1657 			 647
464 			 842 			 307
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 99
278 			 248 			 70
254 			 251 			 81
182 			 169 			 52
146 			 237 			 44
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7279460352
Epoch [262/500] took 172.51911973953247s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3826414524951829, train accuracy: 0.4945953841659363
Val mean loss: 1.6559846575667219, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2815 			 1998 			 1199
2177 			 2123 			 1047
2078 			 1966 			 1052
1540 			 1683 			 829
1212 			 1657 			 648
447 			 842 			 304
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
366 			 263 			 99
279 			 248 			 73
239 			 251 			 76
177 			 169 			 52
151 			 237 			 51
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7225179136
Epoch [263/500] took 172.27640080451965s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3832884718695906, train accuracy: 0.49274515532184243
Val mean loss: 1.653372453480232, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2856 			 1998 			 1207
2072 			 2123 			 1022
2112 			 1966 			 1064
1559 			 1683 			 823
1206 			 1657 			 639
464 			 842 			 305
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 103
302 			 248 			 81
236 			 251 			 75
173 			 169 			 49
149 			 237 			 46
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7190919168
Epoch [264/500] took 171.84937953948975s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3819068677700197, train accuracy: 0.49362157951115004
Val mean loss: 1.6686398750398217, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2803 			 1998 			 1207
2205 			 2123 			 1059
2102 			 1966 			 1057
1463 			 1683 			 797
1228 			 1657 			 646
468 			 842 			 303
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
363 			 263 			 105
270 			 248 			 70
236 			 251 			 78
194 			 169 			 55
150 			 237 			 47
71 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7200922624
Epoch [265/500] took 171.68229913711548s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3799343365375127, train accuracy: 0.4942058623040218
Val mean loss: 1.6520616601153117, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2871 			 1998 			 1219
2036 			 2123 			 1011
2136 			 1966 			 1073
1552 			 1683 			 829
1227 			 1657 			 643
447 			 842 			 300
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 105
304 			 248 			 78
223 			 251 			 72
193 			 169 			 54
140 			 237 			 46
70 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7192967168
Epoch [266/500] took 171.6743688583374s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3801728104505213, train accuracy: 0.4979063199922096
Val mean loss: 1.6611998924394933, val accuracy: 0.30218068535825543

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2753 			 1998 			 1190
2209 			 2123 			 1082
2019 			 1966 			 1033
1604 			 1683 			 851
1214 			 1657 			 648
470 			 842 			 309
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 105
283 			 248 			 76
243 			 251 			 78
167 			 169 			 50
152 			 237 			 46
74 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7199095808
Epoch [267/500] took 171.99084448814392s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3780296001107522, train accuracy: 0.49897750511247446
Val mean loss: 1.6559711811019153, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2760 			 1998 			 1200
2146 			 2123 			 1067
2100 			 1966 			 1064
1502 			 1683 			 809
1283 			 1657 			 671
478 			 842 			 313
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
382 			 263 			 111
282 			 248 			 72
238 			 251 			 77
183 			 169 			 54
131 			 237 			 41
68 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7226227712
Epoch [268/500] took 171.94686245918274s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3765420241519297, train accuracy: 0.49517966695880805
Val mean loss: 1.6533799636654738, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2875 			 1998 			 1222
2109 			 2123 			 1035
2067 			 1966 			 1053
1572 			 1683 			 830
1188 			 1657 			 641
458 			 842 			 304
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
364 			 263 			 107
287 			 248 			 74
249 			 251 			 79
170 			 169 			 49
144 			 237 			 47
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7198915584
Epoch [269/500] took 171.77197289466858s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.377040526205877, train accuracy: 0.4944006232349791
Val mean loss: 1.661732990567277, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2838 			 1998 			 1211
2185 			 2123 			 1065
2050 			 1966 			 1042
1511 			 1683 			 814
1224 			 1657 			 644
461 			 842 			 301
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
363 			 263 			 103
272 			 248 			 72
259 			 251 			 82
179 			 169 			 50
146 			 237 			 48
65 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7191631872
Epoch [270/500] took 171.6578826904297s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3765190505535803, train accuracy: 0.4972246567338592
Val mean loss: 1.6707758176617507, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2768 			 1998 			 1198
2099 			 2123 			 1041
2146 			 1966 			 1081
1556 			 1683 			 830
1244 			 1657 			 652
456 			 842 			 304
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 104
302 			 248 			 78
233 			 251 			 75
179 			 169 			 53
150 			 237 			 45
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7207140352
Epoch [271/500] took 172.2429177761078s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3773812813179516, train accuracy: 0.4987827441815172
Val mean loss: 1.648066552673898, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2784 			 1998 			 1200
2160 			 2123 			 1061
2042 			 1966 			 1041
1588 			 1683 			 853
1241 			 1657 			 661
454 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
367 			 263 			 108
287 			 248 			 74
245 			 251 			 78
169 			 169 			 51
142 			 237 			 44
74 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7211449344
Epoch [272/500] took 171.31530904769897s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3752331767126778, train accuracy: 0.4988801246469958
Val mean loss: 1.6542546400209752, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2827 			 1998 			 1210
2177 			 2123 			 1068
2062 			 1966 			 1048
1519 			 1683 			 818
1213 			 1657 			 663
471 			 842 			 316
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 98
295 			 248 			 76
252 			 251 			 82
164 			 169 			 47
141 			 237 			 42
74 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7289282560
Epoch [273/500] took 172.3591685295105s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3766460537539094, train accuracy: 0.49547180835524396
Val mean loss: 1.6558531261071927, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2796 			 1998 			 1196
2086 			 2123 			 1040
2155 			 1966 			 1079
1527 			 1683 			 820
1264 			 1657 			 659
441 			 842 			 294
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 99
294 			 248 			 74
229 			 251 			 75
184 			 169 			 54
146 			 237 			 45
72 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7192352768
Epoch [274/500] took 171.58356356620789s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3745516122687271, train accuracy: 0.4980037004576882
Val mean loss: 1.677526130908873, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2778 			 1998 			 1186
2117 			 2123 			 1045
2105 			 1966 			 1079
1557 			 1683 			 840
1262 			 1657 			 658
450 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
380 			 263 			 108
295 			 248 			 77
218 			 251 			 71
193 			 169 			 57
126 			 237 			 43
72 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7223098368
Epoch [275/500] took 171.27424716949463s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.373116767295053, train accuracy: 0.49936702697438895
Val mean loss: 1.6576922230604219, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2889 			 1998 			 1234
2121 			 2123 			 1041
2023 			 1966 			 1046
1567 			 1683 			 847
1218 			 1657 			 656
451 			 842 			 304
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 103
291 			 248 			 77
240 			 251 			 77
186 			 169 			 53
127 			 237 			 40
75 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7243348992
Epoch [276/500] took 171.35963606834412s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3726343306425577, train accuracy: 0.4972246567338592
Val mean loss: 1.662777551790563, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2802 			 1998 			 1197
2119 			 2123 			 1044
2047 			 1966 			 1056
1612 			 1683 			 856
1199 			 1657 			 637
490 			 842 			 316
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
369 			 263 			 98
290 			 248 			 72
242 			 251 			 78
165 			 169 			 49
151 			 237 			 45
67 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7230921728
Epoch [277/500] took 172.51113772392273s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3719778413713164, train accuracy: 0.49868536371603855
Val mean loss: 1.6600666075218014, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2799 			 1998 			 1201
2148 			 2123 			 1064
2148 			 1966 			 1086
1517 			 1683 			 822
1218 			 1657 			 643
439 			 842 			 305
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 98
296 			 248 			 75
234 			 251 			 75
177 			 169 			 52
153 			 237 			 46
75 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7235443712
Epoch [278/500] took 172.38508009910583s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3722938989924494, train accuracy: 0.4987827441815172
Val mean loss: 1.6507013716348788, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2835 			 1998 			 1217
2123 			 2123 			 1044
2048 			 1966 			 1050
1548 			 1683 			 839
1248 			 1657 			 663
467 			 842 			 309
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 100
288 			 248 			 74
247 			 251 			 76
180 			 169 			 52
145 			 237 			 46
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7189837824
Epoch [279/500] took 172.5301012992859s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.373855950676392, train accuracy: 0.5000486902327393
Val mean loss: 1.6464721255186128, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2825 			 1998 			 1226
2099 			 2123 			 1045
2073 			 1966 			 1052
1571 			 1683 			 847
1244 			 1657 			 659
457 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 97
298 			 248 			 77
246 			 251 			 76
173 			 169 			 50
151 			 237 			 50
71 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7225097216
Epoch [280/500] took 171.39545011520386s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3696501596694424, train accuracy: 0.50141201674944
Val mean loss: 1.640778948621052, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2802 			 1998 			 1217
2207 			 2123 			 1076
2060 			 1966 			 1056
1552 			 1683 			 846
1205 			 1657 			 648
443 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
348 			 263 			 101
269 			 248 			 70
256 			 251 			 82
177 			 169 			 51
156 			 237 			 46
78 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7207451648
Epoch [281/500] took 171.38270592689514s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.369988778669886, train accuracy: 0.4987827441815172
Val mean loss: 1.6459273681408022, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2795 			 1998 			 1202
2107 			 2123 			 1037
2127 			 1966 			 1083
1542 			 1683 			 830
1232 			 1657 			 659
466 			 842 			 311
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
328 			 263 			 93
282 			 248 			 73
250 			 251 			 80
194 			 169 			 54
153 			 237 			 44
77 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7190550528
Epoch [282/500] took 171.63405060768127s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.371010078076633, train accuracy: 0.5021910604732691
Val mean loss: 1.6538520586199876, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2753 			 1998 			 1201
2144 			 2123 			 1062
2101 			 1966 			 1075
1551 			 1683 			 837
1233 			 1657 			 659
487 			 842 			 323
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 103
287 			 248 			 74
231 			 251 			 75
201 			 169 			 57
141 			 237 			 44
70 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7200455680
Epoch [283/500] took 170.73568558692932s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3677432113718764, train accuracy: 0.5016067776803973
Val mean loss: 1.6702118937562151, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2818 			 1998 			 1221
2090 			 2123 			 1043
2088 			 1966 			 1065
1557 			 1683 			 846
1261 			 1657 			 670
455 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 102
303 			 248 			 77
225 			 251 			 74
194 			 169 			 54
143 			 237 			 42
74 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7199700992
Epoch [284/500] took 171.5115385055542s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3690711631210422, train accuracy: 0.5036517674554485
Val mean loss: 1.654843533911356, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2678 			 1998 			 1190
2198 			 2123 			 1075
2052 			 1966 			 1061
1595 			 1683 			 854
1266 			 1657 			 678
480 			 842 			 314
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 104
284 			 248 			 76
246 			 251 			 77
182 			 169 			 51
146 			 237 			 43
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7241317376
Epoch [285/500] took 170.5686960220337s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.366202769621139, train accuracy: 0.5019962995423118
Val mean loss: 1.6592259203515403, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2797 			 1998 			 1219
2104 			 2123 			 1053
2121 			 1966 			 1074
1554 			 1683 			 841
1255 			 1657 			 666
438 			 842 			 302
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 100
281 			 248 			 72
246 			 251 			 77
182 			 169 			 51
149 			 237 			 46
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7190312960
Epoch [286/500] took 170.6684010028839s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.365969009117174, train accuracy: 0.502483201869705
Val mean loss: 1.662052538336777, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2768 			 1998 			 1211
2173 			 2123 			 1071
2063 			 1966 			 1052
1583 			 1683 			 853
1211 			 1657 			 653
471 			 842 			 320
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 99
284 			 248 			 73
247 			 251 			 81
167 			 169 			 50
153 			 237 			 46
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7202094080
Epoch [287/500] took 171.04766964912415s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3649432867115532, train accuracy: 0.5007303534910897
Val mean loss: 1.6419286001019362, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2841 			 1998 			 1234
2097 			 2123 			 1035
2091 			 1966 			 1060
1510 			 1683 			 823
1277 			 1657 			 684
453 			 842 			 306
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
355 			 263 			 102
297 			 248 			 77
236 			 251 			 76
179 			 169 			 52
142 			 237 			 44
75 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7219149824
Epoch [288/500] took 171.35424327850342s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3655463980737133, train accuracy: 0.5011198753530042
Val mean loss: 1.6608612043101614, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2819 			 1998 			 1223
2153 			 2123 			 1059
2050 			 1966 			 1046
1525 			 1683 			 832
1264 			 1657 			 676
458 			 842 			 310
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 98
288 			 248 			 76
239 			 251 			 79
191 			 169 			 54
147 			 237 			 43
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7157725184
Epoch [289/500] took 171.54502415657043s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3653079783805062, train accuracy: 0.5036517674554485
Val mean loss: 1.6707140265441522, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2713 			 1998 			 1203
2178 			 2123 			 1077
2056 			 1966 			 1060
1630 			 1683 			 862
1209 			 1657 			 652
483 			 842 			 318
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 263 			 108
272 			 248 			 72
265 			 251 			 85
162 			 169 			 47
146 			 237 			 47
71 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7198989312
Epoch [290/500] took 171.06476163864136s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.364082774640615, train accuracy: 0.5042360502483202
Val mean loss: 1.6523242898103667, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2803 			 1998 			 1219
2084 			 2123 			 1040
2121 			 1966 			 1083
1536 			 1683 			 835
1252 			 1657 			 682
473 			 842 			 319
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
362 			 263 			 105
293 			 248 			 77
247 			 251 			 79
168 			 169 			 49
151 			 237 			 48
63 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7256481792
Epoch [291/500] took 171.03218913078308s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3644972356309029, train accuracy: 0.5054046158340637
Val mean loss: 1.6685339008889548, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2780 			 1998 			 1216
2180 			 2123 			 1079
2048 			 1966 			 1058
1524 			 1683 			 845
1291 			 1657 			 684
446 			 842 			 308
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 106
281 			 248 			 72
259 			 251 			 82
172 			 169 			 51
144 			 237 			 43
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7190001664
Epoch [292/500] took 170.60179257392883s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3617604796388811, train accuracy: 0.5068653228162431
Val mean loss: 1.6612110108864018, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2745 			 1998 			 1216
2097 			 2123 			 1054
2155 			 1966 			 1094
1592 			 1683 			 858
1208 			 1657 			 658
472 			 842 			 325
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 100
292 			 248 			 76
244 			 251 			 78
169 			 169 			 50
151 			 237 			 47
76 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7201012736
Epoch [293/500] took 170.81041884422302s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3618653622743124, train accuracy: 0.5055019962995423
Val mean loss: 1.6566236629718687, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2760 			 1998 			 1213
2225 			 2123 			 1093
2052 			 1966 			 1063
1514 			 1683 			 831
1233 			 1657 			 667
485 			 842 			 324
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 102
265 			 248 			 68
256 			 251 			 81
181 			 169 			 52
160 			 237 			 48
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7208909824
Epoch [294/500] took 171.19853830337524s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3617942199528774, train accuracy: 0.5055019962995423
Val mean loss: 1.6543044724115512, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2786 			 1998 			 1219
2019 			 2123 			 1037
2119 			 1966 			 1077
1561 			 1683 			 846
1298 			 1657 			 687
486 			 842 			 325
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
363 			 263 			 102
315 			 248 			 79
233 			 251 			 74
178 			 169 			 51
132 			 237 			 39
63 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7202692096
Epoch [295/500] took 171.29672193527222s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3612404244711094, train accuracy: 0.5070600837472004
Val mean loss: 1.6631901903850277, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2762 			 1998 			 1217
2188 			 2123 			 1082
2092 			 1966 			 1076
1549 			 1683 			 848
1213 			 1657 			 667
465 			 842 			 317
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 95
293 			 248 			 78
228 			 251 			 73
191 			 169 			 54
154 			 237 			 49
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7190689792
Epoch [296/500] took 171.35007786750793s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3605132882840165, train accuracy: 0.5059888986269354
Val mean loss: 1.6520011948376168, val accuracy: 0.3037383177570093

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2771 			 1998 			 1230
2168 			 2123 			 1078
2070 			 1966 			 1069
1548 			 1683 			 842
1240 			 1657 			 659
472 			 842 			 318
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
371 			 263 			 110
282 			 248 			 76
227 			 251 			 75
196 			 169 			 56
135 			 237 			 41
73 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7202257920
Epoch [297/500] took 171.49659323692322s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.361048988464094, train accuracy: 0.50637842048885
Val mean loss: 1.6542083868166295, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2742 			 1998 			 1208
2180 			 2123 			 1085
2029 			 1966 			 1059
1627 			 1683 			 861
1229 			 1657 			 671
462 			 842 			 316
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
363 			 263 			 101
280 			 248 			 72
249 			 251 			 79
168 			 169 			 49
151 			 237 			 45
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7201225728
Epoch [298/500] took 171.05708956718445s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3591346504903656, train accuracy: 0.5085207907293797
Val mean loss: 1.6484874690451272, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2689 			 1998 			 1205
2181 			 2123 			 1086
2104 			 1966 			 1077
1557 			 1683 			 846
1258 			 1657 			 681
480 			 842 			 327
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
396 			 263 			 110
264 			 248 			 68
240 			 251 			 81
167 			 169 			 49
144 			 237 			 45
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7273889792
Epoch [299/500] took 171.13241243362427s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3564359142772877, train accuracy: 0.5072548446781575
Val mean loss: 1.6512305416711948, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2928 			 1998 			 1267
2113 			 2123 			 1069
2060 			 1966 			 1066
1516 			 1683 			 828
1204 			 1657 			 664
448 			 842 			 315
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
333 			 263 			 97
287 			 248 			 73
249 			 251 			 79
174 			 169 			 49
164 			 237 			 49
77 			 116 			 34
Max memory allocated: 14723398656; Memory allocated: 7209163776
Epoch [300/500] took 171.49972558021545s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3583971228554985, train accuracy: 0.5052098549031064
Val mean loss: 1.657267523974907, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2702 			 1998 			 1191
2118 			 2123 			 1058
2134 			 1966 			 1095
1560 			 1683 			 849
1272 			 1657 			 674
483 			 842 			 321
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
355 			 263 			 97
295 			 248 			 77
219 			 251 			 72
190 			 169 			 54
152 			 237 			 47
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7216937984
Epoch [301/500] took 171.65056037902832s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3588765176285835, train accuracy: 0.5078391274710293
Val mean loss: 1.6805605626687772, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2855 			 1998 			 1251
2112 			 2123 			 1064
2001 			 1966 			 1052
1577 			 1683 			 847
1267 			 1657 			 688
457 			 842 			 313
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 263 			 95
306 			 248 			 79
250 			 251 			 82
176 			 169 			 50
142 			 237 			 42
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7244594176
Epoch [302/500] took 171.34676313400269s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3565733689014043, train accuracy: 0.5080338884019866
Val mean loss: 1.6455119557496978, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2705 			 1998 			 1205
2173 			 2123 			 1078
2136 			 1966 			 1094
1563 			 1683 			 851
1219 			 1657 			 670
473 			 842 			 319
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 105
288 			 248 			 76
233 			 251 			 74
173 			 169 			 50
145 			 237 			 46
73 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7201815552
Epoch [303/500] took 172.0316572189331s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.356686043219403, train accuracy: 0.5058915181614568
Val mean loss: 1.6692412103094705, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2862 			 1998 			 1243
2120 			 2123 			 1068
2077 			 1966 			 1068
1524 			 1683 			 835
1227 			 1657 			 661
459 			 842 			 320
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 99
284 			 248 			 72
217 			 251 			 70
206 			 169 			 55
158 			 237 			 45
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7141136384
Epoch [304/500] took 171.06649518013s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.354967154075052, train accuracy: 0.5067679423507644
Val mean loss: 1.65226809571429, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2767 			 1998 			 1217
2106 			 2123 			 1057
2077 			 1966 			 1073
1610 			 1683 			 868
1232 			 1657 			 670
477 			 842 			 319
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
343 			 263 			 101
295 			 248 			 76
244 			 251 			 77
175 			 169 			 50
156 			 237 			 50
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7225555968
Epoch [305/500] took 170.44576120376587s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.355136305000923, train accuracy: 0.50920245398773
Val mean loss: 1.6613933691164342, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2723 			 1998 			 1208
2125 			 2123 			 1067
2063 			 1966 			 1074
1558 			 1683 			 849
1337 			 1657 			 711
463 			 842 			 320
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 97
311 			 248 			 80
229 			 251 			 75
185 			 169 			 53
148 			 237 			 45
77 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7228996608
Epoch [306/500] took 170.70214915275574s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3525762357444406, train accuracy: 0.5100788781770377
Val mean loss: 1.6617673839010842, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2740 			 1998 			 1214
2193 			 2123 			 1087
2051 			 1966 			 1067
1573 			 1683 			 861
1221 			 1657 			 676
491 			 842 			 333
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 97
282 			 248 			 72
254 			 251 			 80
173 			 169 			 51
149 			 237 			 43
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7207435264
Epoch [307/500] took 170.65643429756165s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.352601817835157, train accuracy: 0.510273639107995
Val mean loss: 1.6669998634152297, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2746 			 1998 			 1225
2129 			 2123 			 1075
2127 			 1966 			 1089
1532 			 1683 			 838
1260 			 1657 			 689
475 			 842 			 324
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 97
280 			 248 			 74
239 			 251 			 75
193 			 169 			 54
155 			 237 			 51
79 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7197703168
Epoch [308/500] took 170.45835876464844s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.352502199719628, train accuracy: 0.5119291070211316
Val mean loss: 1.6632826037523223, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2702 			 1998 			 1208
2162 			 2123 			 1077
2081 			 1966 			 1091
1549 			 1683 			 858
1288 			 1657 			 694
487 			 842 			 329
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
384 			 263 			 111
270 			 248 			 72
226 			 251 			 73
197 			 169 			 56
139 			 237 			 44
68 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7216184320
Epoch [309/500] took 171.0695276260376s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3519517123884872, train accuracy: 0.5104684000389522
Val mean loss: 1.6684343087963942, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2806 			 1998 			 1238
2115 			 2123 			 1070
2043 			 1966 			 1070
1628 			 1683 			 877
1208 			 1657 			 666
469 			 842 			 321
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 101
281 			 248 			 74
258 			 251 			 83
172 			 169 			 51
141 			 237 			 42
74 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7221001216
Epoch [310/500] took 171.31466674804688s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.352764994555916, train accuracy: 0.508423410263901
Val mean loss: 1.6739063844448183, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2764 			 1998 			 1219
2162 			 2123 			 1084
2103 			 1966 			 1082
1515 			 1683 			 841
1251 			 1657 			 680
474 			 842 			 315
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
380 			 263 			 106
274 			 248 			 71
237 			 251 			 76
188 			 169 			 53
130 			 237 			 40
75 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7201299456
Epoch [311/500] took 170.802832365036s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.350754238363367, train accuracy: 0.5119291070211316
Val mean loss: 1.6455171224547596, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2736 			 1998 			 1227
2154 			 2123 			 1080
1994 			 1966 			 1056
1630 			 1683 			 876
1271 			 1657 			 689
484 			 842 			 329
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 102
285 			 248 			 73
261 			 251 			 82
181 			 169 			 51
132 			 237 			 43
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7208369152
Epoch [312/500] took 171.44394063949585s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.351122484400265, train accuracy: 0.5103710195734735
Val mean loss: 1.6763703939391346, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2793 			 1998 			 1235
2079 			 2123 			 1060
2088 			 1966 			 1084
1631 			 1683 			 878
1213 			 1657 			 668
465 			 842 			 316
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 103
300 			 248 			 77
258 			 251 			 80
153 			 169 			 45
143 			 237 			 46
70 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7293583360
Epoch [313/500] took 170.89782071113586s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3495988047382914, train accuracy: 0.5118317265556529
Val mean loss: 1.6597970811332143, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2802 			 1998 			 1241
2179 			 2123 			 1095
2111 			 1966 			 1088
1471 			 1683 			 828
1235 			 1657 			 676
471 			 842 			 328
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 101
288 			 248 			 75
234 			 251 			 76
189 			 169 			 54
157 			 237 			 51
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7209106432
Epoch [314/500] took 170.87986087799072s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3481446088660172, train accuracy: 0.5136819553997468
Val mean loss: 1.658270934732949, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2794 			 1998 			 1234
2124 			 2123 			 1083
2068 			 1966 			 1091
1566 			 1683 			 864
1253 			 1657 			 688
464 			 842 			 315
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 102
276 			 248 			 71
258 			 251 			 81
174 			 169 			 50
152 			 237 			 42
70 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7192655872
Epoch [315/500] took 171.30115008354187s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.348471607374625, train accuracy: 0.5141688577271399
Val mean loss: 1.65720040914489, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2713 			 1998 			 1213
2168 			 2123 			 1092
2067 			 1966 			 1086
1578 			 1683 			 865
1246 			 1657 			 684
497 			 842 			 340
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 102
267 			 248 			 68
256 			 251 			 80
175 			 169 			 52
157 			 237 			 50
68 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7237385216
Epoch [316/500] took 170.4677004814148s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3467194796351258, train accuracy: 0.5118317265556529
Val mean loss: 1.6767728241478526, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2799 			 1998 			 1238
2040 			 2123 			 1052
2125 			 1966 			 1097
1566 			 1683 			 856
1272 			 1657 			 686
467 			 842 			 327
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
348 			 263 			 100
296 			 248 			 76
247 			 251 			 78
177 			 169 			 50
145 			 237 			 43
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7210482688
Epoch [317/500] took 170.95635604858398s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3469885539414355, train accuracy: 0.5151426623819262
Val mean loss: 1.6732532396549131, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2728 			 1998 			 1229
2116 			 2123 			 1073
2075 			 1966 			 1088
1618 			 1683 			 879
1255 			 1657 			 692
477 			 842 			 329
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 101
291 			 248 			 77
253 			 251 			 81
171 			 169 			 49
142 			 237 			 42
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7225973760
Epoch [318/500] took 170.68187880516052s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3467749004423433, train accuracy: 0.5119291070211316
Val mean loss: 1.6644260679803244, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2815 			 1998 			 1239
2085 			 2123 			 1061
2070 			 1966 			 1075
1537 			 1683 			 851
1291 			 1657 			 705
471 			 842 			 326
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 102
302 			 248 			 76
247 			 251 			 76
181 			 169 			 51
137 			 237 			 40
70 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7236369408
Epoch [319/500] took 171.18077206611633s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.34622243371708, train accuracy: 0.5114422046937385
Val mean loss: 1.670186691167878, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2719 			 1998 			 1210
2192 			 2123 			 1097
2074 			 1966 			 1081
1558 			 1683 			 853
1252 			 1657 			 691
474 			 842 			 320
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
369 			 263 			 104
281 			 248 			 74
242 			 251 			 78
178 			 169 			 51
138 			 237 			 43
76 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7186716672
Epoch [320/500] took 171.60246634483337s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3463995300720786, train accuracy: 0.5110526828318239
Val mean loss: 1.6730159870008143, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2821 			 1998 			 1237
2057 			 2123 			 1050
2112 			 1966 			 1092
1567 			 1683 			 867
1240 			 1657 			 679
472 			 842 			 323
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 105
311 			 248 			 81
238 			 251 			 75
178 			 169 			 51
128 			 237 			 40
69 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7207009280
Epoch [321/500] took 170.8997359275818s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3451723918736538, train accuracy: 0.5139740967961827
Val mean loss: 1.6827330560218998, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2725 			 1998 			 1208
2196 			 2123 			 1105
2059 			 1966 			 1087
1576 			 1683 			 869
1225 			 1657 			 680
488 			 842 			 329
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
373 			 263 			 109
286 			 248 			 78
245 			 251 			 78
175 			 169 			 52
136 			 237 			 40
69 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7231413248
Epoch [322/500] took 171.47888827323914s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.345686410817773, train accuracy: 0.5147531405200116
Val mean loss: 1.6603557714601842, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2790 			 1998 			 1238
2075 			 2123 			 1066
2146 			 1966 			 1115
1592 			 1683 			 873
1214 			 1657 			 675
452 			 842 			 319
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 263 			 103
296 			 248 			 77
231 			 251 			 75
172 			 169 			 48
142 			 237 			 44
75 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7242103808
Epoch [323/500] took 171.64734482765198s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.345403220794654, train accuracy: 0.5138767163307041
Val mean loss: 1.6656490622497186, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2828 			 1998 			 1251
2167 			 2123 			 1098
1991 			 1966 			 1060
1551 			 1683 			 858
1250 			 1657 			 684
482 			 842 			 326
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
337 			 263 			 99
290 			 248 			 73
256 			 251 			 83
171 			 169 			 49
155 			 237 			 49
75 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7154407424
Epoch [324/500] took 170.7890167236328s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3422295664701136, train accuracy: 0.5160190865712339
Val mean loss: 1.6675619032324813, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2692 			 1998 			 1210
2121 			 2123 			 1083
2121 			 1966 			 1101
1559 			 1683 			 864
1294 			 1657 			 707
482 			 842 			 334
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 97
296 			 248 			 78
228 			 251 			 74
184 			 169 			 53
149 			 237 			 43
78 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7212874752
Epoch [325/500] took 171.50474190711975s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.343963389084718, train accuracy: 0.5167007498295841
Val mean loss: 1.6649930302689715, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2706 			 1998 			 1215
2128 			 2123 			 1092
2113 			 1966 			 1097
1566 			 1683 			 874
1258 			 1657 			 694
498 			 842 			 334
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
369 			 263 			 104
291 			 248 			 76
228 			 251 			 75
180 			 169 			 53
149 			 237 			 43
67 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7242562560
Epoch [326/500] took 171.5940134525299s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3432954546075744, train accuracy: 0.5142662381926185
Val mean loss: 1.6711953180592234, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2779 			 1998 			 1239
2150 			 2123 			 1085
2057 			 1966 			 1083
1565 			 1683 			 866
1238 			 1657 			 681
480 			 842 			 327
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 102
288 			 248 			 77
230 			 251 			 77
191 			 169 			 55
150 			 237 			 48
65 			 116 			 25
Max memory allocated: 14723398656; Memory allocated: 7258636288
Epoch [327/500] took 170.93184971809387s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3403815554681224, train accuracy: 0.5149479014509689
Val mean loss: 1.661475725290252, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2719 			 1998 			 1219
2042 			 2123 			 1055
2119 			 1966 			 1103
1592 			 1683 			 871
1305 			 1657 			 702
492 			 842 			 338
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 103
306 			 248 			 77
240 			 251 			 79
169 			 169 			 50
144 			 237 			 44
67 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7154407424
Epoch [328/500] took 171.53272032737732s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3411615956980862, train accuracy: 0.5177719349498491
Val mean loss: 1.6554339164640846, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2723 			 1998 			 1232
2198 			 2123 			 1120
2081 			 1966 			 1097
1536 			 1683 			 853
1269 			 1657 			 695
462 			 842 			 320
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 263 			 103
279 			 248 			 74
230 			 251 			 75
192 			 169 			 56
144 			 237 			 44
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7194122240
Epoch [329/500] took 171.10048937797546s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3417651868683527, train accuracy: 0.5180640763462849
Val mean loss: 1.6679403840041742, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2787 			 1998 			 1243
2132 			 2123 			 1095
2077 			 1966 			 1100
1557 			 1683 			 872
1235 			 1657 			 677
481 			 842 			 333
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 100
284 			 248 			 73
230 			 251 			 73
197 			 169 			 55
162 			 237 			 49
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7187666944
Epoch [330/500] took 171.15053009986877s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3421293942727774, train accuracy: 0.517285032622456
Val mean loss: 1.656740682881053, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2681 			 1998 			 1215
2137 			 2123 			 1084
2082 			 1966 			 1099
1578 			 1683 			 868
1309 			 1657 			 714
482 			 842 			 332
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 100
283 			 248 			 75
232 			 251 			 73
198 			 169 			 53
141 			 237 			 43
70 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7233928192
Epoch [331/500] took 171.66642332077026s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3409305257589275, train accuracy: 0.520401207517772
Val mean loss: 1.6736530443517172, val accuracy: 0.3029595015576324

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2731 			 1998 			 1234
2110 			 2123 			 1088
2069 			 1966 			 1100
1652 			 1683 			 902
1209 			 1657 			 680
498 			 842 			 340
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 104
281 			 248 			 75
225 			 251 			 74
193 			 169 			 55
155 			 237 			 48
74 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7210998784
Epoch [332/500] took 171.8486511707306s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.339864329385609, train accuracy: 0.5173824130879345
Val mean loss: 1.6794031771217905, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2791 			 1998 			 1248
2145 			 2123 			 1096
2024 			 1966 			 1074
1580 			 1683 			 874
1257 			 1657 			 693
472 			 842 			 328
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 105
267 			 248 			 72
263 			 251 			 80
180 			 169 			 51
142 			 237 			 43
73 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7200570368
Epoch [333/500] took 170.64138674736023s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.337493216137277, train accuracy: 0.5170902716914987
Val mean loss: 1.652760749909936, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2736 			 1998 			 1231
2065 			 2123 			 1068
2124 			 1966 			 1104
1565 			 1683 			 871
1321 			 1657 			 718
458 			 842 			 318
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 100
298 			 248 			 77
244 			 251 			 76
186 			 169 			 52
130 			 237 			 38
72 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7250075648
Epoch [334/500] took 170.88735461235046s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3376253215694724, train accuracy: 0.5153374233128835
Val mean loss: 1.6539502899821212, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2754 			 1998 			 1230
2111 			 2123 			 1072
2092 			 1966 			 1097
1618 			 1683 			 883
1231 			 1657 			 686
463 			 842 			 324
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
355 			 263 			 105
301 			 248 			 78
232 			 251 			 74
173 			 169 			 50
152 			 237 			 46
71 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7201692672
Epoch [335/500] took 171.22088479995728s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3376039845921168, train accuracy: 0.5174797935534132
Val mean loss: 1.6618306724036611, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2751 			 1998 			 1234
2190 			 2123 			 1116
2049 			 1966 			 1080
1543 			 1683 			 862
1249 			 1657 			 688
487 			 842 			 334
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 101
280 			 248 			 74
251 			 251 			 80
180 			 169 			 50
149 			 237 			 47
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7210417152
Epoch [336/500] took 171.3696322441101s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3379480601099794, train accuracy: 0.5206933489142078
Val mean loss: 1.6839259833824345, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2701 			 1998 			 1226
2163 			 2123 			 1099
2048 			 1966 			 1090
1618 			 1683 			 895
1243 			 1657 			 691
496 			 842 			 346
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
348 			 263 			 100
277 			 248 			 73
257 			 251 			 84
180 			 169 			 51
150 			 237 			 46
72 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7199243264
Epoch [337/500] took 171.21751809120178s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3365919344893127, train accuracy: 0.5187457396046353
Val mean loss: 1.6593170340468244, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2736 			 1998 			 1235
2122 			 2123 			 1083
2115 			 1966 			 1109
1578 			 1683 			 877
1223 			 1657 			 683
495 			 842 			 340
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 99
288 			 248 			 76
238 			 251 			 76
185 			 169 			 51
159 			 237 			 49
67 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7193163776
Epoch [338/500] took 170.4306914806366s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3346725252929879, train accuracy: 0.5192326419320284
Val mean loss: 1.670707891627056, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2699 			 1998 			 1223
2140 			 2123 			 1086
2070 			 1966 			 1093
1592 			 1683 			 880
1296 			 1657 			 714
472 			 842 			 336
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 98
287 			 248 			 76
241 			 251 			 78
191 			 169 			 54
148 			 237 			 46
73 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7223966720
Epoch [339/500] took 171.53461384773254s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3352497511563644, train accuracy: 0.518550978673678
Val mean loss: 1.6708016831700394, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2691 			 1998 			 1214
2115 			 2123 			 1096
2105 			 1966 			 1104
1573 			 1683 			 870
1288 			 1657 			 701
497 			 842 			 340
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
370 			 263 			 102
280 			 248 			 72
224 			 251 			 73
179 			 169 			 50
157 			 237 			 47
74 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7225654272
Epoch [340/500] took 171.76671886444092s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.33726813043018, train accuracy: 0.5209854903106437
Val mean loss: 1.6688377072171467, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2781 			 1998 			 1249
2130 			 2123 			 1101
2017 			 1966 			 1077
1633 			 1683 			 895
1238 			 1657 			 696
470 			 842 			 332
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 97
287 			 248 			 74
247 			 251 			 79
171 			 169 			 50
161 			 237 			 46
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7205403648
Epoch [341/500] took 171.10610914230347s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3339590227863871, train accuracy: 0.5207907293796864
Val mean loss: 1.6507336453693668, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2737 			 1998 			 1235
2103 			 2123 			 1087
2131 			 1966 			 1120
1532 			 1683 			 864
1277 			 1657 			 703
489 			 842 			 339
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 102
297 			 248 			 79
219 			 251 			 72
188 			 169 			 53
152 			 237 			 45
68 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7216053248
Epoch [342/500] took 171.67675256729126s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3343217941088097, train accuracy: 0.5183562177427208
Val mean loss: 1.6681926831966494, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2744 			 1998 			 1231
2142 			 2123 			 1088
2031 			 1966 			 1086
1590 			 1683 			 881
1278 			 1657 			 702
484 			 842 			 335
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 101
287 			 248 			 73
237 			 251 			 77
183 			 169 			 53
150 			 237 			 47
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7192893440
Epoch [343/500] took 170.3811914920807s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3308935072563148, train accuracy: 0.5186483591391566
Val mean loss: 1.6616881387989695, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2732 			 1998 			 1234
2091 			 2123 			 1068
2023 			 1966 			 1078
1616 			 1683 			 892
1334 			 1657 			 726
473 			 842 			 328
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 107
292 			 248 			 75
251 			 251 			 80
174 			 169 			 51
135 			 237 			 41
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7225056256
Epoch [344/500] took 171.70911979675293s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.333552258036961, train accuracy: 0.5220566754309086
Val mean loss: 1.6496323608770602, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2776 			 1998 			 1251
2108 			 2123 			 1088
2118 			 1966 			 1114
1541 			 1683 			 869
1247 			 1657 			 708
479 			 842 			 331
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 263 			 97
300 			 248 			 78
240 			 251 			 76
180 			 169 			 49
147 			 237 			 44
75 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7220141056
Epoch [345/500] took 171.23037195205688s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3327089733795214, train accuracy: 0.5223488168273445
Val mean loss: 1.6559078809691639, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2749 			 1998 			 1251
2106 			 2123 			 1085
2089 			 1966 			 1100
1577 			 1683 			 878
1266 			 1657 			 717
482 			 842 			 333
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
336 			 263 			 97
295 			 248 			 77
234 			 251 			 75
189 			 169 			 54
155 			 237 			 48
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7191926784
Epoch [346/500] took 171.21429085731506s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3312938306190514, train accuracy: 0.5222514363618658
Val mean loss: 1.6603931421186866, val accuracy: 0.3052959501557632

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2673 			 1998 			 1224
2139 			 2123 			 1093
2061 			 1966 			 1095
1594 			 1683 			 885
1303 			 1657 			 719
499 			 842 			 347
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 100
285 			 248 			 76
252 			 251 			 82
190 			 169 			 53
151 			 237 			 49
72 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7196391424
Epoch [347/500] took 171.72943449020386s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3318499497535443, train accuracy: 0.5218619144999513
Val mean loss: 1.6636394960124319, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2706 			 1998 			 1233
2158 			 2123 			 1108
2112 			 1966 			 1108
1556 			 1683 			 872
1273 			 1657 			 710
464 			 842 			 328
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 103
286 			 248 			 75
229 			 251 			 73
192 			 169 			 53
149 			 237 			 46
74 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7199931392
Epoch [348/500] took 170.82738614082336s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.329075691484588, train accuracy: 0.5226409582237803
Val mean loss: 1.665245640568617, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2736 			 1998 			 1247
2113 			 2123 			 1086
2080 			 1966 			 1115
1568 			 1683 			 869
1272 			 1657 			 706
500 			 842 			 344
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 263 			 98
299 			 248 			 76
236 			 251 			 73
185 			 169 			 50
147 			 237 			 44
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7242235904
Epoch [349/500] took 171.54647660255432s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3280400542826667, train accuracy: 0.5241990456714383
Val mean loss: 1.6700287999176398, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2722 			 1998 			 1243
2164 			 2123 			 1107
2075 			 1966 			 1110
1585 			 1683 			 893
1239 			 1657 			 690
484 			 842 			 340
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
340 			 263 			 98
301 			 248 			 76
232 			 251 			 75
186 			 169 			 51
148 			 237 			 42
77 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7185995776
Epoch [350/500] took 171.73565340042114s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.330541842823088, train accuracy: 0.5217645340344726
Val mean loss: 1.671276191385781, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2665 			 1998 			 1215
2112 			 2123 			 1091
2053 			 1966 			 1090
1634 			 1683 			 905
1315 			 1657 			 719
490 			 842 			 338
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 100
275 			 248 			 74
247 			 251 			 82
179 			 169 			 52
152 			 237 			 46
75 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7242792960
Epoch [351/500] took 171.11824893951416s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.328175872657158, train accuracy: 0.522446197292823
Val mean loss: 1.6603238146479538, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2739 			 1998 			 1248
2126 			 2123 			 1091
2086 			 1966 			 1103
1559 			 1683 			 873
1273 			 1657 			 703
486 			 842 			 347
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 263 			 100
281 			 248 			 73
252 			 251 			 78
182 			 169 			 50
152 			 237 			 46
75 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7207230464
Epoch [352/500] took 170.7936475276947s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3284540009275776, train accuracy: 0.5236147628785666
Val mean loss: 1.6798706403592738, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2705 			 1998 			 1225
2183 			 2123 			 1125
2040 			 1966 			 1088
1571 			 1683 			 882
1266 			 1657 			 709
504 			 842 			 348
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 101
260 			 248 			 70
272 			 251 			 84
175 			 169 			 49
151 			 237 			 45
79 			 116 			 34
Max memory allocated: 14723398656; Memory allocated: 7266648064
Epoch [353/500] took 170.56898069381714s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3262260669488402, train accuracy: 0.5244911870678742
Val mean loss: 1.6624040719939441, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2758 			 1998 			 1250
2060 			 2123 			 1078
2101 			 1966 			 1122
1601 			 1683 			 892
1261 			 1657 			 705
488 			 842 			 339
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 102
283 			 248 			 73
239 			 251 			 77
177 			 169 			 50
158 			 237 			 47
67 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7197596672
Epoch [354/500] took 171.41659998893738s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3275191219424904, train accuracy: 0.524296426136917
Val mean loss: 1.6706679448848818, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2670 			 1998 			 1226
2125 			 2123 			 1100
2052 			 1966 			 1103
1612 			 1683 			 899
1317 			 1657 			 719
493 			 842 			 337
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
378 			 263 			 107
288 			 248 			 74
237 			 251 			 77
172 			 169 			 48
142 			 237 			 42
67 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7191640064
Epoch [355/500] took 171.39883017539978s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3276835420049982, train accuracy: 0.5240042847404811
Val mean loss: 1.685708941482916, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2752 			 1998 			 1259
2168 			 2123 			 1110
2042 			 1966 			 1091
1540 			 1683 			 870
1285 			 1657 			 712
482 			 842 			 339
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 101
272 			 248 			 72
252 			 251 			 80
183 			 169 			 51
150 			 237 			 41
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7190976512
Epoch [356/500] took 171.30129051208496s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3271323256774854, train accuracy: 0.523517382413088
Val mean loss: 1.656034580091151, val accuracy: 0.30062305295950154

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2722 			 1998 			 1237
2142 			 2123 			 1104
2100 			 1966 			 1115
1590 			 1683 			 883
1231 			 1657 			 697
484 			 842 			 340
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 102
280 			 248 			 72
234 			 251 			 77
181 			 169 			 54
160 			 237 			 49
72 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7261011968
Epoch [357/500] took 170.89920711517334s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3233855505970036, train accuracy: 0.5276073619631901
Val mean loss: 1.667885835577802, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2743 			 1998 			 1261
2112 			 2123 			 1098
2100 			 1966 			 1118
1536 			 1683 			 872
1277 			 1657 			 717
501 			 842 			 352
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
330 			 263 			 95
276 			 248 			 73
244 			 251 			 76
200 			 169 			 55
160 			 237 			 47
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7222918144
Epoch [358/500] took 171.6251266002655s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.326171978983181, train accuracy: 0.5246859479988314
Val mean loss: 1.6504579753410527, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2700 			 1998 			 1233
2130 			 2123 			 1109
2091 			 1966 			 1105
1599 			 1683 			 896
1270 			 1657 			 707
479 			 842 			 338
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 263 			 102
294 			 248 			 74
228 			 251 			 73
199 			 169 			 54
152 			 237 			 47
69 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7206091776
Epoch [359/500] took 171.2458336353302s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3241420765160772, train accuracy: 0.5250754698607459
Val mean loss: 1.6959690553386038, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2694 			 1998 			 1239
2122 			 2123 			 1100
2094 			 1966 			 1109
1580 			 1683 			 890
1288 			 1657 			 709
491 			 842 			 345
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 100
283 			 248 			 74
247 			 251 			 81
192 			 169 			 52
144 			 237 			 45
74 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7233895424
Epoch [360/500] took 171.56510615348816s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3241688280462105, train accuracy: 0.5238095238095238
Val mean loss: 1.6846983200166283, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2665 			 1998 			 1230
2138 			 2123 			 1104
2102 			 1966 			 1104
1562 			 1683 			 884
1313 			 1657 			 712
489 			 842 			 345
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
371 			 263 			 105
284 			 248 			 75
233 			 251 			 77
197 			 169 			 54
129 			 237 			 39
70 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7200291840
Epoch [361/500] took 170.64422821998596s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3224100780635608, train accuracy: 0.5280942642905833
Val mean loss: 1.66968433449908, val accuracy: 0.3014018691588785

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2771 			 1998 			 1265
2125 			 2123 			 1110
2041 			 1966 			 1099
1609 			 1683 			 901
1236 			 1657 			 705
487 			 842 			 343
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 102
276 			 248 			 74
248 			 251 			 79
189 			 169 			 53
156 			 237 			 47
71 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7260536832
Epoch [362/500] took 171.90418767929077s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3230704180548125, train accuracy: 0.5261466549810108
Val mean loss: 1.6643043000523636, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2694 			 1998 			 1232
2106 			 2123 			 1108
2081 			 1966 			 1110
1631 			 1683 			 900
1263 			 1657 			 706
494 			 842 			 347
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 99
287 			 248 			 75
230 			 251 			 76
187 			 169 			 51
148 			 237 			 46
76 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7154407424
Epoch [363/500] took 171.47723531723022s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.322699786718018, train accuracy: 0.5275099814977116
Val mean loss: 1.6677314043045044, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2684 			 1998 			 1243
2154 			 2123 			 1115
2074 			 1966 			 1104
1570 			 1683 			 891
1290 			 1657 			 715
497 			 842 			 349
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 102
273 			 248 			 71
229 			 251 			 73
199 			 169 			 54
157 			 237 			 48
76 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7253213184
Epoch [364/500] took 171.26896166801453s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3215061894087035, train accuracy: 0.5269256987048399
Val mean loss: 1.6867850553698656, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2680 			 1998 			 1230
2127 			 2123 			 1108
2003 			 1966 			 1083
1611 			 1683 			 901
1330 			 1657 			 731
518 			 842 			 358
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
367 			 263 			 110
283 			 248 			 74
258 			 251 			 80
175 			 169 			 48
131 			 237 			 42
70 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7200111616
Epoch [365/500] took 171.65760684013367s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3220467474601723, train accuracy: 0.5268283182393612
Val mean loss: 1.662528593365739, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2766 			 1998 			 1263
2064 			 2123 			 1081
2122 			 1966 			 1128
1586 			 1683 			 890
1244 			 1657 			 706
487 			 842 			 342
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 98
302 			 248 			 78
235 			 251 			 75
179 			 169 			 48
155 			 237 			 46
72 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7227882496
Epoch [366/500] took 171.31660151481628s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3190760549355147, train accuracy: 0.5278995033596261
Val mean loss: 1.6958322670401595, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2695 			 1998 			 1241
2190 			 2123 			 1125
2058 			 1966 			 1110
1585 			 1683 			 895
1269 			 1657 			 712
472 			 842 			 338
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 97
283 			 248 			 75
227 			 251 			 74
199 			 169 			 54
159 			 237 			 47
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7195015168
Epoch [367/500] took 170.99748706817627s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.319434082768045, train accuracy: 0.5308209173239848
Val mean loss: 1.6833311464728378, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2667 			 1998 			 1241
2134 			 2123 			 1122
2047 			 1966 			 1104
1617 			 1683 			 899
1295 			 1657 			 727
509 			 842 			 358
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 103
287 			 248 			 74
244 			 251 			 81
177 			 169 			 49
154 			 237 			 45
66 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7191320576
Epoch [368/500] took 171.599041223526s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3186030272754181, train accuracy: 0.5279968838251047
Val mean loss: 1.6738957137596318, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2696 			 1998 			 1236
2113 			 2123 			 1100
2072 			 1966 			 1122
1598 			 1683 			 897
1302 			 1657 			 723
488 			 842 			 344
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 101
282 			 248 			 75
255 			 251 			 82
179 			 169 			 48
142 			 237 			 41
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7199628288
Epoch [369/500] took 170.95149493217468s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3181509507408022, train accuracy: 0.5291654494108482
Val mean loss: 1.666821200673173, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2716 			 1998 			 1245
2086 			 2123 			 1099
2105 			 1966 			 1127
1567 			 1683 			 882
1274 			 1657 			 721
521 			 842 			 360
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 101
287 			 248 			 73
239 			 251 			 77
194 			 169 			 53
145 			 237 			 41
66 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7215954944
Epoch [370/500] took 171.65480637550354s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3176441200054323, train accuracy: 0.5295549712727626
Val mean loss: 1.6722098385415427, val accuracy: 0.29906542056074764

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2705 			 1998 			 1254
2183 			 2123 			 1114
2068 			 1966 			 1120
1553 			 1683 			 883
1261 			 1657 			 714
499 			 842 			 353
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 98
271 			 248 			 73
245 			 251 			 79
197 			 169 			 56
159 			 237 			 45
78 			 116 			 33
Max memory allocated: 14723398656; Memory allocated: 7198759936
Epoch [371/500] took 170.69359493255615s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3157214685763896, train accuracy: 0.5303340149965917
Val mean loss: 1.665550525595502, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2662 			 1998 			 1241
2070 			 2123 			 1097
2082 			 1966 			 1119
1632 			 1683 			 911
1325 			 1657 			 725
498 			 842 			 353
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 102
279 			 248 			 73
251 			 251 			 79
194 			 169 			 52
143 			 237 			 42
67 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7190853632
Epoch [372/500] took 170.6878101825714s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3158049316049736, train accuracy: 0.5295549712727626
Val mean loss: 1.6772194432049263, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2688 			 1998 			 1236
2150 			 2123 			 1121
2099 			 1966 			 1119
1593 			 1683 			 899
1233 			 1657 			 711
506 			 842 			 352
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 101
285 			 248 			 74
223 			 251 			 74
197 			 169 			 55
160 			 237 			 46
68 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7193065472
Epoch [373/500] took 170.7644624710083s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.315236489720805, train accuracy: 0.5301392540656344
Val mean loss: 1.6707105113238823, val accuracy: 0.2998442367601246

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2693 			 1998 			 1250
2051 			 2123 			 1094
2071 			 1966 			 1109
1655 			 1683 			 915
1296 			 1657 			 722
503 			 842 			 354
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
326 			 263 			 97
319 			 248 			 82
228 			 251 			 74
181 			 169 			 51
155 			 237 			 49
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7248101376
Epoch [374/500] took 170.84390258789062s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3148181761536644, train accuracy: 0.5290680689453695
Val mean loss: 1.6625492979840535, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2664 			 1998 			 1235
2220 			 2123 			 1139
2056 			 1966 			 1101
1541 			 1683 			 882
1288 			 1657 			 723
500 			 842 			 353
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 103
270 			 248 			 73
253 			 251 			 81
188 			 169 			 51
150 			 237 			 45
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7207271424
Epoch [375/500] took 170.79544496536255s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3140465663600933, train accuracy: 0.5308209173239848
Val mean loss: 1.6793046491902048, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2698 			 1998 			 1242
2048 			 2123 			 1090
2148 			 1966 			 1137
1565 			 1683 			 895
1301 			 1657 			 725
509 			 842 			 362
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
340 			 263 			 95
302 			 248 			 78
213 			 251 			 71
202 			 169 			 54
156 			 237 			 48
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7191025664
Epoch [376/500] took 170.9329764842987s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3136540153687617, train accuracy: 0.5299444931346772
Val mean loss: 1.6618452886255777, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2724 			 1998 			 1250
2137 			 2123 			 1112
1994 			 1966 			 1093
1603 			 1683 			 902
1325 			 1657 			 738
486 			 842 			 347
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
348 			 263 			 101
285 			 248 			 76
254 			 251 			 80
182 			 169 			 49
142 			 237 			 41
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7200791552
Epoch [377/500] took 171.54155850410461s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3158148007229482, train accuracy: 0.5330606680299932
Val mean loss: 1.6735498672578393, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2643 			 1998 			 1239
2199 			 2123 			 1136
2089 			 1966 			 1132
1559 			 1683 			 891
1268 			 1657 			 719
511 			 842 			 357
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
366 			 263 			 103
261 			 248 			 69
252 			 251 			 82
193 			 169 			 52
142 			 237 			 44
70 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7191107584
Epoch [378/500] took 171.04675698280334s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3136772882901249, train accuracy: 0.5289706884798909
Val mean loss: 1.66916872815388, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2684 			 1998 			 1228
2032 			 2123 			 1083
2099 			 1966 			 1118
1658 			 1683 			 927
1303 			 1657 			 729
493 			 842 			 347
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
362 			 263 			 101
296 			 248 			 77
227 			 251 			 75
183 			 169 			 50
145 			 237 			 44
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7250362368
Epoch [379/500] took 170.76235508918762s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3118633172965124, train accuracy: 0.5309182977894634
Val mean loss: 1.6697572178956939, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2697 			 1998 			 1249
2178 			 2123 			 1119
2041 			 1966 			 1104
1543 			 1683 			 887
1310 			 1657 			 736
500 			 842 			 357
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 99
290 			 248 			 75
245 			 251 			 79
196 			 169 			 52
135 			 237 			 41
77 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7254163456
Epoch [380/500] took 170.50418043136597s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.311082821397395, train accuracy: 0.5312104391858993
Val mean loss: 1.6615152329933354, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2608 			 1998 			 1218
2157 			 2123 			 1128
2089 			 1966 			 1122
1632 			 1683 			 911
1259 			 1657 			 713
524 			 842 			 363
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
372 			 263 			 103
271 			 248 			 73
235 			 251 			 77
191 			 169 			 54
144 			 237 			 41
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7219289088
Epoch [381/500] took 170.7344467639923s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.31270544625517, train accuracy: 0.5327685266335573
Val mean loss: 1.6686176584988106, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2713 			 1998 			 1258
2053 			 2123 			 1094
2068 			 1966 			 1116
1618 			 1683 			 916
1314 			 1657 			 733
503 			 842 			 354
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
351 			 263 			 98
282 			 248 			 75
237 			 251 			 80
189 			 169 			 51
157 			 237 			 45
68 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7244472320
Epoch [382/500] took 170.49512887001038s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3108815608366255, train accuracy: 0.5329632875645146
Val mean loss: 1.6689835205310728, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2699 			 1998 			 1256
2095 			 2123 			 1106
2085 			 1966 			 1120
1620 			 1683 			 913
1296 			 1657 			 732
474 			 842 			 346
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 97
295 			 248 			 74
250 			 251 			 78
171 			 169 			 46
155 			 237 			 49
72 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7187535872
Epoch [383/500] took 170.69986414909363s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3113958716763885, train accuracy: 0.5332554289609505
Val mean loss: 1.6640339566440117, val accuracy: 0.29750778816199375

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2705 			 1998 			 1258
2128 			 2123 			 1120
2092 			 1966 			 1114
1539 			 1683 			 890
1299 			 1657 			 736
506 			 842 			 358
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
337 			 263 			 99
298 			 248 			 78
233 			 251 			 76
201 			 169 			 56
140 			 237 			 42
75 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7157725184
Epoch [384/500] took 170.9599587917328s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.310665351579494, train accuracy: 0.5337423312883436
Val mean loss: 1.6765233598104337, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2645 			 1998 			 1233
2180 			 2123 			 1136
2050 			 1966 			 1111
1632 			 1683 			 913
1244 			 1657 			 724
518 			 842 			 364
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 101
273 			 248 			 73
241 			 251 			 76
192 			 169 			 51
155 			 237 			 46
67 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7254097920
Epoch [385/500] took 170.94921207427979s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3098886547801651, train accuracy: 0.533352809426429
Val mean loss: 1.659424240996198, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2636 			 1998 			 1239
2166 			 2123 			 1138
2074 			 1966 			 1124
1598 			 1683 			 906
1315 			 1657 			 727
480 			 842 			 343
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
394 			 263 			 110
265 			 248 			 71
241 			 251 			 77
179 			 169 			 48
139 			 237 			 43
66 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7201520640
Epoch [386/500] took 170.95207357406616s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3094191061002072, train accuracy: 0.5334501898919077
Val mean loss: 1.6713533372413822, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2748 			 1998 			 1258
2091 			 2123 			 1118
2089 			 1966 			 1125
1588 			 1683 			 908
1254 			 1657 			 714
499 			 842 			 355
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
337 			 263 			 94
264 			 248 			 72
253 			 251 			 83
187 			 169 			 49
169 			 237 			 47
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7252721664
Epoch [387/500] took 170.83676075935364s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3091037418240699, train accuracy: 0.5323790047716428
Val mean loss: 1.6826487808692745, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2631 			 1998 			 1234
2103 			 2123 			 1113
2113 			 1966 			 1133
1582 			 1683 			 902
1316 			 1657 			 725
524 			 842 			 360
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 104
272 			 248 			 72
238 			 251 			 78
192 			 169 			 52
153 			 237 			 45
71 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7198751744
Epoch [388/500] took 171.1282618045807s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3096566575338535, train accuracy: 0.5326711461680786
Val mean loss: 1.6664184564497413, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2703 			 1998 			 1252
2080 			 2123 			 1104
2040 			 1966 			 1104
1643 			 1683 			 919
1310 			 1657 			 736
493 			 842 			 355
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 100
289 			 248 			 75
241 			 251 			 78
186 			 169 			 49
151 			 237 			 44
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7241382912
Epoch [389/500] took 170.57039284706116s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3073975352854743, train accuracy: 0.5354951796669588
Val mean loss: 1.6569721146327694, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2684 			 1998 			 1251
2191 			 2123 			 1135
2037 			 1966 			 1115
1553 			 1683 			 892
1296 			 1657 			 744
508 			 842 			 362
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
340 			 263 			 94
255 			 248 			 70
267 			 251 			 82
196 			 169 			 52
154 			 237 			 43
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7193073664
Epoch [390/500] took 170.77466583251953s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.308393058747146, train accuracy: 0.5340344726847794
Val mean loss: 1.6679055254633834, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2692 			 1998 			 1255
2044 			 2123 			 1093
2159 			 1966 			 1142
1598 			 1683 			 908
1268 			 1657 			 725
508 			 842 			 361
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 98
297 			 248 			 75
221 			 251 			 74
194 			 169 			 53
158 			 237 			 44
76 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7201799168
Epoch [391/500] took 170.28975415229797s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3049493276070212, train accuracy: 0.5370532671146168
Val mean loss: 1.6912455558776855, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2594 			 1998 			 1232
2138 			 2123 			 1130
2034 			 1966 			 1109
1634 			 1683 			 923
1336 			 1657 			 747
533 			 842 			 374
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 102
275 			 248 			 72
245 			 251 			 80
187 			 169 			 49
148 			 237 			 44
77 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7161042944
Epoch [392/500] took 170.70134854316711s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3057739430127486, train accuracy: 0.5356899405979161
Val mean loss: 1.6746981173026851, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2715 			 1998 			 1266
2105 			 2123 			 1114
2094 			 1966 			 1125
1590 			 1683 			 913
1249 			 1657 			 717
516 			 842 			 366
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
335 			 263 			 99
281 			 248 			 76
253 			 251 			 79
184 			 169 			 50
159 			 237 			 47
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7355262976
Epoch [393/500] took 171.49868035316467s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3077262406037233, train accuracy: 0.5351056578050443
Val mean loss: 1.6803849295872013, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2685 			 1998 			 1256
2068 			 2123 			 1112
2067 			 1966 			 1114
1625 			 1683 			 912
1327 			 1657 			 743
497 			 842 			 358
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 101
296 			 248 			 75
257 			 251 			 79
172 			 169 			 49
145 			 237 			 42
67 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7226539008
Epoch [394/500] took 170.89225816726685s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3049936617646263, train accuracy: 0.5342292336157367
Val mean loss: 1.6791815234393608, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2700 			 1998 			 1251
2168 			 2123 			 1139
2075 			 1966 			 1120
1530 			 1683 			 886
1281 			 1657 			 725
515 			 842 			 365
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
328 			 263 			 93
290 			 248 			 74
253 			 251 			 81
181 			 169 			 48
158 			 237 			 46
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7220689920
Epoch [395/500] took 170.42972207069397s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.304305979767321, train accuracy: 0.5379296913039244
Val mean loss: 1.678820647844454, val accuracy: 0.2827102803738318

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2643 			 1998 			 1244
2114 			 2123 			 1122
2132 			 1966 			 1149
1585 			 1683 			 903
1280 			 1657 			 741
515 			 842 			 365
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
332 			 263 			 92
285 			 248 			 73
236 			 251 			 74
200 			 169 			 51
160 			 237 			 44
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7210040320
Epoch [396/500] took 170.90861129760742s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.304289908795342, train accuracy: 0.5347161359431298
Val mean loss: 1.6651555532362403, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2669 			 1998 			 1244
2117 			 2123 			 1115
2052 			 1966 			 1117
1627 			 1683 			 917
1293 			 1657 			 736
511 			 842 			 362
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
355 			 263 			 103
301 			 248 			 78
240 			 251 			 75
187 			 169 			 50
133 			 237 			 39
68 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7206419456
Epoch [397/500] took 170.7817690372467s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3051934283099071, train accuracy: 0.5342292336157367
Val mean loss: 1.6810423135757446, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2654 			 1998 			 1235
2148 			 2123 			 1135
2104 			 1966 			 1134
1598 			 1683 			 903
1255 			 1657 			 712
510 			 842 			 367
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 99
271 			 248 			 70
253 			 251 			 78
187 			 169 			 49
152 			 237 			 43
68 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7277166592
Epoch [398/500] took 171.25582027435303s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3041170620101263, train accuracy: 0.535203038270523
Val mean loss: 1.6505119626115008, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2665 			 1998 			 1238
2100 			 2123 			 1122
2035 			 1966 			 1117
1645 			 1683 			 923
1336 			 1657 			 747
488 			 842 			 349
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 100
268 			 248 			 72
265 			 251 			 83
179 			 169 			 50
152 			 237 			 43
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7239875584
Epoch [399/500] took 171.28404450416565s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.303642859711454, train accuracy: 0.5382218327003603
Val mean loss: 1.6878499112478116, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2678 			 1998 			 1250
2070 			 2123 			 1117
2118 			 1966 			 1145
1588 			 1683 			 910
1303 			 1657 			 738
512 			 842 			 367
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
359 			 263 			 105
294 			 248 			 75
236 			 251 			 77
176 			 169 			 47
145 			 237 			 44
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7249698816
Epoch [400/500] took 170.38056874275208s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3010948454479563, train accuracy: 0.5379296913039244
Val mean loss: 1.6804328488140572, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2641 			 1998 			 1250
2149 			 2123 			 1123
2068 			 1966 			 1127
1590 			 1683 			 913
1296 			 1657 			 743
525 			 842 			 368
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
360 			 263 			 103
286 			 248 			 74
233 			 251 			 77
183 			 169 			 50
151 			 237 			 47
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7190657024
Epoch [401/500] took 171.35782265663147s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.302691550641045, train accuracy: 0.5392930178206252
Val mean loss: 1.655569893557851, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2721 			 1998 			 1277
2135 			 2123 			 1131
2071 			 1966 			 1122
1558 			 1683 			 899
1286 			 1657 			 745
498 			 842 			 364
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
337 			 263 			 96
266 			 248 			 71
251 			 251 			 77
195 			 169 			 51
162 			 237 			 47
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7247216640
Epoch [402/500] took 170.61764097213745s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3007850697107404, train accuracy: 0.5381244522348817
Val mean loss: 1.6855609649565162, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2655 			 1998 			 1251
2095 			 2123 			 1116
2048 			 1966 			 1119
1636 			 1683 			 923
1306 			 1657 			 741
529 			 842 			 376
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 97
283 			 248 			 75
263 			 251 			 83
175 			 169 			 47
156 			 237 			 43
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7206632448
Epoch [403/500] took 171.38654708862305s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.302063952725253, train accuracy: 0.5405589638718473
Val mean loss: 1.6694733224264005, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2622 			 1998 			 1240
2110 			 2123 			 1134
2148 			 1966 			 1160
1590 			 1683 			 914
1304 			 1657 			 743
495 			 842 			 360
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 101
274 			 248 			 72
241 			 251 			 80
191 			 169 			 49
159 			 237 			 45
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7191443456
Epoch [404/500] took 171.44561171531677s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.3010392582676493, train accuracy: 0.5367611257181809
Val mean loss: 1.663913162743173, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2629 			 1998 			 1241
2080 			 2123 			 1104
2088 			 1966 			 1126
1619 			 1683 			 920
1332 			 1657 			 756
521 			 842 			 365
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 102
294 			 248 			 75
231 			 251 			 76
181 			 169 			 49
148 			 237 			 44
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7198521344
Epoch [405/500] took 170.64280128479004s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.299265795407637, train accuracy: 0.5402668224754115
Val mean loss: 1.6748257148556593, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2623 			 1998 			 1244
2168 			 2123 			 1150
2074 			 1966 			 1135
1600 			 1683 			 920
1293 			 1657 			 739
511 			 842 			 360
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 101
273 			 248 			 72
247 			 251 			 79
185 			 169 			 49
147 			 237 			 44
67 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7270187008
Epoch [406/500] took 171.12003111839294s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2992867142240578, train accuracy: 0.538027071769403
Val mean loss: 1.6726954361287558, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2733 			 1998 			 1270
2106 			 2123 			 1126
2062 			 1966 			 1121
1577 			 1683 			 907
1269 			 1657 			 726
522 			 842 			 375
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
358 			 263 			 101
285 			 248 			 74
229 			 251 			 73
192 			 169 			 52
153 			 237 			 47
67 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7151089664
Epoch [407/500] took 171.25441646575928s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2999205864107126, train accuracy: 0.5373454085110527
Val mean loss: 1.6788466558223818, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2705 			 1998 			 1263
2058 			 2123 			 1107
2085 			 1966 			 1130
1607 			 1683 			 913
1306 			 1657 			 749
508 			 842 			 356
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
348 			 263 			 99
295 			 248 			 76
231 			 251 			 75
194 			 169 			 52
146 			 237 			 43
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7236008960
Epoch [408/500] took 170.29225087165833s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2960677960208644, train accuracy: 0.5405589638718473
Val mean loss: 1.6678446676672958, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2647 			 1998 			 1256
2163 			 2123 			 1137
2060 			 1966 			 1135
1611 			 1683 			 921
1288 			 1657 			 741
500 			 842 			 361
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 263 			 94
286 			 248 			 75
242 			 251 			 78
190 			 169 			 50
155 			 237 			 45
72 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7201273856
Epoch [409/500] took 170.82269167900085s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2984448834743083, train accuracy: 0.5393903982861038
Val mean loss: 1.6868879533395535, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2651 			 1998 			 1262
2110 			 2123 			 1125
2096 			 1966 			 1131
1587 			 1683 			 912
1305 			 1657 			 739
520 			 842 			 370
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 101
286 			 248 			 76
217 			 251 			 70
196 			 169 			 52
159 			 237 			 47
65 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7205796864
Epoch [410/500] took 171.25317549705505s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2976807437581808, train accuracy: 0.5391956373551465
Val mean loss: 1.6689111430470536, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2648 			 1998 			 1246
2129 			 2123 			 1134
2041 			 1966 			 1119
1640 			 1683 			 931
1299 			 1657 			 742
512 			 842 			 365
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
355 			 263 			 102
272 			 248 			 70
244 			 251 			 78
184 			 169 			 50
155 			 237 			 43
74 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7200766976
Epoch [411/500] took 170.46454572677612s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2960498112013035, train accuracy: 0.5397799201480183
Val mean loss: 1.67318856716156, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2690 			 1998 			 1268
2070 			 2123 			 1110
2059 			 1966 			 1125
1615 			 1683 			 921
1321 			 1657 			 750
514 			 842 			 369
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
333 			 263 			 96
300 			 248 			 77
240 			 251 			 76
183 			 169 			 47
152 			 237 			 44
76 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7209401344
Epoch [412/500] took 170.64057755470276s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.295002266068325, train accuracy: 0.5413380075956763
Val mean loss: 1.6642326581768874, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2656 			 1998 			 1258
2141 			 2123 			 1143
2044 			 1966 			 1121
1602 			 1683 			 918
1306 			 1657 			 742
520 			 842 			 377
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
346 			 263 			 98
265 			 248 			 72
259 			 251 			 79
188 			 169 			 50
153 			 237 			 43
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7199448064
Epoch [413/500] took 171.33875060081482s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2959802273277925, train accuracy: 0.5416301489921121
Val mean loss: 1.6695473572102988, val accuracy: 0.29595015576323985

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2631 			 1998 			 1245
2125 			 2123 			 1131
2104 			 1966 			 1147
1601 			 1683 			 923
1292 			 1657 			 746
516 			 842 			 370
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 102
265 			 248 			 72
247 			 251 			 79
189 			 169 			 49
161 			 237 			 47
69 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7205338112
Epoch [414/500] took 171.38203263282776s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2963837069514383, train accuracy: 0.5418249099230694
Val mean loss: 1.673689818963772, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2663 			 1998 			 1269
2057 			 2123 			 1117
2101 			 1966 			 1143
1617 			 1683 			 921
1331 			 1657 			 754
500 			 842 			 360
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
329 			 263 			 95
292 			 248 			 75
236 			 251 			 78
196 			 169 			 51
160 			 237 			 46
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7201520640
Epoch [415/500] took 170.51567339897156s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2944970951644803, train accuracy: 0.5432856169052488
Val mean loss: 1.684270160954173, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2575 			 1998 			 1246
2103 			 2123 			 1128
2088 			 1966 			 1139
1627 			 1683 			 928
1358 			 1657 			 763
518 			 842 			 375
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
364 			 263 			 105
285 			 248 			 74
238 			 251 			 79
192 			 169 			 51
135 			 237 			 40
70 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7266385920
Epoch [416/500] took 170.88752508163452s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2957297660108666, train accuracy: 0.5429934755088129
Val mean loss: 1.6890187147187024, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2702 			 1998 			 1282
2081 			 2123 			 1127
2114 			 1966 			 1148
1608 			 1683 			 918
1248 			 1657 			 733
516 			 842 			 368
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 98
306 			 248 			 80
224 			 251 			 74
187 			 169 			 50
152 			 237 			 48
74 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7219510272
Epoch [417/500] took 171.12341237068176s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2944498760306575, train accuracy: 0.5393903982861038
Val mean loss: 1.667728743902067, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2691 			 1998 			 1262
2131 			 2123 			 1134
2044 			 1966 			 1117
1603 			 1683 			 915
1286 			 1657 			 738
514 			 842 			 373
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 100
286 			 248 			 73
245 			 251 			 79
183 			 169 			 49
156 			 237 			 45
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7157725184
Epoch [418/500] took 171.0260283946991s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.293386019650278, train accuracy: 0.5423118122504625
Val mean loss: 1.6960419794408286, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2621 			 1998 			 1254
2096 			 2123 			 1126
2116 			 1966 			 1149
1592 			 1683 			 919
1325 			 1657 			 753
519 			 842 			 368
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 95
301 			 248 			 79
225 			 251 			 73
191 			 169 			 50
162 			 237 			 49
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7213841408
Epoch [419/500] took 170.59118247032166s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.292229431069157, train accuracy: 0.5439672801635992
Val mean loss: 1.6764797902688748, val accuracy: 0.28738317757009346

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2648 			 1998 			 1266
2148 			 2123 			 1148
2053 			 1966 			 1128
1602 			 1683 			 922
1317 			 1657 			 752
501 			 842 			 370
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 263 			 94
286 			 248 			 72
229 			 251 			 75
197 			 169 			 53
157 			 237 			 45
76 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7259701248
Epoch [420/500] took 170.76611757278442s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2924674229458486, train accuracy: 0.5439672801635992
Val mean loss: 1.6563420499243386, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2565 			 1998 			 1238
2132 			 2123 			 1139
2069 			 1966 			 1138
1637 			 1683 			 935
1345 			 1657 			 767
521 			 842 			 369
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 263 			 102
284 			 248 			 75
240 			 251 			 76
180 			 169 			 49
148 			 237 			 45
75 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7213407232
Epoch [421/500] took 170.83315515518188s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.290357496136817, train accuracy: 0.5418249099230694
Val mean loss: 1.6803399411643423, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2679 			 1998 			 1267
2137 			 2123 			 1141
2075 			 1966 			 1128
1561 			 1683 			 907
1308 			 1657 			 748
509 			 842 			 373
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
333 			 263 			 96
282 			 248 			 72
237 			 251 			 77
202 			 169 			 54
156 			 237 			 45
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7196882944
Epoch [422/500] took 171.18535804748535s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2904715088669014, train accuracy: 0.5434803778362061
Val mean loss: 1.6798015047864217, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2612 			 1998 			 1248
2103 			 2123 			 1130
2066 			 1966 			 1128
1639 			 1683 			 941
1328 			 1657 			 761
521 			 842 			 373
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 98
279 			 248 			 73
263 			 251 			 82
185 			 169 			 51
147 			 237 			 44
65 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7216315392
Epoch [423/500] took 171.74112677574158s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2919731073290388, train accuracy: 0.5441620410945565
Val mean loss: 1.67709197939896, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2646 			 1998 			 1260
2136 			 2123 			 1143
2091 			 1966 			 1148
1592 			 1683 			 924
1298 			 1657 			 751
506 			 842 			 362
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 100
269 			 248 			 74
254 			 251 			 82
190 			 169 			 51
152 			 237 			 46
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7201274880
Epoch [424/500] took 170.64516878128052s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2880427519851756, train accuracy: 0.5416301489921121
Val mean loss: 1.66402222179785, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2656 			 1998 			 1257
2135 			 2123 			 1129
2081 			 1966 			 1135
1587 			 1683 			 919
1298 			 1657 			 750
512 			 842 			 372
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
324 			 263 			 92
260 			 248 			 70
263 			 251 			 83
190 			 169 			 50
168 			 237 			 49
79 			 116 			 34
Max memory allocated: 14723398656; Memory allocated: 7232199680
Epoch [425/500] took 171.4700644016266s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2903248292634792, train accuracy: 0.5434803778362061
Val mean loss: 1.670051551446682, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2704 			 1998 			 1276
2108 			 2123 			 1128
2086 			 1966 			 1141
1586 			 1683 			 924
1257 			 1657 			 738
528 			 842 			 374
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
330 			 263 			 95
260 			 248 			 71
250 			 251 			 80
199 			 169 			 52
172 			 237 			 49
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7278379008
Epoch [426/500] took 171.17679834365845s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.287871579514857, train accuracy: 0.546109650404129
Val mean loss: 1.67614394571723, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2639 			 1998 			 1264
2019 			 2123 			 1110
2098 			 1966 			 1158
1647 			 1683 			 941
1367 			 1657 			 774
499 			 842 			 361
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
346 			 263 			 98
290 			 248 			 75
235 			 251 			 78
193 			 169 			 52
148 			 237 			 43
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7252803584
Epoch [427/500] took 170.65828013420105s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.285868611105506, train accuracy: 0.5428960950433344
Val mean loss: 1.6680423631900694, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2620 			 1998 			 1244
2140 			 2123 			 1148
2091 			 1966 			 1141
1596 			 1683 			 915
1295 			 1657 			 750
527 			 842 			 377
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 100
291 			 248 			 76
225 			 251 			 74
181 			 169 			 49
160 			 237 			 46
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7192623104
Epoch [428/500] took 171.0805025100708s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2872741857421732, train accuracy: 0.5439672801635992
Val mean loss: 1.7004869420353959, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2641 			 1998 			 1250
2065 			 2123 			 1122
2069 			 1966 			 1135
1631 			 1683 			 937
1359 			 1657 			 780
504 			 842 			 362
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 102
311 			 248 			 78
237 			 251 			 74
173 			 169 			 46
139 			 237 			 40
71 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7199243264
Epoch [429/500] took 171.02564883232117s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2880190989681493, train accuracy: 0.5457201285422144
Val mean loss: 1.6728915237798923, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2657 			 1998 			 1265
2180 			 2123 			 1157
2069 			 1966 			 1135
1559 			 1683 			 913
1284 			 1657 			 754
520 			 842 			 380
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 98
285 			 248 			 74
249 			 251 			 78
190 			 169 			 50
145 			 237 			 44
68 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7209597952
Epoch [430/500] took 170.80919766426086s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.287845085714465, train accuracy: 0.5456227480767358
Val mean loss: 1.6883277834915533, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2581 			 1998 			 1240
2135 			 2123 			 1139
2080 			 1966 			 1146
1623 			 1683 			 938
1343 			 1657 			 766
507 			 842 			 374
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
337 			 263 			 94
276 			 248 			 74
257 			 251 			 80
192 			 169 			 49
150 			 237 			 46
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7251607552
Epoch [431/500] took 170.77175283432007s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2865248094095247, train accuracy: 0.5458175090076931
Val mean loss: 1.663399050875408, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2647 			 1998 			 1262
2066 			 2123 			 1122
2121 			 1966 			 1168
1629 			 1683 			 933
1298 			 1657 			 750
508 			 842 			 370
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 93
291 			 248 			 72
238 			 251 			 75
182 			 169 			 48
161 			 237 			 48
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7236451328
Epoch [432/500] took 170.2765121459961s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2858255277170199, train accuracy: 0.5425065731814198
Val mean loss: 1.6780028110597192, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2600 			 1998 			 1236
2116 			 2123 			 1133
2074 			 1966 			 1136
1632 			 1683 			 929
1314 			 1657 			 757
533 			 842 			 380
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 99
288 			 248 			 75
241 			 251 			 77
178 			 169 			 47
154 			 237 			 44
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7209401344
Epoch [433/500] took 170.4358389377594s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2845004221360632, train accuracy: 0.5444541824909923
Val mean loss: 1.6702052965396788, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2686 			 1998 			 1283
2109 			 2123 			 1129
2090 			 1966 			 1147
1558 			 1683 			 902
1316 			 1657 			 760
510 			 842 			 370
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
329 			 263 			 97
298 			 248 			 77
233 			 251 			 76
195 			 169 			 50
155 			 237 			 47
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7242234880
Epoch [434/500] took 171.10938382148743s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2877271973826803, train accuracy: 0.5464017918005648
Val mean loss: 1.6723256082069584, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2600 			 1998 			 1253
2140 			 2123 			 1143
2045 			 1966 			 1139
1638 			 1683 			 943
1319 			 1657 			 754
527 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
365 			 263 			 102
274 			 248 			 72
246 			 251 			 77
178 			 169 			 49
150 			 237 			 43
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7222475776
Epoch [435/500] took 171.5324764251709s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2867079533149148, train accuracy: 0.5462070308696075
Val mean loss: 1.6820478875462601, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2676 			 1998 			 1265
2098 			 2123 			 1132
2061 			 1966 			 1144
1597 			 1683 			 922
1318 			 1657 			 769
519 			 842 			 377
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 97
279 			 248 			 72
247 			 251 			 78
186 			 169 			 48
165 			 237 			 46
69 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7212162048
Epoch [436/500] took 170.11489510536194s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2838068242385008, train accuracy: 0.5474729769208296
Val mean loss: 1.6859100068487771, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2575 			 1998 			 1240
2094 			 2123 			 1134
2086 			 1966 			 1154
1626 			 1683 			 944
1363 			 1657 			 771
525 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 98
290 			 248 			 75
225 			 251 			 75
197 			 169 			 52
156 			 237 			 47
69 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7246381056
Epoch [437/500] took 170.73980236053467s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2833300479847323, train accuracy: 0.5466939331970007
Val mean loss: 1.6689704191393968, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2608 			 1998 			 1254
2073 			 2123 			 1125
2114 			 1966 			 1155
1606 			 1683 			 929
1331 			 1657 			 766
537 			 842 			 385
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
346 			 263 			 96
312 			 248 			 80
216 			 251 			 67
207 			 169 			 53
137 			 237 			 41
66 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7226997760
Epoch [438/500] took 171.37137389183044s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2851186192295634, train accuracy: 0.5474729769208296
Val mean loss: 1.6906551616947825, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2661 			 1998 			 1276
2214 			 2123 			 1171
2000 			 1966 			 1119
1625 			 1683 			 937
1252 			 1657 			 740
517 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
325 			 263 			 93
274 			 248 			 70
257 			 251 			 80
196 			 169 			 49
163 			 237 			 48
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7185758208
Epoch [439/500] took 170.70049691200256s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2834672129414164, train accuracy: 0.5460122699386503
Val mean loss: 1.6887701662575327, val accuracy: 0.2967289719626168

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2614 			 1998 			 1252
2090 			 2123 			 1131
2118 			 1966 			 1159
1595 			 1683 			 927
1326 			 1657 			 757
526 			 842 			 381
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
329 			 263 			 98
283 			 248 			 76
254 			 251 			 81
193 			 169 			 50
150 			 237 			 45
75 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7203961856
Epoch [440/500] took 171.12021851539612s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2829699124502616, train accuracy: 0.5487389229720518
Val mean loss: 1.6770625725025083, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2602 			 1998 			 1260
2073 			 2123 			 1128
2115 			 1966 			 1157
1621 			 1683 			 947
1349 			 1657 			 772
509 			 842 			 371
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 100
304 			 248 			 76
242 			 251 			 77
189 			 169 			 48
133 			 237 			 37
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7204649984
Epoch [441/500] took 170.51912999153137s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2811971572329321, train accuracy: 0.5479598792482228
Val mean loss: 1.6790691178019455, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2627 			 1998 			 1258
2136 			 2123 			 1156
2094 			 1966 			 1156
1630 			 1683 			 933
1250 			 1657 			 745
532 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
335 			 263 			 97
295 			 248 			 76
241 			 251 			 77
185 			 169 			 50
156 			 237 			 45
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7279034368
Epoch [442/500] took 170.306293964386s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2804947255927825, train accuracy: 0.5475703573863083
Val mean loss: 1.6822899783529885, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2590 			 1998 			 1255
2163 			 2123 			 1151
2071 			 1966 			 1143
1609 			 1683 			 937
1324 			 1657 			 761
512 			 842 			 376
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 94
270 			 248 			 74
249 			 251 			 82
189 			 169 			 50
162 			 237 			 49
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7221328896
Epoch [443/500] took 171.07176113128662s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2809820093469828, train accuracy: 0.5478624987827442
Val mean loss: 1.6704679349573648, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2675 			 1998 			 1275
2065 			 2123 			 1129
2031 			 1966 			 1128
1601 			 1683 			 936
1377 			 1657 			 784
520 			 842 			 374
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
332 			 263 			 94
296 			 248 			 73
246 			 251 			 77
188 			 169 			 49
147 			 237 			 44
75 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7206984704
Epoch [444/500] took 171.31923532485962s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2817355840005606, train accuracy: 0.5463044113350862
Val mean loss: 1.6837384351869908, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2630 			 1998 			 1264
2126 			 2123 			 1131
2104 			 1966 			 1160
1598 			 1683 			 923
1303 			 1657 			 759
508 			 842 			 373
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 263 			 99
289 			 248 			 76
255 			 251 			 78
177 			 169 			 47
149 			 237 			 44
75 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7192729600
Epoch [445/500] took 170.96374011039734s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2803312662605928, train accuracy: 0.5498101080923167
Val mean loss: 1.6715363990969774, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2531 			 1998 			 1235
2106 			 2123 			 1148
2108 			 1966 			 1169
1634 			 1683 			 939
1378 			 1657 			 781
512 			 842 			 374
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
353 			 263 			 95
273 			 248 			 74
246 			 251 			 79
186 			 169 			 49
156 			 237 			 46
70 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7192737792
Epoch [446/500] took 171.39661693572998s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2809379784117607, train accuracy: 0.5501022494887525
Val mean loss: 1.6840854156308058, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2597 			 1998 			 1267
2126 			 2123 			 1147
2060 			 1966 			 1148
1632 			 1683 			 941
1328 			 1657 			 763
526 			 842 			 383
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
375 			 263 			 101
260 			 248 			 68
254 			 251 			 79
178 			 169 			 48
148 			 237 			 40
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7237229568
Epoch [447/500] took 171.028062582016s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2794017806602787, train accuracy: 0.5506865322816243
Val mean loss: 1.6722331541340525, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2651 			 1998 			 1283
2087 			 2123 			 1138
2125 			 1966 			 1166
1566 			 1683 			 917
1315 			 1657 			 768
525 			 842 			 383
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 99
283 			 248 			 74
239 			 251 			 78
186 			 169 			 48
151 			 237 			 45
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7221050368
Epoch [448/500] took 170.53003668785095s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2775310266797788, train accuracy: 0.5491284448339663
Val mean loss: 1.6708321600425533, val accuracy: 0.2842679127725857

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2618 			 1998 			 1264
2117 			 2123 			 1146
2073 			 1966 			 1146
1604 			 1683 			 935
1329 			 1657 			 770
528 			 842 			 378
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
324 			 263 			 91
284 			 248 			 73
251 			 251 			 77
192 			 169 			 50
158 			 237 			 44
75 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7226776576
Epoch [449/500] took 171.29399752616882s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2799248062190236, train accuracy: 0.5501996299542312
Val mean loss: 1.695307714183156, val accuracy: 0.2881619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2572 			 1998 			 1247
2097 			 2123 			 1148
2107 			 1966 			 1158
1637 			 1683 			 947
1329 			 1657 			 769
527 			 842 			 381
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 96
294 			 248 			 76
239 			 251 			 78
183 			 169 			 47
153 			 237 			 43
68 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7220657152
Epoch [450/500] took 171.46174716949463s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2796941761658571, train accuracy: 0.5483494011101373
Val mean loss: 1.7095323277682792, val accuracy: 0.2982866043613707

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2638 			 1998 			 1264
2109 			 2123 			 1145
2089 			 1966 			 1155
1591 			 1683 			 931
1322 			 1657 			 759
520 			 842 			 377
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
346 			 263 			 102
293 			 248 			 78
236 			 251 			 76
194 			 169 			 53
144 			 237 			 44
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7204879360
Epoch [451/500] took 170.8832061290741s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2777060459707386, train accuracy: 0.5498101080923167
Val mean loss: 1.6834542431482455, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2585 			 1998 			 1260
2182 			 2123 			 1164
2060 			 1966 			 1150
1646 			 1683 			 951
1273 			 1657 			 743
523 			 842 			 378
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
356 			 263 			 99
267 			 248 			 71
242 			 251 			 77
186 			 169 			 48
164 			 237 			 50
69 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7241120768
Epoch [452/500] took 170.8366310596466s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2776685373805394, train accuracy: 0.5486415425065732
Val mean loss: 1.6712761303273642, val accuracy: 0.29439252336448596

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2623 			 1998 			 1255
2088 			 2123 			 1143
2080 			 1966 			 1152
1578 			 1683 			 935
1366 			 1657 			 770
534 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 98
273 			 248 			 73
232 			 251 			 75
214 			 169 			 54
152 			 237 			 48
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7243366400
Epoch [453/500] took 170.94749689102173s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2767430094543648, train accuracy: 0.5524393806602396
Val mean loss: 1.6718876100167996, val accuracy: 0.28738317757009346

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2621 			 1998 			 1258
2087 			 2123 			 1144
2042 			 1966 			 1145
1664 			 1683 			 959
1334 			 1657 			 777
521 			 842 			 390
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 94
294 			 248 			 74
244 			 251 			 76
186 			 169 			 50
154 			 237 			 46
72 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7227587584
Epoch [454/500] took 171.13390016555786s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.276181256473993, train accuracy: 0.5496153471613594
Val mean loss: 1.679205679311985, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2674 			 1998 			 1283
2077 			 2123 			 1133
2124 			 1966 			 1167
1583 			 1683 			 929
1293 			 1657 			 754
518 			 842 			 378
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
314 			 263 			 90
307 			 248 			 77
228 			 251 			 72
193 			 169 			 49
167 			 237 			 49
75 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7258144768
Epoch [455/500] took 171.48738837242126s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2788693017305985, train accuracy: 0.5501996299542312
Val mean loss: 1.6919602068459116, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2609 			 1998 			 1264
2137 			 2123 			 1156
2086 			 1966 			 1157
1585 			 1683 			 929
1327 			 1657 			 767
525 			 842 			 377
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
326 			 263 			 95
299 			 248 			 77
232 			 251 			 75
197 			 169 			 50
158 			 237 			 42
72 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7193524224
Epoch [456/500] took 170.5786099433899s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2740502008396517, train accuracy: 0.5528289025221541
Val mean loss: 1.6806447186121127, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2557 			 1998 			 1251
2165 			 2123 			 1168
2075 			 1966 			 1158
1621 			 1683 			 946
1332 			 1657 			 770
519 			 842 			 384
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 97
282 			 248 			 73
238 			 251 			 73
195 			 169 			 52
160 			 237 			 48
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7201455104
Epoch [457/500] took 171.233567237854s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.27432013152173, train accuracy: 0.5513681955399746
Val mean loss: 1.67268989144302, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2555 			 1998 			 1247
2131 			 2123 			 1150
2051 			 1966 			 1145
1652 			 1683 			 957
1349 			 1657 			 781
531 			 842 			 382
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
361 			 263 			 100
270 			 248 			 71
246 			 251 			 78
178 			 169 			 48
161 			 237 			 47
68 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7212825600
Epoch [458/500] took 171.15969705581665s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2747472208979715, train accuracy: 0.5509786736780602
Val mean loss: 1.6840052430222674, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2666 			 1998 			 1286
2056 			 2123 			 1131
2127 			 1966 			 1170
1559 			 1683 			 923
1340 			 1657 			 767
521 			 842 			 381
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
333 			 263 			 93
283 			 248 			 76
229 			 251 			 73
205 			 169 			 53
160 			 237 			 47
74 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7276396544
Epoch [459/500] took 170.87484002113342s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2735248519995501, train accuracy: 0.5506865322816243
Val mean loss: 1.6791784385355508, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2571 			 1998 			 1250
2133 			 2123 			 1148
2050 			 1966 			 1148
1648 			 1683 			 947
1335 			 1657 			 773
532 			 842 			 389
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 97
279 			 248 			 74
248 			 251 			 79
186 			 169 			 49
156 			 237 			 45
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7213202432
Epoch [460/500] took 171.2159035205841s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2738205331879613, train accuracy: 0.5540948485733762
Val mean loss: 1.6764489644911231, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2615 			 1998 			 1278
2112 			 2123 			 1147
2059 			 1966 			 1148
1627 			 1683 			 952
1331 			 1657 			 777
525 			 842 			 388
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
325 			 263 			 92
276 			 248 			 73
260 			 251 			 82
184 			 169 			 49
168 			 237 			 48
71 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7201012736
Epoch [461/500] took 171.2015998363495s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2740479544315755, train accuracy: 0.5508812932125815
Val mean loss: 1.6670545136056296, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2623 			 1998 			 1277
2117 			 2123 			 1146
2152 			 1966 			 1180
1565 			 1683 			 918
1291 			 1657 			 755
521 			 842 			 381
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
337 			 263 			 93
295 			 248 			 74
212 			 251 			 68
195 			 169 			 52
172 			 237 			 50
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7192885248
Epoch [462/500] took 171.3829424381256s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2728054456621687, train accuracy: 0.5516603369364106
Val mean loss: 1.6912124622158888, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2616 			 1998 			 1266
2110 			 2123 			 1146
2070 			 1966 			 1158
1603 			 1683 			 939
1351 			 1657 			 772
519 			 842 			 384
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 97
287 			 248 			 74
226 			 251 			 73
195 			 169 			 52
163 			 237 			 49
75 			 116 			 32
Max memory allocated: 14723398656; Memory allocated: 7235009536
Epoch [463/500] took 172.10373973846436s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2733121425191933, train accuracy: 0.5509786736780602
Val mean loss: 1.6775751840777513, val accuracy: 0.28738317757009346

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2620 			 1998 			 1267
2167 			 2123 			 1172
2034 			 1966 			 1140
1579 			 1683 			 927
1338 			 1657 			 773
531 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 98
266 			 248 			 69
257 			 251 			 79
194 			 169 			 49
158 			 237 			 45
68 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7196761088
Epoch [464/500] took 170.99055075645447s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2706363700631995, train accuracy: 0.5519524783328464
Val mean loss: 1.6754182664359487, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2560 			 1998 			 1244
2091 			 2123 			 1137
2074 			 1966 			 1161
1665 			 1683 			 957
1335 			 1657 			 773
544 			 842 			 396
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 100
281 			 248 			 75
250 			 251 			 79
182 			 169 			 47
156 			 237 			 45
66 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7246479360
Epoch [465/500] took 170.73833513259888s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.270849874086469, train accuracy: 0.5502970104197098
Val mean loss: 1.6935534593535633, val accuracy: 0.28738317757009346

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2670 			 1998 			 1276
2089 			 2123 			 1136
2090 			 1966 			 1157
1584 			 1683 			 933
1335 			 1657 			 777
501 			 842 			 372
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
336 			 263 			 94
282 			 248 			 73
247 			 251 			 78
192 			 169 			 50
161 			 237 			 46
66 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7227882496
Epoch [466/500] took 170.56240248680115s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2712371198930472, train accuracy: 0.5524393806602396
Val mean loss: 1.6874400580801614, val accuracy: 0.29517133956386293

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2565 			 1998 			 1252
2132 			 2123 			 1160
2106 			 1966 			 1171
1605 			 1683 			 937
1331 			 1657 			 769
530 			 842 			 384
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
344 			 263 			 101
278 			 248 			 72
238 			 251 			 78
189 			 169 			 52
164 			 237 			 47
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7243776000
Epoch [467/500] took 171.05762457847595s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2696598016213034, train accuracy: 0.5526341415911968
Val mean loss: 1.6859875655755765, val accuracy: 0.28738317757009346

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2646 			 1998 			 1274
2051 			 2123 			 1133
2078 			 1966 			 1155
1620 			 1683 			 942
1356 			 1657 			 789
518 			 842 			 382
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
323 			 263 			 93
305 			 248 			 78
225 			 251 			 72
201 			 169 			 52
159 			 237 			 43
71 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7199243264
Epoch [468/500] took 170.86142921447754s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2698683902110637, train accuracy: 0.552342000194761
Val mean loss: 1.6742312297588442, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2594 			 1998 			 1264
2137 			 2123 			 1161
2099 			 1966 			 1158
1595 			 1683 			 943
1340 			 1657 			 775
504 			 842 			 371
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
335 			 263 			 95
302 			 248 			 76
228 			 251 			 74
192 			 169 			 50
153 			 237 			 43
74 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7212964864
Epoch [469/500] took 171.9066412448883s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2687698138465762, train accuracy: 0.5535105657805044
Val mean loss: 1.6644683145895236, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2554 			 1998 			 1256
2139 			 2123 			 1164
2032 			 1966 			 1140
1667 			 1683 			 958
1338 			 1657 			 775
539 			 842 			 391
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
354 			 263 			 102
274 			 248 			 73
247 			 251 			 79
182 			 169 			 47
155 			 237 			 46
72 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7200979968
Epoch [470/500] took 172.4900085926056s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.268409515467017, train accuracy: 0.5530236634531113
Val mean loss: 1.6917008830279838, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2605 			 1998 			 1267
2105 			 2123 			 1147
2083 			 1966 			 1164
1613 			 1683 			 944
1339 			 1657 			 778
524 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
366 			 263 			 101
278 			 248 			 75
226 			 251 			 74
189 			 169 			 51
154 			 237 			 46
71 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7209565184
Epoch [471/500] took 173.04914784431458s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.268434960894124, train accuracy: 0.5532184243840685
Val mean loss: 1.6621062145000551, val accuracy: 0.2881619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2659 			 1998 			 1281
2136 			 2123 			 1163
2050 			 1966 			 1144
1565 			 1683 			 930
1335 			 1657 			 780
524 			 842 			 383
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
335 			 263 			 95
278 			 248 			 74
233 			 251 			 73
202 			 169 			 53
162 			 237 			 45
74 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7197801472
Epoch [472/500] took 173.6038851737976s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.271014681486326, train accuracy: 0.5527315220566754
Val mean loss: 1.7082609606952202, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2594 			 1998 			 1262
2095 			 2123 			 1140
2050 			 1966 			 1152
1666 			 1683 			 955
1330 			 1657 			 776
534 			 842 			 391
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 99
271 			 248 			 72
252 			 251 			 79
183 			 169 			 48
158 			 237 			 48
68 			 116 			 25
Max memory allocated: 14723398656; Memory allocated: 7157725184
Epoch [473/500] took 172.121591091156s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2669513400098615, train accuracy: 0.5524393806602396
Val mean loss: 1.6810641230606451, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2659 			 1998 			 1282
2085 			 2123 			 1136
2113 			 1966 			 1179
1613 			 1683 			 939
1287 			 1657 			 756
512 			 842 			 381
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
326 			 263 			 92
301 			 248 			 79
223 			 251 			 75
185 			 169 			 48
180 			 237 			 54
69 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7207959552
Epoch [474/500] took 171.79802680015564s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2648090512210335, train accuracy: 0.5538027071769404
Val mean loss: 1.6776912066994645, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2548 			 1998 			 1249
2158 			 2123 			 1166
2075 			 1966 			 1158
1548 			 1683 			 919
1397 			 1657 			 801
543 			 842 			 394
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
334 			 263 			 98
265 			 248 			 70
241 			 251 			 77
206 			 169 			 52
167 			 237 			 49
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7205567488
Epoch [475/500] took 173.44688296318054s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2677542576537326, train accuracy: 0.5563345992793846
Val mean loss: 1.6894404510172403, val accuracy: 0.2881619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2573 			 1998 			 1251
2035 			 2123 			 1139
2084 			 1966 			 1174
1679 			 1683 			 970
1357 			 1657 			 785
541 			 842 			 394
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 263 			 95
295 			 248 			 75
248 			 251 			 77
179 			 169 			 48
150 			 237 			 45
73 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7209204736
Epoch [476/500] took 172.5917263031006s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.265950542001338, train accuracy: 0.5560424578829487
Val mean loss: 1.6793135695341157, val accuracy: 0.2881619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2557 			 1998 			 1259
2128 			 2123 			 1159
2101 			 1966 			 1170
1582 			 1683 			 941
1368 			 1657 			 790
533 			 842 			 391
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 101
282 			 248 			 74
243 			 251 			 76
192 			 169 			 48
149 			 237 			 43
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7228341248
Epoch [477/500] took 172.83236527442932s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2659165257605436, train accuracy: 0.5569188820722563
Val mean loss: 1.6906608517577009, val accuracy: 0.2881619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2615 			 1998 			 1275
2068 			 2123 			 1145
2115 			 1966 			 1178
1611 			 1683 			 947
1327 			 1657 			 781
533 			 842 			 393
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 263 			 97
304 			 248 			 79
218 			 251 			 71
193 			 169 			 49
159 			 237 			 47
68 			 116 			 27
Max memory allocated: 14723398656; Memory allocated: 7198669824
Epoch [478/500] took 172.6814513206482s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2647868526687502, train accuracy: 0.5543869899698121
Val mean loss: 1.682416459409202, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2591 			 1998 			 1265
2142 			 2123 			 1167
2062 			 1966 			 1149
1620 			 1683 			 945
1337 			 1657 			 783
517 			 842 			 384
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
340 			 263 			 95
283 			 248 			 74
249 			 251 			 79
185 			 169 			 48
158 			 237 			 47
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7217560576
Epoch [479/500] took 171.99137806892395s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2632913726883885, train accuracy: 0.5549712727626838
Val mean loss: 1.6909316749107548, val accuracy: 0.29205607476635514

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2595 			 1998 			 1265
2177 			 2123 			 1177
2087 			 1966 			 1166
1566 			 1683 			 933
1317 			 1657 			 770
527 			 842 			 388
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
340 			 263 			 98
258 			 248 			 70
244 			 251 			 78
209 			 169 			 53
160 			 237 			 48
73 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7239908352
Epoch [480/500] took 172.73692631721497s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2645881140714865, train accuracy: 0.555166033693641
Val mean loss: 1.6936547698044195, val accuracy: 0.2850467289719626

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2615 			 1998 			 1272
2054 			 2123 			 1131
2090 			 1966 			 1167
1644 			 1683 			 960
1329 			 1657 			 781
537 			 842 			 390
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 93
278 			 248 			 72
239 			 251 			 75
194 			 169 			 49
162 			 237 			 48
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7269531648
Epoch [481/500] took 172.2916271686554s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.261679893342134, train accuracy: 0.5591586327782647
Val mean loss: 1.6885062107225743, val accuracy: 0.29283489096573206

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2597 			 1998 			 1282
2047 			 2123 			 1138
2100 			 1966 			 1178
1609 			 1683 			 950
1365 			 1657 			 794
551 			 842 			 400
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 97
296 			 248 			 77
227 			 251 			 75
194 			 169 			 51
152 			 237 			 46
68 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7284752384
Epoch [482/500] took 173.2710371017456s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.263809139483443, train accuracy: 0.5583795890544356
Val mean loss: 1.6981729239952275, val accuracy: 0.29127725856697817

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2576 			 1998 			 1267
2160 			 2123 			 1179
2086 			 1966 			 1172
1610 			 1683 			 949
1314 			 1657 			 775
523 			 842 			 392
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
350 			 263 			 101
274 			 248 			 71
229 			 251 			 72
206 			 169 			 54
157 			 237 			 47
68 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7230471168
Epoch [483/500] took 172.61262965202332s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.261822912923272, train accuracy: 0.5565293602103418
Val mean loss: 1.6751037777923956, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2588 			 1998 			 1268
2115 			 2123 			 1150
2071 			 1966 			 1167
1649 			 1683 			 958
1307 			 1657 			 776
539 			 842 			 396
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 263 			 97
287 			 248 			 75
230 			 251 			 73
191 			 169 			 49
163 			 237 			 45
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7193540608
Epoch [484/500] took 172.52627801895142s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2598935200417896, train accuracy: 0.5574057843996494
Val mean loss: 1.684143883426015, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2616 			 1998 			 1278
2074 			 2123 			 1145
2056 			 1966 			 1161
1600 			 1683 			 946
1378 			 1657 			 791
545 			 842 			 403
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 100
275 			 248 			 73
234 			 251 			 75
202 			 169 			 52
155 			 237 			 45
69 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7216708608
Epoch [485/500] took 173.37373733520508s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2622553163971113, train accuracy: 0.5588664913818288
Val mean loss: 1.678197997372325, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2611 			 1998 			 1280
2092 			 2123 			 1153
2092 			 1966 			 1179
1611 			 1683 			 953
1332 			 1657 			 777
531 			 842 			 397
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
336 			 263 			 98
280 			 248 			 73
243 			 251 			 76
201 			 169 			 51
154 			 237 			 45
70 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7230577664
Epoch [486/500] took 172.4668459892273s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2609286553391785, train accuracy: 0.5563345992793846
Val mean loss: 1.700168763718954, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2561 			 1998 			 1257
2129 			 2123 			 1160
2071 			 1966 			 1164
1637 			 1683 			 953
1344 			 1657 			 791
527 			 842 			 388
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 99
283 			 248 			 75
243 			 251 			 77
178 			 169 			 47
163 			 237 			 46
68 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7253344256
Epoch [487/500] took 173.10649919509888s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2629624209671377, train accuracy: 0.5546791313662479
Val mean loss: 1.6837313291503162, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2659 			 1998 			 1287
2153 			 2123 			 1168
2058 			 1966 			 1157
1552 			 1683 			 924
1312 			 1657 			 768
535 			 842 			 392
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
317 			 263 			 92
273 			 248 			 72
251 			 251 			 76
209 			 169 			 52
163 			 237 			 46
71 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7202036736
Epoch [488/500] took 173.0531656742096s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.261242566821731, train accuracy: 0.5550686532281625
Val mean loss: 1.6729748190903082, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2539 			 1998 			 1247
2075 			 2123 			 1140
2129 			 1966 			 1179
1616 			 1683 			 949
1381 			 1657 			 795
529 			 842 			 390
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
352 			 263 			 99
274 			 248 			 71
239 			 251 			 76
193 			 169 			 51
156 			 237 			 45
70 			 116 			 26
Max memory allocated: 14723398656; Memory allocated: 7260143616
Epoch [489/500] took 173.16512489318848s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2626320810704217, train accuracy: 0.5585743499853929
Val mean loss: 1.6793273164004814, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2596 			 1998 			 1274
2116 			 2123 			 1158
2057 			 1966 			 1168
1657 			 1683 			 964
1297 			 1657 			 770
546 			 842 			 402
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
348 			 263 			 101
283 			 248 			 72
230 			 251 			 71
192 			 169 			 51
164 			 237 			 48
67 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7233895424
Epoch [490/500] took 172.13842678070068s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2577212053667348, train accuracy: 0.5557503164865129
Val mean loss: 1.6946378015890353, val accuracy: 0.2819314641744548

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2556 			 1998 			 1260
2121 			 2123 			 1156
2051 			 1966 			 1153
1605 			 1683 			 947
1384 			 1657 			 793
552 			 842 			 398
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
347 			 263 			 95
277 			 248 			 71
242 			 251 			 73
198 			 169 			 48
152 			 237 			 47
68 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7306331136
Epoch [491/500] took 173.67792630195618s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2619291001762556, train accuracy: 0.5586717304508716
Val mean loss: 1.6696258347208908, val accuracy: 0.2842679127725857

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2613 			 1998 			 1276
2104 			 2123 			 1162
2085 			 1966 			 1178
1601 			 1683 			 943
1353 			 1657 			 799
513 			 842 			 379
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
340 			 263 			 95
275 			 248 			 73
252 			 251 			 78
193 			 169 			 48
151 			 237 			 42
73 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7197506560
Epoch [492/500] took 172.66184782981873s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2591173942215346, train accuracy: 0.5600350569675723
Val mean loss: 1.6803770646816347, val accuracy: 0.29361370716510904

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2536 			 1998 			 1256
2110 			 2123 			 1164
2119 			 1966 			 1187
1624 			 1683 			 961
1339 			 1657 			 789
541 			 842 			 394
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
349 			 263 			 102
281 			 248 			 73
228 			 251 			 75
193 			 169 			 51
164 			 237 			 46
69 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7213513728
Epoch [493/500] took 172.40355968475342s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.259766063957571, train accuracy: 0.5577953062615639
Val mean loss: 1.668753091881915, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2604 			 1998 			 1278
2102 			 2123 			 1155
2029 			 1966 			 1152
1673 			 1683 			 968
1328 			 1657 			 787
533 			 842 			 388
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 263 			 94
280 			 248 			 75
265 			 251 			 79
177 			 169 			 46
154 			 237 			 48
69 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7198717952
Epoch [494/500] took 172.66990208625793s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2578733658122125, train accuracy: 0.5576979257960853
Val mean loss: 1.6919689789050962, val accuracy: 0.2834890965732087

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2597 			 1998 			 1269
2095 			 2123 			 1158
2149 			 1966 			 1195
1568 			 1683 			 936
1328 			 1657 			 778
532 			 842 			 391
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
326 			 263 			 90
299 			 248 			 75
234 			 251 			 73
180 			 169 			 45
170 			 237 			 51
75 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7249174528
Epoch [495/500] took 173.00921988487244s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.257672098752494, train accuracy: 0.5576005453306067
Val mean loss: 1.6742007557938738, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2575 			 1998 			 1265
2122 			 2123 			 1159
2054 			 1966 			 1158
1609 			 1683 			 953
1377 			 1657 			 797
532 			 842 			 394
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
323 			 263 			 93
282 			 248 			 74
242 			 251 			 74
206 			 169 			 53
158 			 237 			 47
73 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7211006976
Epoch [496/500] took 173.25745964050293s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2577743663966099, train accuracy: 0.5592560132437433
Val mean loss: 1.6829075522539092, val accuracy: 0.28582554517133957

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2513 			 1998 			 1246
2121 			 2123 			 1163
2129 			 1966 			 1195
1631 			 1683 			 956
1322 			 1657 			 783
553 			 842 			 400
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
343 			 263 			 96
265 			 248 			 71
227 			 251 			 72
202 			 169 			 52
177 			 237 			 48
70 			 116 			 28
Max memory allocated: 14723398656; Memory allocated: 7307871232
Epoch [497/500] took 173.06173872947693s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2576557891762516, train accuracy: 0.5624695686045379
Val mean loss: 1.6723129109638493, val accuracy: 0.2866043613707165

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2544 			 1998 			 1267
2111 			 2123 			 1166
2026 			 1966 			 1159
1634 			 1683 			 966
1416 			 1657 			 823
538 			 842 			 395
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
341 			 263 			 98
289 			 248 			 74
243 			 251 			 73
195 			 169 			 50
145 			 237 			 42
71 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7215528960
Epoch [498/500] took 172.57022190093994s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2550880520885979, train accuracy: 0.5600350569675723
Val mean loss: 1.686609585110734, val accuracy: 0.2897196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2596 			 1998 			 1281
2105 			 2123 			 1162
2127 			 1966 			 1189
1606 			 1683 			 951
1313 			 1657 			 778
522 			 842 			 390
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
345 			 263 			 98
295 			 248 			 79
234 			 251 			 74
179 			 169 			 47
159 			 237 			 44
72 			 116 			 30
Max memory allocated: 14723398656; Memory allocated: 7198137344
Epoch [499/500] took 173.3589370250702s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2569629991908682, train accuracy: 0.5579900671925212
Val mean loss: 1.6761351474901525, val accuracy: 0.29049844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2628 			 1998 			 1283
2118 			 2123 			 1163
2035 			 1966 			 1155
1598 			 1683 			 950
1355 			 1657 			 787
535 			 842 			 392
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
319 			 263 			 91
285 			 248 			 74
254 			 251 			 81
191 			 169 			 49
160 			 237 			 49
75 			 116 			 29
Max memory allocated: 14723398656; Memory allocated: 7187159040
Epoch [500/500] took 173.3101670742035s
Experiment configuration: {'LM': 'LLAMA 2 13B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 500, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}}
Train mean loss: 1.2565839689840037, train accuracy: 0.5588664913818288
Val mean loss: 1.689560797156357, val accuracy: 0.28894080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2558 			 1998 			 1252
2126 			 2123 			 1164
2071 			 1966 			 1173
1644 			 1683 			 971
1348 			 1657 			 791
522 			 842 			 388
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
338 			 263 			 98
294 			 248 			 75
243 			 251 			 77
185 			 169 			 47
153 			 237 			 43
71 			 116 			 31
Max memory allocated: 14723398656; Memory allocated: 7246970880
Training finished! Training for 500 epochs took: 85851.62616252899s
Training loss: [1.7730096823701234, 1.7442781550119228, 1.7307670238976167, 1.7214172651463209, 1.7121207725221865, 1.7056860270158525, 1.6986169532823414, 1.6935578161310927, 1.6880532581115437, 1.683397488430653, 1.6782646023224448, 1.674428669834434, 1.6707998499320675, 1.6664332489358302, 1.6630901194807153, 1.658561799013726, 1.6562097648222498, 1.6534875159694398, 1.6501032953321748, 1.6476494538078428, 1.6438785048660087, 1.6412702954818155, 1.6398203610631163, 1.6367044144330367, 1.6347250284806962, 1.6319212323037264, 1.630019164902399, 1.626549649832776, 1.6239054834359903, 1.6225217075734124, 1.6198429582274962, 1.6180428623039032, 1.6172189582545438, 1.6137297547123515, 1.612459998264491, 1.6096509267979322, 1.6070007297480218, 1.6059487812987, 1.6040487957892018, 1.602136438138017, 1.6001306192897191, 1.5983640167200677, 1.5966868656817998, 1.595571133577935, 1.592607289088478, 1.5924607433634013, 1.5888662423671591, 1.5878237771839367, 1.5862274288759797, 1.5843055615915316, 1.583284383250917, 1.5817101269124825, 1.5803150811299356, 1.5770835130014151, 1.575850249822266, 1.575376225780475, 1.5741865724046653, 1.572476695631152, 1.569545586161153, 1.5696351383334008, 1.5662918800134153, 1.566246573056016, 1.5647528401787778, 1.5636646929559679, 1.562068739041361, 1.5596810802121028, 1.55836134796202, 1.5580561112763354, 1.5565854485532575, 1.5551500442986177, 1.5523071029104547, 1.5530313721327025, 1.5504647705042474, 1.5494029997293823, 1.5475811482961304, 1.5470558843137319, 1.5447926168501191, 1.5453196192084815, 1.5439454684747713, 1.5414474389263402, 1.540087785676261, 1.5394624159714887, 1.5390136969795107, 1.536643330553239, 1.5364331363517547, 1.5347836975739382, 1.534781814364258, 1.5334911918343042, 1.529887145924791, 1.529521448589931, 1.5287690155231322, 1.527709670898699, 1.5260901818765658, 1.5254247522799769, 1.5239865341661876, 1.5222169197979747, 1.5225376689174093, 1.5198870971566791, 1.5206998653500994, 1.5201473878551495, 1.5173388519019724, 1.5166653754926545, 1.5133161199427096, 1.513686245104234, 1.5127469278941645, 1.5116074530877799, 1.5100172420157079, 1.509394422127079, 1.508238538774746, 1.5072604139274526, 1.5064960770146498, 1.5047750955801515, 1.505200648604895, 1.5033292777813112, 1.5016074054337736, 1.5009804496141237, 1.5005737494828173, 1.4992834470725134, 1.4969732029787106, 1.4959461336195283, 1.495600929141416, 1.4947854514433958, 1.492431903925269, 1.491661612118516, 1.492160702791541, 1.4908823695880973, 1.490349693461742, 1.4910045594812553, 1.486795235645734, 1.4871848732511574, 1.4862545806670857, 1.484482954224322, 1.483662199008502, 1.4826122882581574, 1.4825709723980627, 1.4814420983056042, 1.4803427955443242, 1.4800310365136167, 1.4781310614024368, 1.478212599442384, 1.4763996719942658, 1.4751405556253927, 1.4739657930124586, 1.4740356184611811, 1.4733276879676034, 1.4727615006616182, 1.4714259529410865, 1.4694574235755706, 1.4710812475822426, 1.468390573965055, 1.4662191563306197, 1.4656485345133368, 1.4639809618115054, 1.4640343902267028, 1.462839216458092, 1.4640582677359892, 1.461458834903634, 1.4620610973173955, 1.4594911923661038, 1.4583119384224912, 1.4571038324884908, 1.4568720005011633, 1.457927142348245, 1.4552747100313133, 1.456140620314815, 1.4533394601114813, 1.4535972908649861, 1.452559179606096, 1.4496881713005612, 1.4527402629733457, 1.4479975748656324, 1.4488356132002262, 1.4461694424768845, 1.4455023357801349, 1.4471119820514573, 1.4453566854245194, 1.445251858122995, 1.4428644815337992, 1.4433045866333436, 1.4429194607838662, 1.4416573445002239, 1.441015945788113, 1.4400048471314142, 1.4394002142724962, 1.4367022061273689, 1.4357845289313533, 1.436056258151093, 1.436320697778482, 1.4353438686358966, 1.4325235016249422, 1.432236339444312, 1.432881358627961, 1.4312110686227912, 1.4306566663248887, 1.4302320220388727, 1.4283759196599324, 1.429285549300482, 1.4280149167943224, 1.4268500719486368, 1.4257063977072173, 1.423742198127081, 1.4258860342227782, 1.4226170614872395, 1.4241856240037818, 1.4244210512095894, 1.4242996437898678, 1.419682049677008, 1.420588995066016, 1.4199678886716611, 1.4189098315818287, 1.4163589707787534, 1.4175128602535925, 1.4172768013499608, 1.4163227471235758, 1.4151316019604883, 1.415287747190006, 1.4144314549793706, 1.4121827466465602, 1.410881469925616, 1.4114998229938875, 1.4114201949021528, 1.4096552512356053, 1.4093067939407729, 1.4070037893045728, 1.4059111414668717, 1.4049825051863245, 1.406218867807002, 1.4058142696214242, 1.4039929288198643, 1.4034905088282077, 1.4031152766070263, 1.4035746887836873, 1.4029122750707133, 1.4014069313572204, 1.4015461429257259, 1.4003417031415897, 1.3984231451218745, 1.3975571698488847, 1.3970429473948256, 1.3978051645362117, 1.3957455473896871, 1.3943033604607034, 1.3950998363465164, 1.3946579479354193, 1.3937114406597577, 1.392755506566009, 1.3927768461429442, 1.3919943355696967, 1.3896566592272939, 1.391234967938836, 1.3883768606037366, 1.3896966960942634, 1.3884742196846602, 1.3880243435084263, 1.386958818197993, 1.387051034939252, 1.3854616913840034, 1.3851557097331015, 1.382888575952001, 1.3816466847684152, 1.3837082096349413, 1.3826414524951829, 1.3832884718695906, 1.3819068677700197, 1.3799343365375127, 1.3801728104505213, 1.3780296001107522, 1.3765420241519297, 1.377040526205877, 1.3765190505535803, 1.3773812813179516, 1.3752331767126778, 1.3766460537539094, 1.3745516122687271, 1.373116767295053, 1.3726343306425577, 1.3719778413713164, 1.3722938989924494, 1.373855950676392, 1.3696501596694424, 1.369988778669886, 1.371010078076633, 1.3677432113718764, 1.3690711631210422, 1.366202769621139, 1.365969009117174, 1.3649432867115532, 1.3655463980737133, 1.3653079783805062, 1.364082774640615, 1.3644972356309029, 1.3617604796388811, 1.3618653622743124, 1.3617942199528774, 1.3612404244711094, 1.3605132882840165, 1.361048988464094, 1.3591346504903656, 1.3564359142772877, 1.3583971228554985, 1.3588765176285835, 1.3565733689014043, 1.356686043219403, 1.354967154075052, 1.355136305000923, 1.3525762357444406, 1.352601817835157, 1.352502199719628, 1.3519517123884872, 1.352764994555916, 1.350754238363367, 1.351122484400265, 1.3495988047382914, 1.3481446088660172, 1.348471607374625, 1.3467194796351258, 1.3469885539414355, 1.3467749004423433, 1.34622243371708, 1.3463995300720786, 1.3451723918736538, 1.345686410817773, 1.345403220794654, 1.3422295664701136, 1.343963389084718, 1.3432954546075744, 1.3403815554681224, 1.3411615956980862, 1.3417651868683527, 1.3421293942727774, 1.3409305257589275, 1.339864329385609, 1.337493216137277, 1.3376253215694724, 1.3376039845921168, 1.3379480601099794, 1.3365919344893127, 1.3346725252929879, 1.3352497511563644, 1.33726813043018, 1.3339590227863871, 1.3343217941088097, 1.3308935072563148, 1.333552258036961, 1.3327089733795214, 1.3312938306190514, 1.3318499497535443, 1.329075691484588, 1.3280400542826667, 1.330541842823088, 1.328175872657158, 1.3284540009275776, 1.3262260669488402, 1.3275191219424904, 1.3276835420049982, 1.3271323256774854, 1.3233855505970036, 1.326171978983181, 1.3241420765160772, 1.3241688280462105, 1.3224100780635608, 1.3230704180548125, 1.322699786718018, 1.3215061894087035, 1.3220467474601723, 1.3190760549355147, 1.319434082768045, 1.3186030272754181, 1.3181509507408022, 1.3176441200054323, 1.3157214685763896, 1.3158049316049736, 1.315236489720805, 1.3148181761536644, 1.3140465663600933, 1.3136540153687617, 1.3158148007229482, 1.3136772882901249, 1.3118633172965124, 1.311082821397395, 1.31270544625517, 1.3108815608366255, 1.3113958716763885, 1.310665351579494, 1.3098886547801651, 1.3094191061002072, 1.3091037418240699, 1.3096566575338535, 1.3073975352854743, 1.308393058747146, 1.3049493276070212, 1.3057739430127486, 1.3077262406037233, 1.3049936617646263, 1.304305979767321, 1.304289908795342, 1.3051934283099071, 1.3041170620101263, 1.303642859711454, 1.3010948454479563, 1.302691550641045, 1.3007850697107404, 1.302063952725253, 1.3010392582676493, 1.299265795407637, 1.2992867142240578, 1.2999205864107126, 1.2960677960208644, 1.2984448834743083, 1.2976807437581808, 1.2960498112013035, 1.295002266068325, 1.2959802273277925, 1.2963837069514383, 1.2944970951644803, 1.2957297660108666, 1.2944498760306575, 1.293386019650278, 1.292229431069157, 1.2924674229458486, 1.290357496136817, 1.2904715088669014, 1.2919731073290388, 1.2880427519851756, 1.2903248292634792, 1.287871579514857, 1.285868611105506, 1.2872741857421732, 1.2880190989681493, 1.287845085714465, 1.2865248094095247, 1.2858255277170199, 1.2845004221360632, 1.2877271973826803, 1.2867079533149148, 1.2838068242385008, 1.2833300479847323, 1.2851186192295634, 1.2834672129414164, 1.2829699124502616, 1.2811971572329321, 1.2804947255927825, 1.2809820093469828, 1.2817355840005606, 1.2803312662605928, 1.2809379784117607, 1.2794017806602787, 1.2775310266797788, 1.2799248062190236, 1.2796941761658571, 1.2777060459707386, 1.2776685373805394, 1.2767430094543648, 1.276181256473993, 1.2788693017305985, 1.2740502008396517, 1.27432013152173, 1.2747472208979715, 1.2735248519995501, 1.2738205331879613, 1.2740479544315755, 1.2728054456621687, 1.2733121425191933, 1.2706363700631995, 1.270849874086469, 1.2712371198930472, 1.2696598016213034, 1.2698683902110637, 1.2687698138465762, 1.268409515467017, 1.268434960894124, 1.271014681486326, 1.2669513400098615, 1.2648090512210335, 1.2677542576537326, 1.265950542001338, 1.2659165257605436, 1.2647868526687502, 1.2632913726883885, 1.2645881140714865, 1.261679893342134, 1.263809139483443, 1.261822912923272, 1.2598935200417896, 1.2622553163971113, 1.2609286553391785, 1.2629624209671377, 1.261242566821731, 1.2626320810704217, 1.2577212053667348, 1.2619291001762556, 1.2591173942215346, 1.259766063957571, 1.2578733658122125, 1.257672098752494, 1.2577743663966099, 1.2576557891762516, 1.2550880520885979, 1.2569629991908682, 1.2565839689840037]
Validation loss: [1.7552053317791079, 1.7491635607510079, 1.7373295818887107, 1.7327529104744517, 1.7328534009979992, 1.7154508741890513, 1.7180324473032138, 1.7109605568211252, 1.7030761212837406, 1.6947608720965501, 1.6955249483992414, 1.694917446229516, 1.6992407601054123, 1.6885271799273607, 1.6850947781306942, 1.694299017510763, 1.6907204942005436, 1.7013307838905147, 1.6895701245563786, 1.6797204744525072, 1.682787438718284, 1.6802628185690902, 1.6764100499269439, 1.6751870469349186, 1.6785473707245617, 1.6675397826404106, 1.6861132005365884, 1.6688147812354854, 1.662739890377696, 1.6732762877534075, 1.6655101165538881, 1.6778177720744436, 1.6614237936531626, 1.6550625533592411, 1.6627623017241315, 1.6687202162858916, 1.6736582081492355, 1.6609510096108042, 1.6617010366625902, 1.6580708143187732, 1.6729946107399174, 1.6592567868349029, 1.6599845101193684, 1.6528829539694436, 1.6584869594108769, 1.6533316112146146, 1.6621376014337308, 1.6574060277241032, 1.6547771197993582, 1.6627381225911582, 1.6561030643742258, 1.6492474050056645, 1.6602886857056036, 1.6456808346073801, 1.6579489853323959, 1.6575419234066475, 1.6658092330141765, 1.65528500370863, 1.6590855586819533, 1.6451991273135673, 1.6454759778046026, 1.658507501206747, 1.6533924835484202, 1.6512267822172584, 1.649469000537221, 1.653275076935931, 1.6483620405197144, 1.6426729254606294, 1.6640818409803437, 1.6482478409278682, 1.6532214182179148, 1.6452187299728394, 1.6488236276114858, 1.649211363094609, 1.6515488217516643, 1.6416862563389103, 1.652675869988232, 1.6561515941852476, 1.6436767636275873, 1.6643134210167863, 1.6553693108442353, 1.6390189135946878, 1.6529440967048086, 1.6533590177210367, 1.6561538649768364, 1.6532825783985416, 1.6501336330320777, 1.6451379177046985, 1.6368967788975413, 1.6461906171426541, 1.6425682335365108, 1.644905776512332, 1.6547193294618188, 1.6453296004272089, 1.6439967155456543, 1.6391595311281157, 1.6416381510292613, 1.6424484020326195, 1.6425359278190426, 1.6383753549761888, 1.6448764103214915, 1.6532418175441463, 1.6436462518645496, 1.6424616313562161, 1.6469449677118442, 1.642949616036764, 1.6336247688386498, 1.6448374608667886, 1.6508867130046938, 1.6589059800636479, 1.6482315296080055, 1.6398219044615583, 1.6657655064652606, 1.6336010839880966, 1.644862413406372, 1.6474893005882822, 1.644033853600665, 1.645699201560602, 1.6411042475118869, 1.6456455602878477, 1.6342067369600621, 1.658042550086975, 1.641749728016737, 1.6340775460731694, 1.657186912327278, 1.640937840066305, 1.6403900559355573, 1.661758318179991, 1.6450449984248092, 1.6463268733606107, 1.647124368969987, 1.6438781808062297, 1.6401397571331118, 1.6502323266936512, 1.6238929556637276, 1.640791654586792, 1.6588100601987141, 1.6527402517272205, 1.651808985849706, 1.6461677056987112, 1.6517046660911747, 1.6361023129486456, 1.6734907627105713, 1.638505897870878, 1.6479528182890357, 1.65297692287259, 1.6389833427057034, 1.6599427577925892, 1.6454361764396108, 1.646947436216401, 1.6592227656666825, 1.6500983499899142, 1.6479670274548415, 1.6397752878142566, 1.6538164528404795, 1.6511545908160326, 1.6472466079200185, 1.6331621641066016, 1.6634264399365681, 1.6669636819420792, 1.6479492856235038, 1.6497362823021122, 1.6357459556765672, 1.6603123734637004, 1.640655023295705, 1.6691585517511136, 1.6495064380692273, 1.6378705152651158, 1.6442316828704462, 1.6551045819026668, 1.6477211481187402, 1.6471086507890282, 1.6397634919096784, 1.6523358240360166, 1.6464581547713861, 1.6409144546927474, 1.644388809436705, 1.6565074775277115, 1.6412632668890603, 1.6430900881930095, 1.6411343434961831, 1.6496431972922347, 1.6553012190795526, 1.6447175217837822, 1.6485064175070785, 1.6420966357719609, 1.6491098258553483, 1.653404250377562, 1.6388465863902395, 1.6609603108429327, 1.6506525307166866, 1.6402086717326467, 1.6513794020908634, 1.6591477626707496, 1.6514662213441802, 1.6499188353375691, 1.6437743814980113, 1.653458339412038, 1.637319803237915, 1.6447623299389351, 1.666146976191823, 1.6534126677164218, 1.638149520245994, 1.6614233487989845, 1.6561746946195277, 1.647010640400212, 1.6662596028025558, 1.647079447420632, 1.661137580871582, 1.6485792020472085, 1.6593471038632277, 1.647648712483848, 1.6453755308942097, 1.6584226707132852, 1.6541106817198963, 1.6460488511294853, 1.6462477038546306, 1.6450562738790744, 1.6450365200275328, 1.6544798438141985, 1.6425705653865164, 1.6344047494050933, 1.6560806181372665, 1.6395780109777682, 1.6485419680432576, 1.6506936084933397, 1.6459942736276767, 1.6572024996687726, 1.6456046075355717, 1.6494148591669595, 1.654327828709672, 1.6567920911602858, 1.655387660352195, 1.688169729418871, 1.644838536657938, 1.6486507334360263, 1.6444017916190914, 1.6507898249277255, 1.650015601297704, 1.6477943775130481, 1.6496319131153385, 1.6667963876956846, 1.6469933347004215, 1.6477724982471, 1.6624266432552803, 1.6300494801707384, 1.6568962655416348, 1.6442686668256434, 1.6544649600982666, 1.6558974545176437, 1.651322396790109, 1.6515695612605026, 1.6448386674974023, 1.648406586995939, 1.6474313387056676, 1.6568091526264097, 1.662128416503348, 1.6426582045671416, 1.656738554559103, 1.6642172976237972, 1.6486214486564077, 1.6559846575667219, 1.653372453480232, 1.6686398750398217, 1.6520616601153117, 1.6611998924394933, 1.6559711811019153, 1.6533799636654738, 1.661732990567277, 1.6707758176617507, 1.648066552673898, 1.6542546400209752, 1.6558531261071927, 1.677526130908873, 1.6576922230604219, 1.662777551790563, 1.6600666075218014, 1.6507013716348788, 1.6464721255186128, 1.640778948621052, 1.6459273681408022, 1.6538520586199876, 1.6702118937562151, 1.654843533911356, 1.6592259203515403, 1.662052538336777, 1.6419286001019362, 1.6608612043101614, 1.6707140265441522, 1.6523242898103667, 1.6685339008889548, 1.6612110108864018, 1.6566236629718687, 1.6543044724115512, 1.6631901903850277, 1.6520011948376168, 1.6542083868166295, 1.6484874690451272, 1.6512305416711948, 1.657267523974907, 1.6805605626687772, 1.6455119557496978, 1.6692412103094705, 1.65226809571429, 1.6613933691164342, 1.6617673839010842, 1.6669998634152297, 1.6632826037523223, 1.6684343087963942, 1.6739063844448183, 1.6455171224547596, 1.6763703939391346, 1.6597970811332143, 1.658270934732949, 1.65720040914489, 1.6767728241478526, 1.6732532396549131, 1.6644260679803244, 1.670186691167878, 1.6730159870008143, 1.6827330560218998, 1.6603557714601842, 1.6656490622497186, 1.6675619032324813, 1.6649930302689715, 1.6711953180592234, 1.661475725290252, 1.6554339164640846, 1.6679403840041742, 1.656740682881053, 1.6736530443517172, 1.6794031771217905, 1.652760749909936, 1.6539502899821212, 1.6618306724036611, 1.6839259833824345, 1.6593170340468244, 1.670707891627056, 1.6708016831700394, 1.6688377072171467, 1.6507336453693668, 1.6681926831966494, 1.6616881387989695, 1.6496323608770602, 1.6559078809691639, 1.6603931421186866, 1.6636394960124319, 1.665245640568617, 1.6700287999176398, 1.671276191385781, 1.6603238146479538, 1.6798706403592738, 1.6624040719939441, 1.6706679448848818, 1.685708941482916, 1.656034580091151, 1.667885835577802, 1.6504579753410527, 1.6959690553386038, 1.6846983200166283, 1.66968433449908, 1.6643043000523636, 1.6677314043045044, 1.6867850553698656, 1.662528593365739, 1.6958322670401595, 1.6833311464728378, 1.6738957137596318, 1.666821200673173, 1.6722098385415427, 1.665550525595502, 1.6772194432049263, 1.6707105113238823, 1.6625492979840535, 1.6793046491902048, 1.6618452886255777, 1.6735498672578393, 1.66916872815388, 1.6697572178956939, 1.6615152329933354, 1.6686176584988106, 1.6689835205310728, 1.6640339566440117, 1.6765233598104337, 1.659424240996198, 1.6713533372413822, 1.6826487808692745, 1.6664184564497413, 1.6569721146327694, 1.6679055254633834, 1.6912455558776855, 1.6746981173026851, 1.6803849295872013, 1.6791815234393608, 1.678820647844454, 1.6651555532362403, 1.6810423135757446, 1.6505119626115008, 1.6878499112478116, 1.6804328488140572, 1.655569893557851, 1.6855609649565162, 1.6694733224264005, 1.663913162743173, 1.6748257148556593, 1.6726954361287558, 1.6788466558223818, 1.6678446676672958, 1.6868879533395535, 1.6689111430470536, 1.67318856716156, 1.6642326581768874, 1.6695473572102988, 1.673689818963772, 1.684270160954173, 1.6890187147187024, 1.667728743902067, 1.6960419794408286, 1.6764797902688748, 1.6563420499243386, 1.6803399411643423, 1.6798015047864217, 1.67709197939896, 1.66402222179785, 1.670051551446682, 1.67614394571723, 1.6680423631900694, 1.7004869420353959, 1.6728915237798923, 1.6883277834915533, 1.663399050875408, 1.6780028110597192, 1.6702052965396788, 1.6723256082069584, 1.6820478875462601, 1.6859100068487771, 1.6689704191393968, 1.6906551616947825, 1.6887701662575327, 1.6770625725025083, 1.6790691178019455, 1.6822899783529885, 1.6704679349573648, 1.6837384351869908, 1.6715363990969774, 1.6840854156308058, 1.6722331541340525, 1.6708321600425533, 1.695307714183156, 1.7095323277682792, 1.6834542431482455, 1.6712761303273642, 1.6718876100167996, 1.679205679311985, 1.6919602068459116, 1.6806447186121127, 1.67268989144302, 1.6840052430222674, 1.6791784385355508, 1.6764489644911231, 1.6670545136056296, 1.6912124622158888, 1.6775751840777513, 1.6754182664359487, 1.6935534593535633, 1.6874400580801614, 1.6859875655755765, 1.6742312297588442, 1.6644683145895236, 1.6917008830279838, 1.6621062145000551, 1.7082609606952202, 1.6810641230606451, 1.6776912066994645, 1.6894404510172403, 1.6793135695341157, 1.6906608517577009, 1.682416459409202, 1.6909316749107548, 1.6936547698044195, 1.6885062107225743, 1.6981729239952275, 1.6751037777923956, 1.684143883426015, 1.678197997372325, 1.700168763718954, 1.6837313291503162, 1.6729748190903082, 1.6793273164004814, 1.6946378015890353, 1.6696258347208908, 1.6803770646816347, 1.668753091881915, 1.6919689789050962, 1.6742007557938738, 1.6829075522539092, 1.6723129109638493, 1.686609585110734, 1.6761351474901525, 1.689560797156357]
Training accuracy: [0.19739020352517286, 0.21462654591488947, 0.23897166228454572, 0.2540656344337326, 0.26244035446489433, 0.26643295354951796, 0.27451553218424385, 0.2752945759080728, 0.2828902522154056, 0.2855195247833285, 0.28931736293699484, 0.2951601908657123, 0.29369948388353295, 0.29808160483007107, 0.2966208978478917, 0.3041191936897458, 0.30441133508618173, 0.3050929983445321, 0.3101567825494206, 0.31317557697925796, 0.31531794721978773, 0.31736293699483886, 0.3202843509591976, 0.32125815561398385, 0.32164767747589834, 0.3246664719057357, 0.3258350374914792, 0.32719836400818, 0.3301197779725387, 0.3311909630928036, 0.3320673872821112, 0.33498880124646996, 0.3354757035738631, 0.3367416496250852, 0.33976044405492256, 0.3382023566072646, 0.34346090174311034, 0.3414159119680592, 0.34394780407050346, 0.3470639789658195, 0.3473561203622553, 0.34940111013730646, 0.35095919758496447, 0.3496932515337423, 0.35417275294575906, 0.35018015386113543, 0.35310156782549423, 0.3547570357386308, 0.3589443957542117, 0.35612036225533156, 0.35991820040899797, 0.3608920050637842, 0.3628396143733567, 0.3632291362352712, 0.3602103418054338, 0.36488460414840784, 0.36576102833771545, 0.3659557892686727, 0.36731911578537346, 0.3704352906806895, 0.3690719641639887, 0.3717012367319116, 0.37004576881877493, 0.37199337812834743, 0.37618073814392833, 0.3765702600058428, 0.37666764047132145, 0.37783620605706497, 0.38095238095238093, 0.3811471418833382, 0.3826078488655176, 0.3823157074690817, 0.3816340442107313, 0.38757425260492745, 0.3872821112084916, 0.38406855584769695, 0.38932710098354273, 0.3876716330704061, 0.3880611549323206, 0.3874768721394488, 0.3889375791216282, 0.3890349595871068, 0.38932710098354273, 0.3925406563443373, 0.39195637355146556, 0.39341708053364494, 0.3951699289122602, 0.39565683123965334, 0.3971175382218327, 0.3973122991527899, 0.3981887233420976, 0.3997468107897556, 0.3992599084623624, 0.4024734638231571, 0.40042847404810594, 0.4014022787028922, 0.4060765410458662, 0.4047132145291655, 0.4038367903398578, 0.4068555847696952, 0.4068555847696952, 0.40782938942448144, 0.4117246080436264, 0.4129905540948486, 0.4112377057162333, 0.40860843314831047, 0.4127957931638913, 0.4101665205959685, 0.4142565001460707, 0.4142565001460707, 0.41484078293894244, 0.41678839224851494, 0.4158145875937287, 0.41795695783425846, 0.4178595773687798, 0.4210731327295745, 0.4217547959879248, 0.41961242574739505, 0.4224364592462752, 0.42487097088324083, 0.42097575226409584, 0.4267211997273347, 0.42467620995228356, 0.4267211997273347, 0.42613691693446293, 0.4251631122796767, 0.4232155029701042, 0.4272081020547278, 0.4293504722952576, 0.42886356996786446, 0.4315902230012659, 0.42798714577855684, 0.43168760346674456, 0.4310059402083942, 0.4326614081215308, 0.43012951601908656, 0.43451163696562467, 0.4335378323108384, 0.4341221151037102, 0.43470639789658194, 0.4333430713798812, 0.43626448534423995, 0.4398675625669491, 0.4354854416204109, 0.4403544648943422, 0.4380173337228552, 0.4407439867562567, 0.4395754211705132, 0.4430811179277437, 0.44210731327295744, 0.4433732593241796, 0.4415230304800857, 0.4447365858408803, 0.44541824909923067, 0.44298373746226505, 0.44298373746226505, 0.4466841951504528, 0.44541824909923067, 0.4488265653909826, 0.44872918492550395, 0.4488265653909826, 0.4472684779433246, 0.4485344239945467, 0.4486318044600253, 0.4473658584088032, 0.4523322621482131, 0.4490213263219398, 0.45418249099230695, 0.4542798714577856, 0.44999513097672605, 0.45350082773395656, 0.45379296913039247, 0.45418249099230695, 0.4601226993865031, 0.4562274807673581, 0.45389034959587105, 0.4562274807673581, 0.45720128542214433, 0.45875937286980234, 0.45700652449118706, 0.4574934268185802, 0.4595384165936313, 0.45934365566267404, 0.4595384165936313, 0.46245983055799006, 0.45807770961145194, 0.4588567533352809, 0.4634336352127763, 0.4601226993865031, 0.46479696172947704, 0.4617781672996397, 0.4645048203330412, 0.46314149381634045, 0.46596552731522056, 0.46275197195442597, 0.4660629077806992, 0.4649917226604343, 0.46752361476287857, 0.46752361476287857, 0.4651864835913916, 0.4678157561593144, 0.46440743986756255, 0.47297692082968157, 0.46898432174505794, 0.4684000389521862, 0.4723926380368098, 0.47015288733080146, 0.4722952575713312, 0.47249001850228844, 0.4725873989677671, 0.47619047619047616, 0.4750219106047327, 0.47356120362255333, 0.4739507254844678, 0.47726166131074105, 0.4741454864154251, 0.47424286688090367, 0.4793066510857922, 0.47599571525951895, 0.4769695199143052, 0.47950141201674945, 0.47920927062031354, 0.4809621189989288, 0.48115687992988604, 0.4824228259811082, 0.4828123478430227, 0.4815464017918006, 0.48144902132632195, 0.4836887720323303, 0.4829097283085013, 0.48057259713701433, 0.48339663063589444, 0.4829097283085013, 0.48651280553121046, 0.48495471808355245, 0.4857337618073814, 0.4854416204109456, 0.48661018599668904, 0.48729184925503943, 0.4835913915668517, 0.48651280553121046, 0.48427305482520205, 0.48846041484078295, 0.4868049469276463, 0.4876813711169539, 0.48777875158243256, 0.4918687311325348, 0.4891420780991333, 0.49128444833966306, 0.4924530139254066, 0.4915765897360989, 0.49167397020157755, 0.4902132632193982, 0.49196611159801346, 0.49011588275391954, 0.49040802415035545, 0.4948875255623722, 0.49167397020157755, 0.49216087252897067, 0.49556918882072254, 0.4945953841659363, 0.4945953841659363, 0.49274515532184243, 0.49362157951115004, 0.4942058623040218, 0.4979063199922096, 0.49897750511247446, 0.49517966695880805, 0.4944006232349791, 0.4972246567338592, 0.4987827441815172, 0.4988801246469958, 0.49547180835524396, 0.4980037004576882, 0.49936702697438895, 0.4972246567338592, 0.49868536371603855, 0.4987827441815172, 0.5000486902327393, 0.50141201674944, 0.4987827441815172, 0.5021910604732691, 0.5016067776803973, 0.5036517674554485, 0.5019962995423118, 0.502483201869705, 0.5007303534910897, 0.5011198753530042, 0.5036517674554485, 0.5042360502483202, 0.5054046158340637, 0.5068653228162431, 0.5055019962995423, 0.5055019962995423, 0.5070600837472004, 0.5059888986269354, 0.50637842048885, 0.5085207907293797, 0.5072548446781575, 0.5052098549031064, 0.5078391274710293, 0.5080338884019866, 0.5058915181614568, 0.5067679423507644, 0.50920245398773, 0.5100788781770377, 0.510273639107995, 0.5119291070211316, 0.5104684000389522, 0.508423410263901, 0.5119291070211316, 0.5103710195734735, 0.5118317265556529, 0.5136819553997468, 0.5141688577271399, 0.5118317265556529, 0.5151426623819262, 0.5119291070211316, 0.5114422046937385, 0.5110526828318239, 0.5139740967961827, 0.5147531405200116, 0.5138767163307041, 0.5160190865712339, 0.5167007498295841, 0.5142662381926185, 0.5149479014509689, 0.5177719349498491, 0.5180640763462849, 0.517285032622456, 0.520401207517772, 0.5173824130879345, 0.5170902716914987, 0.5153374233128835, 0.5174797935534132, 0.5206933489142078, 0.5187457396046353, 0.5192326419320284, 0.518550978673678, 0.5209854903106437, 0.5207907293796864, 0.5183562177427208, 0.5186483591391566, 0.5220566754309086, 0.5223488168273445, 0.5222514363618658, 0.5218619144999513, 0.5226409582237803, 0.5241990456714383, 0.5217645340344726, 0.522446197292823, 0.5236147628785666, 0.5244911870678742, 0.524296426136917, 0.5240042847404811, 0.523517382413088, 0.5276073619631901, 0.5246859479988314, 0.5250754698607459, 0.5238095238095238, 0.5280942642905833, 0.5261466549810108, 0.5275099814977116, 0.5269256987048399, 0.5268283182393612, 0.5278995033596261, 0.5308209173239848, 0.5279968838251047, 0.5291654494108482, 0.5295549712727626, 0.5303340149965917, 0.5295549712727626, 0.5301392540656344, 0.5290680689453695, 0.5308209173239848, 0.5299444931346772, 0.5330606680299932, 0.5289706884798909, 0.5309182977894634, 0.5312104391858993, 0.5327685266335573, 0.5329632875645146, 0.5332554289609505, 0.5337423312883436, 0.533352809426429, 0.5334501898919077, 0.5323790047716428, 0.5326711461680786, 0.5354951796669588, 0.5340344726847794, 0.5370532671146168, 0.5356899405979161, 0.5351056578050443, 0.5342292336157367, 0.5379296913039244, 0.5347161359431298, 0.5342292336157367, 0.535203038270523, 0.5382218327003603, 0.5379296913039244, 0.5392930178206252, 0.5381244522348817, 0.5405589638718473, 0.5367611257181809, 0.5402668224754115, 0.538027071769403, 0.5373454085110527, 0.5405589638718473, 0.5393903982861038, 0.5391956373551465, 0.5397799201480183, 0.5413380075956763, 0.5416301489921121, 0.5418249099230694, 0.5432856169052488, 0.5429934755088129, 0.5393903982861038, 0.5423118122504625, 0.5439672801635992, 0.5439672801635992, 0.5418249099230694, 0.5434803778362061, 0.5441620410945565, 0.5416301489921121, 0.5434803778362061, 0.546109650404129, 0.5428960950433344, 0.5439672801635992, 0.5457201285422144, 0.5456227480767358, 0.5458175090076931, 0.5425065731814198, 0.5444541824909923, 0.5464017918005648, 0.5462070308696075, 0.5474729769208296, 0.5466939331970007, 0.5474729769208296, 0.5460122699386503, 0.5487389229720518, 0.5479598792482228, 0.5475703573863083, 0.5478624987827442, 0.5463044113350862, 0.5498101080923167, 0.5501022494887525, 0.5506865322816243, 0.5491284448339663, 0.5501996299542312, 0.5483494011101373, 0.5498101080923167, 0.5486415425065732, 0.5524393806602396, 0.5496153471613594, 0.5501996299542312, 0.5528289025221541, 0.5513681955399746, 0.5509786736780602, 0.5506865322816243, 0.5540948485733762, 0.5508812932125815, 0.5516603369364106, 0.5509786736780602, 0.5519524783328464, 0.5502970104197098, 0.5524393806602396, 0.5526341415911968, 0.552342000194761, 0.5535105657805044, 0.5530236634531113, 0.5532184243840685, 0.5527315220566754, 0.5524393806602396, 0.5538027071769404, 0.5563345992793846, 0.5560424578829487, 0.5569188820722563, 0.5543869899698121, 0.5549712727626838, 0.555166033693641, 0.5591586327782647, 0.5583795890544356, 0.5565293602103418, 0.5574057843996494, 0.5588664913818288, 0.5563345992793846, 0.5546791313662479, 0.5550686532281625, 0.5585743499853929, 0.5557503164865129, 0.5586717304508716, 0.5600350569675723, 0.5577953062615639, 0.5576979257960853, 0.5576005453306067, 0.5592560132437433, 0.5624695686045379, 0.5600350569675723, 0.5579900671925212, 0.5588664913818288]
Validation accuracy: [0.19470404984423675, 0.21105919003115264, 0.2250778816199377, 0.2468847352024922, 0.25, 0.2562305295950156, 0.2538940809968847, 0.2585669781931464, 0.26479750778816197, 0.26869158878504673, 0.2570093457943925, 0.2632398753894081, 0.27414330218068533, 0.2780373831775701, 0.26947040498442365, 0.2780373831775701, 0.26869158878504673, 0.2718068535825545, 0.278816199376947, 0.27414330218068533, 0.2866043613707165, 0.2819314641744548, 0.2764797507788162, 0.29049844236760125, 0.2850467289719626, 0.2811526479750779, 0.2897196261682243, 0.28582554517133957, 0.279595015576324, 0.2850467289719626, 0.2811526479750779, 0.2803738317757009, 0.2850467289719626, 0.2897196261682243, 0.29127725856697817, 0.2850467289719626, 0.2982866043613707, 0.29127725856697817, 0.2850467289719626, 0.2803738317757009, 0.29439252336448596, 0.2967289719626168, 0.29517133956386293, 0.29049844236760125, 0.2850467289719626, 0.29906542056074764, 0.30062305295950154, 0.2834890965732087, 0.2866043613707165, 0.2967289719626168, 0.2967289719626168, 0.29517133956386293, 0.29595015576323985, 0.29127725856697817, 0.30218068535825543, 0.29361370716510904, 0.29595015576323985, 0.2967289719626168, 0.29205607476635514, 0.3014018691588785, 0.29517133956386293, 0.29439252336448596, 0.2982866043613707, 0.3037383177570093, 0.2998442367601246, 0.2967289719626168, 0.29906542056074764, 0.3037383177570093, 0.29127725856697817, 0.3076323987538941, 0.3014018691588785, 0.308411214953271, 0.3037383177570093, 0.3060747663551402, 0.3076323987538941, 0.3076323987538941, 0.29750778816199375, 0.3099688473520249, 0.3068535825545171, 0.30218068535825543, 0.29906542056074764, 0.3076323987538941, 0.3014018691588785, 0.3052959501557632, 0.308411214953271, 0.3052959501557632, 0.308411214953271, 0.3037383177570093, 0.3068535825545171, 0.3076323987538941, 0.29906542056074764, 0.3076323987538941, 0.3076323987538941, 0.309190031152648, 0.3014018691588785, 0.3076323987538941, 0.30218068535825543, 0.3076323987538941, 0.30218068535825543, 0.3076323987538941, 0.29750778816199375, 0.29595015576323985, 0.3052959501557632, 0.308411214953271, 0.31386292834890966, 0.2967289719626168, 0.31230529595015577, 0.2998442367601246, 0.29906542056074764, 0.29906542056074764, 0.3052959501557632, 0.30218068535825543, 0.3076323987538941, 0.3029595015576324, 0.3068535825545171, 0.3060747663551402, 0.3037383177570093, 0.3146417445482866, 0.3107476635514019, 0.29750778816199375, 0.31853582554517135, 0.3014018691588785, 0.3076323987538941, 0.3130841121495327, 0.308411214953271, 0.3130841121495327, 0.3060747663551402, 0.308411214953271, 0.30218068535825543, 0.3076323987538941, 0.309190031152648, 0.3099688473520249, 0.31542056074766356, 0.3060747663551402, 0.3014018691588785, 0.29517133956386293, 0.29517133956386293, 0.3045171339563863, 0.309190031152648, 0.3060747663551402, 0.3099688473520249, 0.3045171339563863, 0.3037383177570093, 0.3068535825545171, 0.3115264797507788, 0.3076323987538941, 0.3076323987538941, 0.3099688473520249, 0.308411214953271, 0.3068535825545171, 0.31230529595015577, 0.31230529595015577, 0.3014018691588785, 0.3076323987538941, 0.3037383177570093, 0.3014018691588785, 0.3052959501557632, 0.3052959501557632, 0.3068535825545171, 0.3076323987538941, 0.2998442367601246, 0.31386292834890966, 0.3076323987538941, 0.3045171339563863, 0.3052959501557632, 0.3052959501557632, 0.3014018691588785, 0.2967289719626168, 0.308411214953271, 0.31230529595015577, 0.3068535825545171, 0.3037383177570093, 0.3037383177570093, 0.2967289719626168, 0.3014018691588785, 0.3045171339563863, 0.29750778816199375, 0.3076323987538941, 0.3045171339563863, 0.2998442367601246, 0.3037383177570093, 0.29750778816199375, 0.2982866043613707, 0.3014018691588785, 0.2998442367601246, 0.3052959501557632, 0.3052959501557632, 0.3037383177570093, 0.3037383177570093, 0.3060747663551402, 0.2982866043613707, 0.30062305295950154, 0.3068535825545171, 0.3045171339563863, 0.29283489096573206, 0.29439252336448596, 0.3014018691588785, 0.3029595015576324, 0.309190031152648, 0.29517133956386293, 0.30218068535825543, 0.30218068535825543, 0.3037383177570093, 0.30062305295950154, 0.2998442367601246, 0.29595015576323985, 0.3014018691588785, 0.30218068535825543, 0.2998442367601246, 0.308411214953271, 0.2967289719626168, 0.29517133956386293, 0.29595015576323985, 0.2967289719626168, 0.3014018691588785, 0.29906542056074764, 0.2967289719626168, 0.2998442367601246, 0.29283489096573206, 0.2998442367601246, 0.3037383177570093, 0.3037383177570093, 0.30062305295950154, 0.29439252336448596, 0.29750778816199375, 0.29361370716510904, 0.29361370716510904, 0.2982866043613707, 0.2967289719626168, 0.29361370716510904, 0.29750778816199375, 0.29517133956386293, 0.29283489096573206, 0.29283489096573206, 0.29906542056074764, 0.2967289719626168, 0.29595015576323985, 0.30218068535825543, 0.29595015576323985, 0.29283489096573206, 0.2982866043613707, 0.29595015576323985, 0.29517133956386293, 0.30062305295950154, 0.29595015576323985, 0.29205607476635514, 0.29439252336448596, 0.3014018691588785, 0.29906542056074764, 0.28894080996884736, 0.2998442367601246, 0.30218068535825543, 0.30062305295950154, 0.29906542056074764, 0.2897196261682243, 0.2967289719626168, 0.2998442367601246, 0.2967289719626168, 0.2998442367601246, 0.2967289719626168, 0.29361370716510904, 0.29595015576323985, 0.2982866043613707, 0.29750778816199375, 0.30062305295950154, 0.30218068535825543, 0.30062305295950154, 0.2998442367601246, 0.29906542056074764, 0.2998442367601246, 0.30062305295950154, 0.29361370716510904, 0.29439252336448596, 0.29750778816199375, 0.29517133956386293, 0.28894080996884736, 0.29205607476635514, 0.29283489096573206, 0.2967289719626168, 0.29750778816199375, 0.29283489096573206, 0.2982866043613707, 0.29595015576323985, 0.2967289719626168, 0.29127725856697817, 0.29517133956386293, 0.29750778816199375, 0.29595015576323985, 0.3037383177570093, 0.2998442367601246, 0.29906542056074764, 0.2982866043613707, 0.2967289719626168, 0.28894080996884736, 0.29439252336448596, 0.3037383177570093, 0.29205607476635514, 0.29906542056074764, 0.2967289719626168, 0.29439252336448596, 0.29361370716510904, 0.2982866043613707, 0.29049844236760125, 0.2982866043613707, 0.2982866043613707, 0.29049844236760125, 0.2982866043613707, 0.29750778816199375, 0.29517133956386293, 0.29361370716510904, 0.2967289719626168, 0.2967289719626168, 0.30062305295950154, 0.29283489096573206, 0.29517133956386293, 0.29283489096573206, 0.29517133956386293, 0.29361370716510904, 0.29750778816199375, 0.2967289719626168, 0.30062305295950154, 0.29595015576323985, 0.30062305295950154, 0.29361370716510904, 0.2967289719626168, 0.29906542056074764, 0.29595015576323985, 0.29595015576323985, 0.29517133956386293, 0.29127725856697817, 0.3029595015576324, 0.2967289719626168, 0.29205607476635514, 0.30062305295950154, 0.2967289719626168, 0.29750778816199375, 0.29517133956386293, 0.29750778816199375, 0.29205607476635514, 0.29283489096573206, 0.29595015576323985, 0.2967289719626168, 0.29906542056074764, 0.29205607476635514, 0.2982866043613707, 0.3052959501557632, 0.2967289719626168, 0.29049844236760125, 0.29127725856697817, 0.29750778816199375, 0.29595015576323985, 0.2982866043613707, 0.29439252336448596, 0.29283489096573206, 0.29049844236760125, 0.30062305295950154, 0.29283489096573206, 0.29595015576323985, 0.2967289719626168, 0.29361370716510904, 0.3014018691588785, 0.29439252336448596, 0.29595015576323985, 0.2998442367601246, 0.29361370716510904, 0.29361370716510904, 0.29439252336448596, 0.29439252336448596, 0.2897196261682243, 0.29906542056074764, 0.29361370716510904, 0.29517133956386293, 0.2998442367601246, 0.2982866043613707, 0.29283489096573206, 0.29439252336448596, 0.29595015576323985, 0.29205607476635514, 0.29439252336448596, 0.29283489096573206, 0.29283489096573206, 0.29205607476635514, 0.29750778816199375, 0.29127725856697817, 0.29283489096573206, 0.29205607476635514, 0.29439252336448596, 0.29205607476635514, 0.28894080996884736, 0.29205607476635514, 0.29439252336448596, 0.29595015576323985, 0.29049844236760125, 0.2897196261682243, 0.2827102803738318, 0.2897196261682243, 0.2866043613707165, 0.29517133956386293, 0.29439252336448596, 0.29517133956386293, 0.29049844236760125, 0.29127725856697817, 0.29517133956386293, 0.29205607476635514, 0.28894080996884736, 0.29283489096573206, 0.29127725856697817, 0.29127725856697817, 0.29049844236760125, 0.29205607476635514, 0.28894080996884736, 0.29049844236760125, 0.29595015576323985, 0.29205607476635514, 0.29361370716510904, 0.29517133956386293, 0.29205607476635514, 0.29127725856697817, 0.28738317757009346, 0.29439252336448596, 0.29127725856697817, 0.29283489096573206, 0.2982866043613707, 0.29439252336448596, 0.29283489096573206, 0.29205607476635514, 0.29361370716510904, 0.28894080996884736, 0.2897196261682243, 0.2897196261682243, 0.2850467289719626, 0.28894080996884736, 0.29361370716510904, 0.2897196261682243, 0.28894080996884736, 0.29361370716510904, 0.2834890965732087, 0.2866043613707165, 0.2967289719626168, 0.28582554517133957, 0.29127725856697817, 0.29439252336448596, 0.28582554517133957, 0.29049844236760125, 0.2897196261682243, 0.2834890965732087, 0.29127725856697817, 0.2842679127725857, 0.2881619937694704, 0.2982866043613707, 0.28894080996884736, 0.29439252336448596, 0.28738317757009346, 0.28582554517133957, 0.28894080996884736, 0.29205607476635514, 0.2897196261682243, 0.28894080996884736, 0.29049844236760125, 0.29127725856697817, 0.2866043613707165, 0.29361370716510904, 0.28738317757009346, 0.2897196261682243, 0.28738317757009346, 0.29517133956386293, 0.28738317757009346, 0.28582554517133957, 0.29127725856697817, 0.29205607476635514, 0.2881619937694704, 0.28894080996884736, 0.29361370716510904, 0.29205607476635514, 0.2881619937694704, 0.2881619937694704, 0.2881619937694704, 0.28894080996884736, 0.29205607476635514, 0.2850467289719626, 0.29283489096573206, 0.29127725856697817, 0.2866043613707165, 0.29049844236760125, 0.28894080996884736, 0.2897196261682243, 0.28582554517133957, 0.2866043613707165, 0.2897196261682243, 0.2819314641744548, 0.2842679127725857, 0.29361370716510904, 0.28894080996884736, 0.2834890965732087, 0.2897196261682243, 0.28582554517133957, 0.2866043613707165, 0.2897196261682243, 0.29049844236760125, 0.28894080996884736]
Accuracy plot saved at '13B_Llama_FULL_SimpleLinearHead_1710654346.614777/accuracy_13B_Llama_FULL_SimpleLinearHead_1710654346.614777.png'
Loss plot saved at '13B_Llama_FULL_SimpleLinearHead_1710654346.614777/loss_13B_Llama_FULL_SimpleLinearHead_1710654346.614777.png'
Checkpoint saved at '13B_Llama_FULL_SimpleLinearHead_1710654346.614777/checkpoint_13B_Llama_FULL_SimpleLinearHead_1710654346.614777.pth'
Best checkpoint saved at '13B_Llama_FULL_SimpleLinearHead_1710654346.614777/best_checkpoint_13B_Llama_FULL_SimpleLinearHead_1710654346.614777.pth'
Output logfile saved at 13B_Llama_FULL_SimpleLinearHead_1710654346.614777/output_log_13B_Llama_FULL_SimpleLinearHead_1710654346.614777.txt
