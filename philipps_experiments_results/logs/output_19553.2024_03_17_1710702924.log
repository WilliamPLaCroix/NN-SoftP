
=============
== PyTorch ==
=============

NVIDIA Release 24.01 (build 80741402)
PyTorch Version 2.2.0a0+81ea7a4

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

NOTE: CUDA Forward Compatibility mode ENABLED.
  Using CUDA 12.3 driver version 545.23.08 with kernel driver version 525.85.12.
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

Language Model has hidden_size: 4096
freezing Model... (AutoModel)
Running on device: cuda
Epoch [1/333] took 95.63058495521545s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.8896279669253626, train accuracy: 0.5418249099230694
Val mean loss: 0.7292609781753726, val accuracy: 0.5700934579439252

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3366 			 4497 			 1592
6855 			 5772 			 3972
11 			 0 			 0
25 			 0 			 0
10 			 0 			 0
2 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
216 			 616 			 140
1068 			 668 			 592
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8157539840; Memory allocated: 3819272704
Epoch [2/333] took 96.2541618347168s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6962316660123451, train accuracy: 0.591781088713604
Val mean loss: 0.6854266800531527, val accuracy: 0.5887850467289719

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2167 			 4497 			 1236
8102 			 5772 			 4841
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
342 			 616 			 215
942 			 668 			 541
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8672884736; Memory allocated: 3817439232
Epoch [3/333] took 96.37227582931519s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6748957743525876, train accuracy: 0.6033693641055604
Val mean loss: 0.6751408547889896, val accuracy: 0.5942367601246106

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
2588 			 4497 			 1506
7681 			 5772 			 4690
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
399 			 616 			 247
885 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8672884736; Memory allocated: 3891791872
Epoch [4/333] took 96.39178037643433s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6642837240317158, train accuracy: 0.6110624208783718
Val mean loss: 0.6682333451945607, val accuracy: 0.5973520249221184

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3011 			 4497 			 1757
7258 			 5772 			 4518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
357 			 616 			 228
927 			 668 			 539
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3846636544
Epoch [5/333] took 96.38324236869812s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6592237732120764, train accuracy: 0.614665498101081
Val mean loss: 0.675533313576768, val accuracy: 0.5989096573208723

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3040 			 4497 			 1790
7229 			 5772 			 4522
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
343 			 616 			 222
941 			 668 			 547
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3845293056
Epoch [6/333] took 96.65539264678955s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6554616931071534, train accuracy: 0.612815269256987
Val mean loss: 0.66241596966255, val accuracy: 0.6051401869158879

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3219 			 4497 			 1870
7050 			 5772 			 4423
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
325 			 616 			 217
959 			 668 			 560
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3808919552
Epoch [7/333] took 96.67420792579651s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.652318934970927, train accuracy: 0.6229428376667641
Val mean loss: 0.6580311597847357, val accuracy: 0.618380062305296

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3131 			 4497 			 1878
7138 			 5772 			 4519
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 616 			 310
790 			 668 			 484
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3845456896
Epoch [8/333] took 96.71640181541443s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6491627509348861, train accuracy: 0.6254747297692083
Val mean loss: 0.6544074139943937, val accuracy: 0.6160436137071651

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3369 			 4497 			 2010
6900 			 5772 			 4413
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
397 			 616 			 260
887 			 668 			 531
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3845456896
Epoch [9/333] took 96.46260976791382s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6474338337268414, train accuracy: 0.6303437530431395
Val mean loss: 0.6570606769585028, val accuracy: 0.6137071651090342

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3401 			 4497 			 2051
6868 			 5772 			 4422
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 616 			 244
916 			 668 			 544
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3821699072
Epoch [10/333] took 96.64018440246582s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6449193179236022, train accuracy: 0.6299542311812251
Val mean loss: 0.648286487998032, val accuracy: 0.6152647975077882

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3283 			 4497 			 1990
6986 			 5772 			 4479
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
530 			 616 			 326
754 			 668 			 464
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3846505472
Epoch [11/333] took 96.42173457145691s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6432810871400566, train accuracy: 0.6345311130587205
Val mean loss: 0.6456692989279584, val accuracy: 0.6269470404984424

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3420 			 4497 			 2082
6849 			 5772 			 4434
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
417 			 616 			 277
867 			 668 			 528
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8772314112; Memory allocated: 3900509184
Epoch [12/333] took 96.73706150054932s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6414814819799406, train accuracy: 0.6367708637647288
Val mean loss: 0.6499536924245881, val accuracy: 0.6261682242990654

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3455 			 4497 			 2111
6814 			 5772 			 4428
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
430 			 616 			 283
854 			 668 			 521
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3852502016
Epoch [13/333] took 96.20600914955139s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6405059628397505, train accuracy: 0.6402765605219592
Val mean loss: 0.6477396982472118, val accuracy: 0.6339563862928349

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3395 			 4497 			 2099
6874 			 5772 			 4476
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
416 			 616 			 281
868 			 668 			 533
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3804659712
Epoch [14/333] took 96.57265067100525s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6383335335975124, train accuracy: 0.6382315707469082
Val mean loss: 0.6417042932859282, val accuracy: 0.6277258566978193

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3384 			 4497 			 2083
6885 			 5772 			 4471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 616 			 300
822 			 668 			 506
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845784576
Epoch [15/333] took 96.67266845703125s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6367238372842842, train accuracy: 0.6460220079851982
Val mean loss: 0.6538909201214953, val accuracy: 0.6362928348909658

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3498 			 4497 			 2180
6771 			 5772 			 4454
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
465 			 616 			 307
819 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3815309312
Epoch [16/333] took 96.23345947265625s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6356662656659278, train accuracy: 0.6448534423994546
Val mean loss: 0.6442058130008418, val accuracy: 0.6246105919003115

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3398 			 4497 			 2124
6871 			 5772 			 4498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
468 			 616 			 301
816 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845620736
Epoch [17/333] took 96.21410512924194s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6343556372361763, train accuracy: 0.6444639205375402
Val mean loss: 0.6460336781129604, val accuracy: 0.6199376947040498

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3514 			 4497 			 2180
6755 			 5772 			 4438
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
368 			 616 			 248
916 			 668 			 548
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3891496960
Epoch [18/333] took 95.97551727294922s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6322542259997668, train accuracy: 0.6493329438114714
Val mean loss: 0.6526132211452578, val accuracy: 0.6269470404984424

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3504 			 4497 			 2200
6765 			 5772 			 4468
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
399 			 616 			 268
885 			 668 			 537
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3813179392
Epoch [19/333] took 96.6094081401825s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6317189944867404, train accuracy: 0.6469958126399844
Val mean loss: 0.6407857290128383, val accuracy: 0.6339563862928349

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3406 			 4497 			 2139
6863 			 5772 			 4505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
436 			 616 			 291
848 			 668 			 523
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3891496960
Epoch [20/333] took 96.40915393829346s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6307999201095735, train accuracy: 0.6487486610185996
Val mean loss: 0.6416772574913211, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3490 			 4497 			 2190
6779 			 5772 			 4472
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 616 			 310
822 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845948416
Epoch [21/333] took 96.28285527229309s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6303795340276581, train accuracy: 0.6504041289317363
Val mean loss: 0.6344537291584945, val accuracy: 0.6362928348909658

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3531 			 4497 			 2219
6738 			 5772 			 4460
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
521 			 616 			 335
763 			 668 			 482
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3854566400
Epoch [22/333] took 96.09956979751587s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.629234841679487, train accuracy: 0.6515726945174798
Val mean loss: 0.6360365944664653, val accuracy: 0.6308411214953271

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3475 			 4497 			 2197
6794 			 5772 			 4494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 616 			 314
798 			 668 			 496
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3808919552
Epoch [23/333] took 96.37954950332642s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6276682028517916, train accuracy: 0.6523517382413088
Val mean loss: 0.6379930885826669, val accuracy: 0.6378504672897196

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3579 			 4497 			 2253
6690 			 5772 			 4446
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
533 			 616 			 342
751 			 668 			 477
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3891988480
Epoch [24/333] took 96.24232387542725s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6270042223351024, train accuracy: 0.6547862498782744
Val mean loss: 0.6384831027286809, val accuracy: 0.6378504672897196

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3522 			 4497 			 2237
6747 			 5772 			 4487
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 616 			 313
809 			 668 			 506
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845784576
Epoch [25/333] took 96.6069004535675s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6257777408090336, train accuracy: 0.653325542896095
Val mean loss: 0.6359932640703713, val accuracy: 0.631619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3497 			 4497 			 2217
6772 			 5772 			 4492
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
519 			 616 			 331
765 			 668 			 480
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3891857408
Epoch [26/333] took 96.40151906013489s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6250432341640983, train accuracy: 0.6573181419807187
Val mean loss: 0.6498873655388995, val accuracy: 0.6401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3594 			 4497 			 2286
6675 			 5772 			 4464
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 616 			 312
814 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3823828992
Epoch [27/333] took 96.36410737037659s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6248431474991677, train accuracy: 0.655662674067582
Val mean loss: 0.6414392808588539, val accuracy: 0.6347352024922118

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3619 			 4497 			 2290
6650 			 5772 			 4443
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
421 			 616 			 284
863 			 668 			 531
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3847259136
Epoch [28/333] took 96.41149473190308s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6243266599757649, train accuracy: 0.6578050443081118
Val mean loss: 0.6254282135788988, val accuracy: 0.631619937694704

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3431 			 4497 			 2207
6838 			 5772 			 4548
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
605 			 616 			 374
679 			 668 			 437
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3813179392
Epoch [29/333] took 96.40619492530823s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6243474187323609, train accuracy: 0.657512902911676
Val mean loss: 0.6337778103060838, val accuracy: 0.6409657320872274

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3726 			 4497 			 2353
6543 			 5772 			 4399
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
421 			 616 			 288
863 			 668 			 535
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3819569152
Epoch [30/333] took 96.48249340057373s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6219226495127812, train accuracy: 0.6617002629272568
Val mean loss: 0.6454988223750416, val accuracy: 0.6238317757009346

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3621 			 4497 			 2322
6648 			 5772 			 4473
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
339 			 616 			 236
945 			 668 			 565
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3847259136
Epoch [31/333] took 96.28136277198792s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6224378230415772, train accuracy: 0.6566364787223683
Val mean loss: 0.6351081627171214, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3521 			 4497 			 2246
6748 			 5772 			 4497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
466 			 616 			 312
818 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3856630784
Epoch [32/333] took 96.74013996124268s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6216605616692813, train accuracy: 0.6598500340831629
Val mean loss: 0.6425668190165263, val accuracy: 0.6370716510903427

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3532 			 4497 			 2268
6737 			 5772 			 4508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
458 			 616 			 304
826 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3806789632
Epoch [33/333] took 96.58484387397766s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6202958037734403, train accuracy: 0.6625766871165644
Val mean loss: 0.6374448334298483, val accuracy: 0.6339563862928349

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3634 			 4497 			 2333
6635 			 5772 			 4471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
416 			 616 			 281
868 			 668 			 533
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845850112
Epoch [34/333] took 96.6483907699585s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6200654800992889, train accuracy: 0.6630635894439575
Val mean loss: 0.6322828182360021, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3523 			 4497 			 2280
6746 			 5772 			 4529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
542 			 616 			 350
742 			 668 			 476
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3823828992
Epoch [35/333] took 96.12894034385681s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6193730416141938, train accuracy: 0.6631609699094362
Val mean loss: 0.6334642535302697, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3602 			 4497 			 2320
6667 			 5772 			 4490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
508 			 616 			 335
776 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3850437632
Epoch [36/333] took 96.14830088615417s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6190078743150301, train accuracy: 0.6635504917713506
Val mean loss: 0.636233909827907, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3558 			 4497 			 2300
6711 			 5772 			 4514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 324
800 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3891628032
Epoch [37/333] took 96.0742461681366s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6186743589390847, train accuracy: 0.6636478722368293
Val mean loss: 0.6362576760896822, val accuracy: 0.6409657320872274

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3569 			 4497 			 2306
6700 			 5772 			 4509
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
511 			 616 			 333
773 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3806789632
Epoch [38/333] took 95.91565799713135s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6179213522936324, train accuracy: 0.6656928620118804
Val mean loss: 0.6323244542610355, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3686 			 4497 			 2375
6583 			 5772 			 4461
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
440 			 616 			 301
844 			 668 			 529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3846734848
Epoch [39/333] took 96.41522312164307s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6165047005700917, train accuracy: 0.6633557308403935
Val mean loss: 0.6367943693951863, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3548 			 4497 			 2294
6721 			 5772 			 4518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
527 			 616 			 348
757 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845850112
Epoch [40/333] took 96.21101903915405s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6167352988712513, train accuracy: 0.6647190573570941
Val mean loss: 0.6409069546839086, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3614 			 4497 			 2334
6655 			 5772 			 4492
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 616 			 318
813 			 668 			 515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3823828992
Epoch [41/333] took 96.4068832397461s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6162467278609766, train accuracy: 0.6667640471321453
Val mean loss: 0.6338600327328938, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3621 			 4497 			 2348
6648 			 5772 			 4499
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
526 			 616 			 346
758 			 668 			 488
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3817439232
Epoch [42/333] took 96.48009467124939s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.615525525399829, train accuracy: 0.6667640471321453
Val mean loss: 0.6347505566550464, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3661 			 4497 			 2368
6608 			 5772 			 4479
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
518 			 616 			 338
766 			 668 			 488
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845620736
Epoch [43/333] took 96.64608240127563s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6147448654486755, train accuracy: 0.6677378517869316
Val mean loss: 0.6378049886808163, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3637 			 4497 			 2361
6632 			 5772 			 4496
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 616 			 330
794 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3847259136
Epoch [44/333] took 96.17087817192078s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6141341265488265, train accuracy: 0.6698802220274613
Val mean loss: 0.6348782268966117, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3533 			 4497 			 2320
6736 			 5772 			 4559
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
555 			 616 			 361
729 			 668 			 474
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845456896
Epoch [45/333] took 96.18756604194641s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6141978947915764, train accuracy: 0.6672509494595384
Val mean loss: 0.6391310793597523, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3712 			 4497 			 2396
6557 			 5772 			 4456
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
454 			 616 			 310
830 			 668 			 524
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845850112
Epoch [46/333] took 96.36365509033203s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6134659089960414, train accuracy: 0.671243548544162
Val mean loss: 0.6325001164180476, val accuracy: 0.6596573208722741

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3631 			 4497 			 2376
6638 			 5772 			 4517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 616 			 337
789 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3854566400
Epoch [47/333] took 96.758216381073s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6127649017397859, train accuracy: 0.6703671243548545
Val mean loss: 0.6383956670761108, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3796 			 4497 			 2454
6473 			 5772 			 4430
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
418 			 616 			 290
866 			 668 			 540
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3893560320
Epoch [48/333] took 96.56557369232178s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6130112009442112, train accuracy: 0.6710487876132047
Val mean loss: 0.644006066206025, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3627 			 4497 			 2373
6642 			 5772 			 4518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 616 			 326
804 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3845653504
Epoch [49/333] took 96.01250171661377s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6116277853090815, train accuracy: 0.6729963969227772
Val mean loss: 0.6331932021350395, val accuracy: 0.6401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3623 			 4497 			 2381
6646 			 5772 			 4530
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
408 			 616 			 281
876 			 668 			 541
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 8806392832; Memory allocated: 3891955712
Epoch [50/333] took 96.4710144996643s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6116512394582743, train accuracy: 0.6728990164572987
Val mean loss: 0.6335304234086013, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3684 			 4497 			 2411
6585 			 5772 			 4499
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
410 			 616 			 284
874 			 668 			 542
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846374400
Epoch [51/333] took 96.66199493408203s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6117000144404414, train accuracy: 0.6709514071477262
Val mean loss: 0.6295149936908628, val accuracy: 0.6534267912772586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3542 			 4497 			 2330
6727 			 5772 			 4560
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
507 			 616 			 339
777 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891988480
Epoch [52/333] took 96.91459369659424s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6102434135857401, train accuracy: 0.6748466257668712
Val mean loss: 0.6373737309037185, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3640 			 4497 			 2399
6629 			 5772 			 4531
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
549 			 616 			 358
735 			 668 			 477
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3808919552
Epoch [53/333] took 96.32115054130554s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6102623901448888, train accuracy: 0.6729963969227772
Val mean loss: 0.6360882302609886, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3667 			 4497 			 2403
6602 			 5772 			 4508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
468 			 616 			 319
816 			 668 			 519
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846636544
Epoch [54/333] took 96.34967684745789s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6089921904687198, train accuracy: 0.6769889960074009
Val mean loss: 0.6327575794080409, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3622 			 4497 			 2401
6647 			 5772 			 4551
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
522 			 616 			 344
762 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [55/333] took 96.39219760894775s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6095958514562648, train accuracy: 0.6761125718180933
Val mean loss: 0.6272017359733582, val accuracy: 0.6573208722741433

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3633 			 4497 			 2402
6636 			 5772 			 4541
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
518 			 616 			 347
766 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3804659712
Epoch [56/333] took 97.03635883331299s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6091209327877496, train accuracy: 0.6749440062323497
Val mean loss: 0.6403641976961275, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3695 			 4497 			 2427
6574 			 5772 			 4504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
437 			 616 			 299
847 			 668 			 530
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845456896
Epoch [57/333] took 96.61244082450867s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.60870777799333, train accuracy: 0.6765994741454864
Val mean loss: 0.6301131081290361, val accuracy: 0.6394080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3698 			 4497 			 2437
6571 			 5772 			 4511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
405 			 616 			 279
879 			 668 			 542
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [58/333] took 97.01946544647217s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6083999773794988, train accuracy: 0.6760151913526147
Val mean loss: 0.6294302838604625, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3578 			 4497 			 2374
6691 			 5772 			 4568
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
532 			 616 			 352
752 			 668 			 488
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892249600
Epoch [59/333] took 96.29907250404358s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.607466679217288, train accuracy: 0.6750413866978284
Val mean loss: 0.6343370865030986, val accuracy: 0.6596573208722741

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3716 			 4497 			 2438
6553 			 5772 			 4494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 336
791 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [60/333] took 96.39455890655518s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6078588106550532, train accuracy: 0.6746518648359139
Val mean loss: 0.6345750311525856, val accuracy: 0.6580996884735203

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3696 			 4497 			 2426
6573 			 5772 			 4502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
511 			 616 			 344
773 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3802529792
Epoch [61/333] took 96.3407723903656s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6066438149997379, train accuracy: 0.6772811374038368
Val mean loss: 0.6337572234432872, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3667 			 4497 			 2425
6602 			 5772 			 4530
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 616 			 325
799 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3856630784
Epoch [62/333] took 96.28402757644653s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6062223712603251, train accuracy: 0.679033985782452
Val mean loss: 0.6303940240929766, val accuracy: 0.6588785046728972

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3675 			 4497 			 2438
6594 			 5772 			 4535
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 331
800 			 668 			 515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [63/333] took 96.9815320968628s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.605973530038495, train accuracy: 0.6760151913526147
Val mean loss: 0.625094935661409, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3672 			 4497 			 2421
6597 			 5772 			 4521
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 321
800 			 668 			 505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3800399872
Epoch [64/333] took 96.50301218032837s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6064456326196498, train accuracy: 0.6784497029895803
Val mean loss: 0.6404396019330839, val accuracy: 0.6573208722741433

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3709 			 4497 			 2452
6560 			 5772 			 4515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 616 			 326
808 			 668 			 518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846538240
Epoch [65/333] took 96.3509566783905s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6054343394586973, train accuracy: 0.679033985782452
Val mean loss: 0.6248959637269741, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3711 			 4497 			 2456
6558 			 5772 			 4517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
496 			 616 			 330
788 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [66/333] took 96.82189011573792s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6045660306917173, train accuracy: 0.6771837569383582
Val mean loss: 0.6365967901741586, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3636 			 4497 			 2409
6633 			 5772 			 4545
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 616 			 313
817 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892119552
Epoch [67/333] took 96.68215799331665s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6041517618846299, train accuracy: 0.679326127178888
Val mean loss: 0.6285766341337343, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3636 			 4497 			 2420
6633 			 5772 			 4556
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
520 			 616 			 346
764 			 668 			 494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [68/333] took 96.33119368553162s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6038299669914899, train accuracy: 0.6784497029895803
Val mean loss: 0.6269950110737871, val accuracy: 0.6565420560747663

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3743 			 4497 			 2469
6526 			 5772 			 4498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
529 			 616 			 352
755 			 668 			 491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [69/333] took 96.85885453224182s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6044695345783531, train accuracy: 0.6808842146265459
Val mean loss: 0.6278562487625494, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3738 			 4497 			 2479
6531 			 5772 			 4513
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
514 			 616 			 343
770 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [70/333] took 96.48728227615356s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6039686124087122, train accuracy: 0.6815658778848963
Val mean loss: 0.6331825416262556, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3713 			 4497 			 2470
6556 			 5772 			 4529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
536 			 616 			 355
748 			 668 			 487
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3926068224
Epoch [71/333] took 96.8854124546051s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6032567737258483, train accuracy: 0.6802999318336742
Val mean loss: 0.6401496078909897, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3714 			 4497 			 2464
6555 			 5772 			 4522
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
543 			 616 			 356
741 			 668 			 481
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [72/333] took 96.53856348991394s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6034435447874099, train accuracy: 0.6816632583503749
Val mean loss: 0.6338456273078918, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3790 			 4497 			 2509
6479 			 5772 			 4491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 616 			 322
808 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3893560320
Epoch [73/333] took 96.57858872413635s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6027043089502697, train accuracy: 0.683221345798033
Val mean loss: 0.6305901800713888, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3632 			 4497 			 2438
6637 			 5772 			 4578
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
515 			 616 			 342
769 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [74/333] took 95.97772026062012s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6021423946102832, train accuracy: 0.6788392248514948
Val mean loss: 0.6365115395406398, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3701 			 4497 			 2450
6568 			 5772 			 4521
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
464 			 616 			 314
820 			 668 			 518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [75/333] took 96.38723707199097s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6014486327535267, train accuracy: 0.6811763560229818
Val mean loss: 0.6269357756870549, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3689 			 4497 			 2456
6580 			 5772 			 4539
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
556 			 616 			 362
728 			 668 			 474
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [76/333] took 96.16044759750366s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6012554289395935, train accuracy: 0.6838056285909047
Val mean loss: 0.6326992264608058, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3800 			 4497 			 2525
6469 			 5772 			 4497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
461 			 616 			 311
823 			 668 			 518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [77/333] took 96.39394760131836s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.60051556493263, train accuracy: 0.6808842146265459
Val mean loss: 0.6296213421879745, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3676 			 4497 			 2448
6593 			 5772 			 4544
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
534 			 616 			 352
750 			 668 			 486
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3804659712
Epoch [78/333] took 96.57803511619568s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6006772807825391, train accuracy: 0.6835134871944688
Val mean loss: 0.6358457672886733, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3771 			 4497 			 2509
6498 			 5772 			 4510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
508 			 616 			 338
776 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891267584
Epoch [79/333] took 96.52383255958557s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6007241430312302, train accuracy: 0.6859479988314344
Val mean loss: 0.6315147934890375, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3718 			 4497 			 2495
6551 			 5772 			 4549
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
454 			 616 			 306
830 			 668 			 520
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [80/333] took 97.12920689582825s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.6003963105218061, train accuracy: 0.6854610965040413
Val mean loss: 0.633893155470127, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3673 			 4497 			 2470
6596 			 5772 			 4569
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
520 			 616 			 345
764 			 668 			 493
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892152320
Epoch [81/333] took 96.22562599182129s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5996049957297672, train accuracy: 0.6854610965040413
Val mean loss: 0.6325977168432096, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3693 			 4497 			 2480
6576 			 5772 			 4559
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
523 			 616 			 346
761 			 668 			 491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [82/333] took 96.26685762405396s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5995390716000139, train accuracy: 0.6835134871944688
Val mean loss: 0.6293278234760936, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3753 			 4497 			 2500
6516 			 5772 			 4519
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 616 			 327
799 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891857408
Epoch [83/333] took 96.64135837554932s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5999151296519045, train accuracy: 0.6841951504528192
Val mean loss: 0.6339576753174386, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3678 			 4497 			 2466
6591 			 5772 			 4560
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
441 			 616 			 305
843 			 668 			 532
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [84/333] took 96.6475338935852s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5980061913762137, train accuracy: 0.6877008472100496
Val mean loss: 0.6308788729877006, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3760 			 4497 			 2525
6509 			 5772 			 4537
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
441 			 616 			 302
843 			 668 			 529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [85/333] took 96.53950071334839s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5978898397672956, train accuracy: 0.6834161067289901
Val mean loss: 0.6318067006948518, val accuracy: 0.6596573208722741

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3724 			 4497 			 2485
6545 			 5772 			 4533
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
533 			 616 			 356
751 			 668 			 491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [86/333] took 96.87000393867493s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.597953536892977, train accuracy: 0.6873113253481352
Val mean loss: 0.6266951335639488, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3754 			 4497 			 2520
6515 			 5772 			 4538
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 616 			 327
799 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [87/333] took 96.83965110778809s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5974663717910137, train accuracy: 0.6856558574349986
Val mean loss: 0.6308806422280102, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3691 			 4497 			 2480
6578 			 5772 			 4561
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
482 			 616 			 326
802 			 668 			 512
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [88/333] took 96.52715039253235s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5980327675275714, train accuracy: 0.6856558574349986
Val mean loss: 0.6338740325555569, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3703 			 4497 			 2486
6566 			 5772 			 4555
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
558 			 616 			 360
726 			 668 			 470
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846538240
Epoch [89/333] took 96.28273820877075s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5973458723672825, train accuracy: 0.6867270425552634
Val mean loss: 0.6373149912531783, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3738 			 4497 			 2509
6531 			 5772 			 4543
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 616 			 319
811 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [90/333] took 96.2022819519043s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5963774033796008, train accuracy: 0.6869218034862207
Val mean loss: 0.6259383064944569, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3770 			 4497 			 2526
6499 			 5772 			 4528
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
468 			 616 			 316
816 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [91/333] took 96.3438777923584s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5962840622273561, train accuracy: 0.6881877495374428
Val mean loss: 0.6262404787831191, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3681 			 4497 			 2488
6588 			 5772 			 4579
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 616 			 325
799 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [92/333] took 96.24694085121155s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5955961852615868, train accuracy: 0.6870191839516993
Val mean loss: 0.6256252112911969, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3727 			 4497 			 2505
6542 			 5772 			 4550
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 616 			 321
809 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3800399872
Epoch [93/333] took 96.29813003540039s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5952671169306258, train accuracy: 0.6883825104684
Val mean loss: 0.6358029478933753, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3753 			 4497 			 2525
6516 			 5772 			 4544
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 326
800 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3856630784
Epoch [94/333] took 96.12981820106506s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5956918734627721, train accuracy: 0.6885772713993573
Val mean loss: 0.6349942829550766, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3757 			 4497 			 2528
6512 			 5772 			 4543
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
447 			 616 			 307
837 			 668 			 528
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891857408
Epoch [95/333] took 96.74131155014038s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5956644822503919, train accuracy: 0.6876034667445711
Val mean loss: 0.628498243849452, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3721 			 4497 			 2505
6548 			 5772 			 4556
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
442 			 616 			 301
842 			 668 			 527
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3815309312
Epoch [96/333] took 96.38079500198364s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5950242878863373, train accuracy: 0.690232739312494
Val mean loss: 0.640109071644341, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3726 			 4497 			 2521
6543 			 5772 			 4567
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
446 			 616 			 308
838 			 668 			 530
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3890414592
Epoch [97/333] took 96.79048109054565s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5944301440522678, train accuracy: 0.6925698704839809
Val mean loss: 0.6363113406227856, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3764 			 4497 			 2552
6505 			 5772 			 4560
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 616 			 318
808 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3804659712
Epoch [98/333] took 96.81917643547058s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5940828005844188, train accuracy: 0.6895510760541436
Val mean loss: 0.6274451591619631, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3685 			 4497 			 2497
6584 			 5772 			 4584
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
500 			 616 			 333
784 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [99/333] took 96.34126687049866s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5930492745195965, train accuracy: 0.6894536955886649
Val mean loss: 0.6317560992589811, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3750 			 4497 			 2529
6519 			 5772 			 4551
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
460 			 616 			 312
824 			 668 			 520
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [100/333] took 96.55285620689392s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5942864612069828, train accuracy: 0.6895510760541436
Val mean loss: 0.627086134218588, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3699 			 4497 			 2504
6570 			 5772 			 4577
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
530 			 616 			 346
754 			 668 			 484
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [101/333] took 96.45358872413635s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5933965580114323, train accuracy: 0.6888694127957932
Val mean loss: 0.627277135848999, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3824 			 4497 			 2563
6445 			 5772 			 4511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
524 			 616 			 346
760 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891463168
Epoch [102/333] took 96.32999539375305s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5933753070058853, train accuracy: 0.6932515337423313
Val mean loss: 0.6343538136017032, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3769 			 4497 			 2558
6500 			 5772 			 4561
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
414 			 616 			 292
870 			 668 			 546
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [103/333] took 96.3429582118988s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5925848684578299, train accuracy: 0.6932515337423313
Val mean loss: 0.6278188555705838, val accuracy: 0.6534267912772586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3701 			 4497 			 2524
6568 			 5772 			 4595
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 616 			 328
799 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845850112
Epoch [104/333] took 96.43288469314575s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5922538472855945, train accuracy: 0.6924724900185023
Val mean loss: 0.6264625453367466, val accuracy: 0.6534267912772586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3747 			 4497 			 2543
6522 			 5772 			 4568
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
517 			 616 			 344
767 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3855778816
Epoch [105/333] took 95.88239765167236s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5912365436182586, train accuracy: 0.6934462946732886
Val mean loss: 0.6339540626944565, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3769 			 4497 			 2559
6500 			 5772 			 4562
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
451 			 616 			 310
833 			 668 			 527
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3815309312
Epoch [106/333] took 96.43761467933655s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5928148611498028, train accuracy: 0.6928620118804167
Val mean loss: 0.6323969872986398, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3731 			 4497 			 2537
6538 			 5772 			 4578
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
488 			 616 			 327
796 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845456896
Epoch [107/333] took 96.48612833023071s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5915645122342392, train accuracy: 0.6926672509494596
Val mean loss: 0.6281469195354276, val accuracy: 0.6573208722741433

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3735 			 4497 			 2538
6534 			 5772 			 4575
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
548 			 616 			 362
736 			 668 			 482
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892185088
Epoch [108/333] took 96.02908396720886s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5915135014279981, train accuracy: 0.6932515337423313
Val mean loss: 0.6350287831411129, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3781 			 4497 			 2564
6488 			 5772 			 4555
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
508 			 616 			 339
776 			 668 			 499
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892119552
Epoch [109/333] took 96.11108469963074s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5913927229208367, train accuracy: 0.693056772811374
Val mean loss: 0.6275904200425962, val accuracy: 0.6588785046728972

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3699 			 4497 			 2522
6570 			 5772 			 4595
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
514 			 616 			 346
770 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892152320
Epoch [110/333] took 96.23213696479797s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5904527170078777, train accuracy: 0.6894536955886649
Val mean loss: 0.6329643261141893, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3828 			 4497 			 2568
6441 			 5772 			 4512
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
422 			 616 			 294
862 			 668 			 540
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [111/333] took 96.56471729278564s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5899886191819688, train accuracy: 0.6934462946732886
Val mean loss: 0.6342739048527508, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3731 			 4497 			 2540
6538 			 5772 			 4581
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 616 			 323
801 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [112/333] took 96.26346206665039s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5912651247881655, train accuracy: 0.6950043821209465
Val mean loss: 0.6372267974586021, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3765 			 4497 			 2565
6504 			 5772 			 4572
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 616 			 329
789 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [113/333] took 96.04834413528442s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5895814318151861, train accuracy: 0.6943227188625961
Val mean loss: 0.634493656274749, val accuracy: 0.6573208722741433

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3718 			 4497 			 2538
6551 			 5772 			 4592
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
556 			 616 			 366
728 			 668 			 478
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891955712
Epoch [114/333] took 96.26741671562195s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5895017310280666, train accuracy: 0.6945174797935534
Val mean loss: 0.6397615278639445, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3802 			 4497 			 2581
6467 			 5772 			 4551
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 616 			 317
817 			 668 			 518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892217856
Epoch [115/333] took 96.52125287055969s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5897550723077352, train accuracy: 0.6929593923458954
Val mean loss: 0.6484869326033244, val accuracy: 0.6588785046728972

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3762 			 4497 			 2553
6507 			 5772 			 4563
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
466 			 616 			 322
818 			 668 			 524
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3806789632
Epoch [116/333] took 96.2588701248169s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5894820238013877, train accuracy: 0.6958808063102542
Val mean loss: 0.634898850103704, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3742 			 4497 			 2558
6527 			 5772 			 4588
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
524 			 616 			 349
760 			 668 			 493
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846374400
Epoch [117/333] took 95.8416817188263s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5878216393083056, train accuracy: 0.6951991430519038
Val mean loss: 0.635449659533617, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3765 			 4497 			 2566
6504 			 5772 			 4573
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
444 			 616 			 305
840 			 668 			 529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [118/333] took 96.40750360488892s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5890033483690933, train accuracy: 0.6946148602590321
Val mean loss: 0.6409559097231888, val accuracy: 0.6573208722741433

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3761 			 4497 			 2561
6508 			 5772 			 4572
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 616 			 339
782 			 668 			 505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846571008
Epoch [119/333] took 96.34177732467651s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5879719943458046, train accuracy: 0.6974388937579121
Val mean loss: 0.6283548561538138, val accuracy: 0.6534267912772586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3744 			 4497 			 2567
6525 			 5772 			 4595
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 616 			 321
813 			 668 			 518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892217856
Epoch [120/333] took 96.69685745239258s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5878739549177829, train accuracy: 0.6924724900185023
Val mean loss: 0.635037726018487, val accuracy: 0.6565420560747663

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3775 			 4497 			 2557
6494 			 5772 			 4554
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 616 			 332
795 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846046720
Epoch [121/333] took 96.41005253791809s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5883671378606576, train accuracy: 0.6964650891031259
Val mean loss: 0.6279127081719841, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3736 			 4497 			 2558
6533 			 5772 			 4594
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
511 			 616 			 340
773 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892185088
Epoch [122/333] took 96.1556568145752s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5876630545590897, train accuracy: 0.6948096211899892
Val mean loss: 0.6253969989171843, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3735 			 4497 			 2549
6534 			 5772 			 4586
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
566 			 616 			 363
718 			 668 			 465
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892152320
Epoch [123/333] took 96.17809414863586s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5869828378114373, train accuracy: 0.6948096211899892
Val mean loss: 0.62890600285879, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3791 			 4497 			 2577
6478 			 5772 			 4558
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 616 			 316
822 			 668 			 522
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [124/333] took 96.03468823432922s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.587349361348375, train accuracy: 0.6942253383971175
Val mean loss: 0.6307095369187797, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3769 			 4497 			 2563
6500 			 5772 			 4566
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
461 			 616 			 317
823 			 668 			 524
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846472704
Epoch [125/333] took 96.12998175621033s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5869907899251979, train accuracy: 0.6975362742233908
Val mean loss: 0.6381826560671736, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3789 			 4497 			 2590
6480 			 5772 			 4573
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 329
791 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [126/333] took 96.03036546707153s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5862317570830431, train accuracy: 0.6958808063102542
Val mean loss: 0.6312265730485683, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3748 			 4497 			 2561
6521 			 5772 			 4585
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
521 			 616 			 347
763 			 668 			 494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [127/333] took 96.20448565483093s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5865544936738653, train accuracy: 0.6994838835329633
Val mean loss: 0.6299479342088466, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3827 			 4497 			 2619
6442 			 5772 			 4564
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 616 			 318
809 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [128/333] took 96.68679308891296s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5864950855758703, train accuracy: 0.6983153179472198
Val mean loss: 0.6318361163139343, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3781 			 4497 			 2590
6488 			 5772 			 4581
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
476 			 616 			 324
808 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891628032
Epoch [129/333] took 96.36128115653992s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5851094648474102, train accuracy: 0.6996786444639206
Val mean loss: 0.637268371698333, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3757 			 4497 			 2585
6512 			 5772 			 4600
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 616 			 332
786 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [130/333] took 96.15659809112549s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.585122890932909, train accuracy: 0.6951991430519038
Val mean loss: 0.6431203920666765, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3765 			 4497 			 2566
6504 			 5772 			 4573
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 616 			 324
795 			 668 			 503
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3853648896
Epoch [131/333] took 96.41045331954956s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5860293189127497, train accuracy: 0.6970493718959977
Val mean loss: 0.624610655918354, val accuracy: 0.6588785046728972

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3716 			 4497 			 2551
6553 			 5772 			 4607
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
534 			 616 			 356
750 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [132/333] took 95.99339890480042s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5854220913020992, train accuracy: 0.6974388937579121
Val mean loss: 0.6299131352727007, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3802 			 4497 			 2596
6467 			 5772 			 4566
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
537 			 616 			 355
747 			 668 			 486
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3854566400
Epoch [133/333] took 96.40057301521301s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5844249710487057, train accuracy: 0.6977310351543481
Val mean loss: 0.6299441878388568, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3773 			 4497 			 2583
6496 			 5772 			 4582
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 616 			 330
790 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [134/333] took 96.4334180355072s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.584140327025054, train accuracy: 0.7020157756354075
Val mean loss: 0.6302952054070263, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3755 			 4497 			 2596
6514 			 5772 			 4613
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 330
791 			 668 			 505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845850112
Epoch [135/333] took 96.221031665802s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5840391204735943, train accuracy: 0.7033791021521083
Val mean loss: 0.6318149668414418, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3737 			 4497 			 2594
6532 			 5772 			 4629
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 616 			 334
790 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [136/333] took 96.90126466751099s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5849523173871441, train accuracy: 0.7014314928425358
Val mean loss: 0.6293800807580715, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3759 			 4497 			 2595
6510 			 5772 			 4608
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
525 			 616 			 347
759 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846898688
Epoch [137/333] took 96.82930612564087s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5836409731446025, train accuracy: 0.6986074593436556
Val mean loss: 0.6283696657273827, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3790 			 4497 			 2596
6479 			 5772 			 4578
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
442 			 616 			 305
842 			 668 			 531
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3849389056
Epoch [138/333] took 96.55070924758911s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.584390587802988, train accuracy: 0.7023079170318434
Val mean loss: 0.6280230458189802, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3744 			 4497 			 2592
6525 			 5772 			 4620
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 616 			 321
811 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [139/333] took 96.35393166542053s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5845628545106014, train accuracy: 0.700847210049664
Val mean loss: 0.6306448964084067, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3741 			 4497 			 2583
6528 			 5772 			 4614
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 616 			 334
782 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892185088
Epoch [140/333] took 96.1747624874115s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5831245786490099, train accuracy: 0.6976336546888694
Val mean loss: 0.63539011740103, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3826 			 4497 			 2609
6443 			 5772 			 4555
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 616 			 332
789 			 668 			 505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845456896
Epoch [141/333] took 96.15209698677063s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5839037533118346, train accuracy: 0.6994838835329633
Val mean loss: 0.6269201229258281, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3793 			 4497 			 2602
6476 			 5772 			 4581
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
472 			 616 			 321
812 			 668 			 517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [142/333] took 95.82626986503601s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5823435386021932, train accuracy: 0.7014314928425358
Val mean loss: 0.6481685042381287, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3775 			 4497 			 2603
6494 			 5772 			 4600
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
510 			 616 			 342
774 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845850112
Epoch [143/333] took 95.97463750839233s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5822862069183421, train accuracy: 0.7009445905151427
Val mean loss: 0.6361811669861398, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3762 			 4497 			 2594
6507 			 5772 			 4604
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
530 			 616 			 352
754 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [144/333] took 96.24147415161133s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5827780597120802, train accuracy: 0.7029895802901938
Val mean loss: 0.629476876520529, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3819 			 4497 			 2633
6450 			 5772 			 4586
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 326
800 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891463168
Epoch [145/333] took 96.397536277771s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.580947339813286, train accuracy: 0.7014314928425358
Val mean loss: 0.6418749050396245, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3775 			 4497 			 2603
6494 			 5772 			 4600
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
516 			 616 			 345
768 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [146/333] took 96.33025240898132s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5819751210858889, train accuracy: 0.7010419709806213
Val mean loss: 0.6276557954346261, val accuracy: 0.6627725856697819

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3787 			 4497 			 2607
6482 			 5772 			 4592
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
523 			 616 			 353
761 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891660800
Epoch [147/333] took 96.49377632141113s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5814105893406912, train accuracy: 0.7004576881877496
Val mean loss: 0.6327623492333947, val accuracy: 0.660436137071651

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3783 			 4497 			 2602
6486 			 5772 			 4591
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
526 			 616 			 353
758 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [148/333] took 96.27858018875122s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5819990296044454, train accuracy: 0.705034570065245
Val mean loss: 0.6477542962969803, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3728 			 4497 			 2598
6541 			 5772 			 4642
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
553 			 616 			 363
731 			 668 			 478
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846112256
Epoch [149/333] took 96.5821430683136s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.581692004408049, train accuracy: 0.7064952770474243
Val mean loss: 0.632774383556552, val accuracy: 0.6565420560747663

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3835 			 4497 			 2659
6434 			 5772 			 4596
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 616 			 321
817 			 668 			 522
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [150/333] took 95.97066831588745s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5811359471064119, train accuracy: 0.7029895802901938
Val mean loss: 0.6444957430769758, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3713 			 4497 			 2580
6556 			 5772 			 4639
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 616 			 333
780 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891759104
Epoch [151/333] took 96.14338541030884s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5812659045431844, train accuracy: 0.7036712435485442
Val mean loss: 0.6331150982438064, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3774 			 4497 			 2614
6495 			 5772 			 4612
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
520 			 616 			 347
764 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [152/333] took 96.2524733543396s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5801394765622148, train accuracy: 0.7058136137890739
Val mean loss: 0.6377990929091849, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3702 			 4497 			 2589
6567 			 5772 			 4659
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
568 			 616 			 366
716 			 668 			 466
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [153/333] took 96.13211631774902s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5807919994321568, train accuracy: 0.7030869607556725
Val mean loss: 0.6307431306780839, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3818 			 4497 			 2633
6451 			 5772 			 4587
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
492 			 616 			 332
792 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [154/333] took 95.86020517349243s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5802850830963467, train accuracy: 0.7068847989093388
Val mean loss: 0.6372405479593974, val accuracy: 0.6596573208722741

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3753 			 4497 			 2620
6516 			 5772 			 4639
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
531 			 616 			 355
753 			 668 			 492
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [155/333] took 96.71716690063477s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5800021709497101, train accuracy: 0.7026000584282793
Val mean loss: 0.634429222199975, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3789 			 4497 			 2616
6480 			 5772 			 4599
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 616 			 320
814 			 668 			 518
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [156/333] took 96.31684160232544s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5797087191792664, train accuracy: 0.7058136137890739
Val mean loss: 0.6290881546532235, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3744 			 4497 			 2610
6525 			 5772 			 4638
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 616 			 323
801 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3808919552
Epoch [157/333] took 95.95519089698792s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5793330046432412, train accuracy: 0.7049371895997663
Val mean loss: 0.6434609541078893, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3831 			 4497 			 2649
6438 			 5772 			 4590
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
524 			 616 			 345
760 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [158/333] took 96.32707953453064s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5787121958078997, train accuracy: 0.7052293309962021
Val mean loss: 0.6280746699833288, val accuracy: 0.6588785046728972

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3768 			 4497 			 2619
6501 			 5772 			 4623
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
508 			 616 			 343
776 			 668 			 503
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [159/333] took 96.48001837730408s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5790413814913076, train accuracy: 0.7052293309962021
Val mean loss: 0.6375485920324558, val accuracy: 0.6534267912772586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3800 			 4497 			 2635
6469 			 5772 			 4607
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 616 			 323
809 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [160/333] took 96.63173198699951s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5779962697504466, train accuracy: 0.7054240919271594
Val mean loss: 0.6298611462116241, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3752 			 4497 			 2612
6517 			 5772 			 4632
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
505 			 616 			 333
779 			 668 			 496
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [161/333] took 96.50729632377625s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5787793319916057, train accuracy: 0.7075664621676891
Val mean loss: 0.6210083699807888, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3770 			 4497 			 2632
6499 			 5772 			 4634
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 616 			 320
813 			 668 			 517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845981184
Epoch [162/333] took 96.10133385658264s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5785379914851203, train accuracy: 0.7076638426331678
Val mean loss: 0.6287738869829875, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3759 			 4497 			 2627
6510 			 5772 			 4640
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 326
800 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845456896
Epoch [163/333] took 96.84916186332703s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5788743932299153, train accuracy: 0.705034570065245
Val mean loss: 0.6342265758572555, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3802 			 4497 			 2635
6467 			 5772 			 4605
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 616 			 334
782 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [164/333] took 95.98259663581848s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5779437665070328, train accuracy: 0.7063978965819456
Val mean loss: 0.6326512032892646, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3756 			 4497 			 2619
6513 			 5772 			 4635
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
534 			 616 			 349
750 			 668 			 483
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3817439232
Epoch [165/333] took 96.35410475730896s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5781557985183977, train accuracy: 0.7097088324082189
Val mean loss: 0.6309308286120252, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3800 			 4497 			 2658
6469 			 5772 			 4630
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 329
791 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3817439232
Epoch [166/333] took 96.62919330596924s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5781369650289648, train accuracy: 0.7048398091342877
Val mean loss: 0.6315090489096757, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3830 			 4497 			 2648
6439 			 5772 			 4590
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
414 			 616 			 289
870 			 668 			 543
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [167/333] took 96.13217854499817s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5770324035039943, train accuracy: 0.7065926575129029
Val mean loss: 0.6299729056474639, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3726 			 4497 			 2605
6543 			 5772 			 4651
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
559 			 616 			 362
725 			 668 			 471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [168/333] took 96.40122652053833s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5782866231934675, train accuracy: 0.7053267114616808
Val mean loss: 0.6263471601939783, val accuracy: 0.6588785046728972

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3805 			 4497 			 2638
6464 			 5772 			 4605
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
538 			 616 			 358
746 			 668 			 488
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [169/333] took 96.1649055480957s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5764604766049489, train accuracy: 0.707858603564125
Val mean loss: 0.6422009548036064, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3831 			 4497 			 2664
6438 			 5772 			 4605
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 616 			 319
804 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846407168
Epoch [170/333] took 95.79912066459656s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5764977130748773, train accuracy: 0.708150744960561
Val mean loss: 0.6398787789228486, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3796 			 4497 			 2648
6473 			 5772 			 4624
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
465 			 616 			 313
819 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891824640
Epoch [171/333] took 96.38896918296814s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5760204612837402, train accuracy: 0.7073717012367319
Val mean loss: 0.6316924647587102, val accuracy: 0.6573208722741433

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3796 			 4497 			 2644
6473 			 5772 			 4620
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
534 			 616 			 355
750 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [172/333] took 95.77322506904602s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5770742403940992, train accuracy: 0.7063978965819456
Val mean loss: 0.6365496210935639, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3814 			 4497 			 2648
6455 			 5772 			 4606
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 616 			 335
782 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [173/333] took 95.70896172523499s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5760957751875726, train accuracy: 0.7059109942545525
Val mean loss: 0.6302231157698283, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3811 			 4497 			 2644
6458 			 5772 			 4605
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 329
791 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [174/333] took 96.24261236190796s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5765061099952626, train accuracy: 0.7089297886843899
Val mean loss: 0.6363047593977393, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3762 			 4497 			 2635
6507 			 5772 			 4645
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
496 			 616 			 332
788 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3806789632
Epoch [175/333] took 95.6342568397522s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5760341783364614, train accuracy: 0.7054240919271594
Val mean loss: 0.6288484589355748, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3840 			 4497 			 2656
6429 			 5772 			 4588
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
492 			 616 			 330
792 			 668 			 506
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891890176
Epoch [176/333] took 96.55509424209595s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5758513834246223, train accuracy: 0.7069821793748174
Val mean loss: 0.6257769145616671, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3790 			 4497 			 2639
6479 			 5772 			 4621
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
513 			 616 			 343
771 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892774912
Epoch [177/333] took 96.35629725456238s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5763186439175472, train accuracy: 0.7106826370630052
Val mean loss: 0.6309140440894336, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3760 			 4497 			 2643
6509 			 5772 			 4655
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
494 			 616 			 333
790 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [178/333] took 96.24548649787903s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5764148738525366, train accuracy: 0.7076638426331678
Val mean loss: 0.6232804954051971, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3765 			 4497 			 2630
6504 			 5772 			 4637
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
527 			 616 			 348
757 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3851518976
Epoch [179/333] took 96.42780780792236s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5759543390288903, train accuracy: 0.7090271691498685
Val mean loss: 0.6425498207894768, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3795 			 4497 			 2652
6474 			 5772 			 4629
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
512 			 616 			 343
772 			 668 			 499
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [180/333] took 96.05465292930603s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5738782084248147, train accuracy: 0.7076638426331678
Val mean loss: 0.6335922101648842, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3813 			 4497 			 2654
6456 			 5772 			 4613
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 616 			 336
780 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [181/333] took 96.26790428161621s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5738709024922498, train accuracy: 0.7092219300808258
Val mean loss: 0.6330167164162892, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3801 			 4497 			 2656
6468 			 5772 			 4627
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
442 			 616 			 303
842 			 668 			 529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3856630784
Epoch [182/333] took 96.40058875083923s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5743887033603644, train accuracy: 0.7095140714772616
Val mean loss: 0.6276702946279107, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3712 			 4497 			 2613
6557 			 5772 			 4673
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
539 			 616 			 353
745 			 668 			 482
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [183/333] took 95.93323135375977s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5739766880173549, train accuracy: 0.7098062128736975
Val mean loss: 0.6271411485788299, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3811 			 4497 			 2664
6458 			 5772 			 4625
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
554 			 616 			 362
730 			 668 			 476
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [184/333] took 95.95534157752991s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5736842653090337, train accuracy: 0.7111695393903983
Val mean loss: 0.6411741034286779, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3843 			 4497 			 2687
6426 			 5772 			 4616
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 616 			 321
810 			 668 			 515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [185/333] took 96.38429403305054s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5748277603651504, train accuracy: 0.7092219300808258
Val mean loss: 0.6291344093113411, val accuracy: 0.660436137071651

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3797 			 4497 			 2654
6472 			 5772 			 4629
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 616 			 335
794 			 668 			 513
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3852502016
Epoch [186/333] took 95.90593791007996s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5734733354265444, train accuracy: 0.7092219300808258
Val mean loss: 0.638304179034582, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3757 			 4497 			 2634
6512 			 5772 			 4649
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
520 			 616 			 341
764 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3815309312
Epoch [187/333] took 96.03993558883667s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5738818827447861, train accuracy: 0.7105852565975266
Val mean loss: 0.6385416824643205, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3813 			 4497 			 2669
6456 			 5772 			 4628
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
620 			 616 			 392
664 			 668 			 440
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892119552
Epoch [188/333] took 96.15007972717285s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5732523778517298, train accuracy: 0.7112669198558769
Val mean loss: 0.6605329615313832, val accuracy: 0.6409657320872274

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3880 			 4497 			 2706
6389 			 5772 			 4598
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
397 			 616 			 276
887 			 668 			 547
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846636544
Epoch [189/333] took 96.0782196521759s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5733462537746192, train accuracy: 0.710195734735612
Val mean loss: 0.6344728280858296, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3765 			 4497 			 2643
6504 			 5772 			 4650
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
485 			 616 			 327
799 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891857408
Epoch [190/333] took 95.72270631790161s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5727797556331967, train accuracy: 0.7100009738046548
Val mean loss: 0.6275555767664095, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3741 			 4497 			 2630
6528 			 5772 			 4661
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
541 			 616 			 355
743 			 668 			 482
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [191/333] took 96.49519896507263s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5730582347540097, train accuracy: 0.7100983542701335
Val mean loss: 0.6337177767986204, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3856 			 4497 			 2688
6413 			 5772 			 4604
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 327
800 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [192/333] took 96.1639015674591s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.573386813342757, train accuracy: 0.7089297886843899
Val mean loss: 0.6268363529589118, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3748 			 4497 			 2628
6521 			 5772 			 4652
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
548 			 616 			 360
736 			 668 			 480
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845456896
Epoch [193/333] took 96.18543648719788s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5721852253901996, train accuracy: 0.7104878761320479
Val mean loss: 0.6275471339865428, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3834 			 4497 			 2679
6435 			 5772 			 4617
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 616 			 319
810 			 668 			 513
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [194/333] took 96.17240905761719s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5717818787164777, train accuracy: 0.71175382218327
Val mean loss: 0.6317205792520104, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3793 			 4497 			 2665
6476 			 5772 			 4644
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
477 			 616 			 321
807 			 668 			 512
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [195/333] took 96.2452232837677s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5727874759201691, train accuracy: 0.7132145291654494
Val mean loss: 0.6323179348212916, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3794 			 4497 			 2673
6475 			 5772 			 4651
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
488 			 616 			 330
796 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [196/333] took 96.13091611862183s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5713439826096329, train accuracy: 0.7136040510273639
Val mean loss: 0.6387891013447832, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3858 			 4497 			 2707
6411 			 5772 			 4621
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
445 			 616 			 306
839 			 668 			 529
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [197/333] took 96.56654906272888s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5719961625207621, train accuracy: 0.7113643003213556
Val mean loss: 0.6285633502936945, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3777 			 4497 			 2655
6492 			 5772 			 4650
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
503 			 616 			 333
781 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [198/333] took 96.64475846290588s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5716671704131866, train accuracy: 0.7105852565975266
Val mean loss: 0.6240936205154513, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3757 			 4497 			 2641
6512 			 5772 			 4656
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
516 			 616 			 339
768 			 668 			 491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3804659712
Epoch [199/333] took 96.10569858551025s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5715332095311066, train accuracy: 0.71175382218327
Val mean loss: 0.6261708983560887, val accuracy: 0.6557632398753894

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3797 			 4497 			 2667
6472 			 5772 			 4642
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
568 			 616 			 371
716 			 668 			 471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892185088
Epoch [200/333] took 96.4394953250885s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5713048166946458, train accuracy: 0.7106826370630052
Val mean loss: 0.6300842231366692, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 4497 			 2694
6407 			 5772 			 4604
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
499 			 616 			 329
785 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [201/333] took 96.03335523605347s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5706623635745123, train accuracy: 0.7129223877690135
Val mean loss: 0.6359056641415852, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3829 			 4497 			 2689
6440 			 5772 			 4632
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
435 			 616 			 302
849 			 668 			 535
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891726336
Epoch [202/333] took 96.56225442886353s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5717356787106701, train accuracy: 0.7107800175284837
Val mean loss: 0.6397101355762016, val accuracy: 0.6565420560747663

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3789 			 4497 			 2658
6480 			 5772 			 4641
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 616 			 332
795 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [203/333] took 95.73893976211548s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5705801120428281, train accuracy: 0.7135066705618853
Val mean loss: 0.6272682816517062, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3759 			 4497 			 2657
6510 			 5772 			 4670
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
546 			 616 			 357
738 			 668 			 479
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [204/333] took 96.4006199836731s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5715505273728356, train accuracy: 0.7136040510273639
Val mean loss: 0.6407028698339695, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 4497 			 2688
6449 			 5772 			 4640
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 616 			 332
787 			 668 			 503
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3855778816
Epoch [205/333] took 96.59557604789734s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5709102073933848, train accuracy: 0.7135066705618853
Val mean loss: 0.6266161137964668, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3819 			 4497 			 2687
6450 			 5772 			 4640
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 616 			 320
813 			 668 			 517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3849389056
Epoch [206/333] took 96.33828783035278s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5704128644733786, train accuracy: 0.7079559840296037
Val mean loss: 0.6265194823102254, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3812 			 4497 			 2655
6457 			 5772 			 4615
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
564 			 616 			 367
720 			 668 			 471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [207/333] took 95.8020977973938s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.568724591969701, train accuracy: 0.7146752361476287
Val mean loss: 0.630746446731614, val accuracy: 0.6580996884735203

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3859 			 4497 			 2713
6410 			 5772 			 4626
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
461 			 616 			 319
823 			 668 			 526
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891988480
Epoch [208/333] took 95.912348985672s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5703587840279315, train accuracy: 0.7097088324082189
Val mean loss: 0.633362368839543, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3852 			 4497 			 2684
6417 			 5772 			 4604
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
499 			 616 			 336
785 			 668 			 505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [209/333] took 96.0287618637085s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5695638402228786, train accuracy: 0.7127276268380562
Val mean loss: 0.6424733247698807, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3771 			 4497 			 2659
6498 			 5772 			 4660
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
554 			 616 			 360
730 			 668 			 474
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [210/333] took 96.19267225265503s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5698047839221182, train accuracy: 0.7127276268380562
Val mean loss: 0.6299188885746932, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3873 			 4497 			 2710
6396 			 5772 			 4609
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
528 			 616 			 345
756 			 668 			 485
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891890176
Epoch [211/333] took 96.12274312973022s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5689054101798393, train accuracy: 0.7138961924237998
Val mean loss: 0.6433752637083937, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3881 			 4497 			 2720
6388 			 5772 			 4611
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
455 			 616 			 311
829 			 668 			 524
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3906898944
Epoch [212/333] took 95.86348724365234s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.568786280177464, train accuracy: 0.7141883338202356
Val mean loss: 0.637918489735301, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3796 			 4497 			 2679
6473 			 5772 			 4655
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
514 			 616 			 340
770 			 668 			 494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [213/333] took 96.38999819755554s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5692950934635888, train accuracy: 0.7125328659070991
Val mean loss: 0.6247464978113407, val accuracy: 0.6542056074766355

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3771 			 4497 			 2658
6498 			 5772 			 4659
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
550 			 616 			 361
734 			 668 			 479
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [214/333] took 96.24002814292908s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5679790993160176, train accuracy: 0.7129223877690135
Val mean loss: 0.6460162517501087, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3805 			 4497 			 2677
6464 			 5772 			 4644
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
484 			 616 			 322
800 			 668 			 506
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [215/333] took 96.16585874557495s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5693470288845609, train accuracy: 0.7158438017333723
Val mean loss: 0.6334154453219437, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3797 			 4497 			 2688
6472 			 5772 			 4663
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
506 			 616 			 336
778 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [216/333] took 95.97182321548462s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5685964272215359, train accuracy: 0.7152595189405005
Val mean loss: 0.6365793507273604, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3851 			 4497 			 2712
6418 			 5772 			 4633
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 616 			 328
795 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [217/333] took 96.57059526443481s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5686004654826405, train accuracy: 0.7169149868536372
Val mean loss: 0.6371130521704511, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3834 			 4497 			 2712
6435 			 5772 			 4650
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
522 			 616 			 343
762 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3800399872
Epoch [218/333] took 95.62980818748474s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5668727814037109, train accuracy: 0.7167202259226799
Val mean loss: 0.6349583311778743, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3816 			 4497 			 2702
6453 			 5772 			 4658
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 616 			 328
797 			 668 			 509
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3808919552
Epoch [219/333] took 96.20375370979309s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5671359074078617, train accuracy: 0.7134092900964066
Val mean loss: 0.6376009932378444, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3818 			 4497 			 2686
6451 			 5772 			 4640
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
535 			 616 			 349
749 			 668 			 482
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [220/333] took 95.94723176956177s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.566925591954561, train accuracy: 0.714090953354757
Val mean loss: 0.6367015024510826, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3851 			 4497 			 2706
6418 			 5772 			 4627
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 616 			 321
810 			 668 			 515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [221/333] took 96.24890804290771s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5682541564617573, train accuracy: 0.7174992696465089
Val mean loss: 0.6355277285343264, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3812 			 4497 			 2704
6457 			 5772 			 4664
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 616 			 324
805 			 668 			 513
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3808919552
Epoch [222/333] took 96.54549551010132s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5673684862172492, train accuracy: 0.7178887915084234
Val mean loss: 0.6347921621508714, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3752 			 4497 			 2676
6517 			 5772 			 4696
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 616 			 332
786 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [223/333] took 96.14346814155579s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5672141001603314, train accuracy: 0.718765215697731
Val mean loss: 0.6425190684272022, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3801 			 4497 			 2705
6468 			 5772 			 4676
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
534 			 616 			 352
750 			 668 			 486
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [224/333] took 96.61260676383972s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5672450481545517, train accuracy: 0.714869997078586
Val mean loss: 0.6298989726275932, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3841 			 4497 			 2705
6428 			 5772 			 4636
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
516 			 616 			 341
768 			 668 			 493
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [225/333] took 95.80606460571289s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5670218454714505, train accuracy: 0.7154542798714578
Val mean loss: 0.6346585256297413, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3817 			 4497 			 2696
6452 			 5772 			 4651
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
548 			 616 			 358
736 			 668 			 478
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3856630784
Epoch [226/333] took 96.50124073028564s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.566803985017111, train accuracy: 0.7155516603369364
Val mean loss: 0.6399698460974345, val accuracy: 0.6417445482866043

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3880 			 4497 			 2728
6389 			 5772 			 4620
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
428 			 616 			 292
856 			 668 			 532
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [227/333] took 96.04922437667847s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5661181450075821, train accuracy: 0.7170123673191158
Val mean loss: 0.6379340211065804, val accuracy: 0.6378504672897196

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3811 			 4497 			 2701
6458 			 5772 			 4662
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
449 			 616 			 300
835 			 668 			 519
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846407168
Epoch [228/333] took 96.62645530700684s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5671597778611466, train accuracy: 0.7173045087155516
Val mean loss: 0.6325528636211302, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3832 			 4497 			 2713
6437 			 5772 			 4653
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 330
791 			 668 			 505
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [229/333] took 96.06995296478271s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.565561127718364, train accuracy: 0.715649040802415
Val mean loss: 0.6336247455783006, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3807 			 4497 			 2692
6462 			 5772 			 4657
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
512 			 616 			 338
772 			 668 			 494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [230/333] took 95.90404915809631s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5666447800824946, train accuracy: 0.7167202259226799
Val mean loss: 0.6234808440615491, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3838 			 4497 			 2713
6431 			 5772 			 4647
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 616 			 333
780 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891988480
Epoch [231/333] took 96.50615358352661s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5659702345032558, train accuracy: 0.718765215697731
Val mean loss: 0.630364468911799, val accuracy: 0.6534267912772586

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3799 			 4497 			 2704
6470 			 5772 			 4677
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
509 			 616 			 340
775 			 668 			 499
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [232/333] took 95.89244437217712s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5662769536920055, train accuracy: 0.7166228454572013
Val mean loss: 0.6380406327363921, val accuracy: 0.6549844236760125

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3831 			 4497 			 2709
6438 			 5772 			 4650
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 616 			 322
813 			 668 			 519
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [233/333] took 96.00825262069702s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.564718009619698, train accuracy: 0.7182783133703379
Val mean loss: 0.6532174421519767, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3794 			 4497 			 2699
6475 			 5772 			 4677
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
550 			 616 			 355
734 			 668 			 473
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [234/333] took 96.38875889778137s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5653734585949194, train accuracy: 0.7166228454572013
Val mean loss: 0.6447874830990303, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3863 			 4497 			 2725
6406 			 5772 			 4634
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 616 			 325
797 			 668 			 506
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892021248
Epoch [235/333] took 96.14430856704712s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5648087829444267, train accuracy: 0.7168176063881585
Val mean loss: 0.6255501879424583, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3837 			 4497 			 2713
6432 			 5772 			 4648
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
554 			 616 			 362
730 			 668 			 476
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [236/333] took 96.33642649650574s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5654542333797502, train accuracy: 0.717207128250073
Val mean loss: 0.6305094092357449, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3873 			 4497 			 2733
6396 			 5772 			 4632
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 616 			 322
801 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891857408
Epoch [237/333] took 95.86082005500793s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5651259839163391, train accuracy: 0.7165254649917226
Val mean loss: 0.6283509840325612, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3824 			 4497 			 2705
6445 			 5772 			 4653
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 616 			 327
789 			 668 			 500
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [238/333] took 96.35573244094849s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5653366809507768, train accuracy: 0.7174992696465089
Val mean loss: 0.6536901353335962, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3824 			 4497 			 2710
6445 			 5772 			 4658
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 616 			 334
780 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892152320
Epoch [239/333] took 96.3355119228363s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5643513517402042, train accuracy: 0.7206154445418249
Val mean loss: 0.6290879380412218, val accuracy: 0.6518691588785047

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3788 			 4497 			 2708
6481 			 5772 			 4692
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
581 			 616 			 375
703 			 668 			 462
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [240/333] took 95.95723390579224s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5641709772225852, train accuracy: 0.7164280845262441
Val mean loss: 0.6365646341951882, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3819 			 4497 			 2702
6450 			 5772 			 4655
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
552 			 616 			 357
732 			 668 			 473
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846374400
Epoch [241/333] took 96.4661021232605s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5646653054659241, train accuracy: 0.7189599766286883
Val mean loss: 0.6263374584477123, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3799 			 4497 			 2705
6470 			 5772 			 4678
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
527 			 616 			 346
757 			 668 			 487
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [242/333] took 96.23949718475342s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5650199547734959, train accuracy: 0.7196416398870387
Val mean loss: 0.6355947546842622, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3826 			 4497 			 2722
6443 			 5772 			 4668
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
517 			 616 			 341
767 			 668 			 492
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3796140032
Epoch [243/333] took 96.21589803695679s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5641410461281691, train accuracy: 0.7181809329048593
Val mean loss: 0.6279929672799459, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3833 			 4497 			 2718
6436 			 5772 			 4657
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
526 			 616 			 344
758 			 668 			 486
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [244/333] took 96.13342547416687s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5638090230037118, train accuracy: 0.7188625961632097
Val mean loss: 0.6443447884989948, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3844 			 4497 			 2727
6425 			 5772 			 4655
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
462 			 616 			 311
822 			 668 			 517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [245/333] took 96.0229823589325s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5626732641105712, train accuracy: 0.7189599766286883
Val mean loss: 0.6381686257153023, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3867 			 4497 			 2739
6402 			 5772 			 4644
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 616 			 332
787 			 668 			 503
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892119552
Epoch [246/333] took 95.641521692276s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5629110061491018, train accuracy: 0.7205180640763463
Val mean loss: 0.6384767802750192, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3827 			 4497 			 2727
6442 			 5772 			 4672
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
475 			 616 			 319
809 			 668 			 512
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [247/333] took 95.94573879241943s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5630047515359623, train accuracy: 0.7213944882656539
Val mean loss: 0.6347379357349582, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3836 			 4497 			 2736
6433 			 5772 			 4672
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
493 			 616 			 326
791 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [248/333] took 96.210697889328s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5633647365733471, train accuracy: 0.7188625961632097
Val mean loss: 0.6320615701559114, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3782 			 4497 			 2696
6487 			 5772 			 4686
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
554 			 616 			 361
730 			 668 			 475
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [249/333] took 96.36429381370544s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5632239658141804, train accuracy: 0.7174018891810303
Val mean loss: 0.627235736788773, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3853 			 4497 			 2724
6416 			 5772 			 4643
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
549 			 616 			 358
735 			 668 			 477
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [250/333] took 96.00043797492981s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5629661768396325, train accuracy: 0.7194468789560814
Val mean loss: 0.6380905610759083, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3818 			 4497 			 2717
6451 			 5772 			 4671
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
503 			 616 			 332
781 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [251/333] took 96.44114065170288s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.562252511487943, train accuracy: 0.7209075859382608
Val mean loss: 0.6430107689485317, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3889 			 4497 			 2760
6380 			 5772 			 4643
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
491 			 616 			 327
793 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3852502016
Epoch [252/333] took 96.22434043884277s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5627835097714006, train accuracy: 0.7196416398870387
Val mean loss: 0.6322817620707721, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3730 			 4497 			 2674
6539 			 5772 			 4716
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
602 			 616 			 383
682 			 668 			 449
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891922944
Epoch [253/333] took 96.52000308036804s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5628232765606259, train accuracy: 0.7197390203525172
Val mean loss: 0.6432160517064537, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3913 			 4497 			 2766
6356 			 5772 			 4625
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
505 			 616 			 335
779 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [254/333] took 96.53607988357544s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5625703313454661, train accuracy: 0.721102346869218
Val mean loss: 0.629946612003373, val accuracy: 0.6417445482866043

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3841 			 4497 			 2737
6428 			 5772 			 4668
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 616 			 327
786 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [255/333] took 96.39626789093018s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5621413609877554, train accuracy: 0.7204206836108676
Val mean loss: 0.6377494945758726, val accuracy: 0.6425233644859814

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3848 			 4497 			 2737
6421 			 5772 			 4661
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 616 			 318
805 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [256/333] took 96.66505146026611s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.56252948229558, train accuracy: 0.7203233031453891
Val mean loss: 0.6320947510440175, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3825 			 4497 			 2725
6444 			 5772 			 4672
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
479 			 616 			 321
805 			 668 			 510
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892086784
Epoch [257/333] took 95.95193004608154s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5615545212294082, train accuracy: 0.7186678352322524
Val mean loss: 0.6353287696838379, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3874 			 4497 			 2741
6395 			 5772 			 4639
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
505 			 616 			 332
779 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891922944
Epoch [258/333] took 95.97234654426575s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5615094854638584, train accuracy: 0.7209075859382608
Val mean loss: 0.6442658893945741, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3775 			 4497 			 2703
6494 			 5772 			 4700
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
528 			 616 			 346
756 			 668 			 486
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846374400
Epoch [259/333] took 96.52562499046326s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5616860842779047, train accuracy: 0.7214918687311326
Val mean loss: 0.6556256369846624, val accuracy: 0.6417445482866043

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3879 			 4497 			 2758
6390 			 5772 			 4651
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 616 			 313
814 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3808919552
Epoch [260/333] took 96.7486641407013s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5617884131049813, train accuracy: 0.718765215697731
Val mean loss: 0.6273306746308397, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3767 			 4497 			 2688
6502 			 5772 			 4693
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
545 			 616 			 356
739 			 668 			 479
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [261/333] took 96.25470614433289s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5607392510335394, train accuracy: 0.7192521180251241
Val mean loss: 0.6391466528904147, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3852 			 4497 			 2733
6417 			 5772 			 4653
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
512 			 616 			 337
772 			 668 			 493
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [262/333] took 96.00664186477661s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5601793506249461, train accuracy: 0.7220761515240043
Val mean loss: 0.6364713979930412, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3883 			 4497 			 2763
6386 			 5772 			 4652
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
470 			 616 			 319
814 			 668 			 517
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [263/333] took 96.36123895645142s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5612126589749833, train accuracy: 0.7214918687311326
Val mean loss: 0.6385408349153472, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3801 			 4497 			 2719
6468 			 5772 			 4690
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
450 			 616 			 308
834 			 668 			 526
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [264/333] took 96.27126169204712s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5614487413676729, train accuracy: 0.7204206836108676
Val mean loss: 0.6395674478716966, val accuracy: 0.6464174454828661

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 4497 			 2744
6407 			 5772 			 4654
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
504 			 616 			 333
780 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [265/333] took 96.31071352958679s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5610140502638534, train accuracy: 0.7197390203525172
Val mean loss: 0.6364038608423094, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3849 			 4497 			 2734
6420 			 5772 			 4657
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
459 			 616 			 312
825 			 668 			 521
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [266/333] took 96.56244730949402s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5604894224357011, train accuracy: 0.7237316194371409
Val mean loss: 0.6339034031077129, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3798 			 4497 			 2729
6471 			 5772 			 4703
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
528 			 616 			 343
756 			 668 			 483
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [267/333] took 96.46356439590454s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5602535251702103, train accuracy: 0.7206154445418249
Val mean loss: 0.6387436317234505, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3820 			 4497 			 2724
6449 			 5772 			 4676
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
495 			 616 			 328
789 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3850437632
Epoch [268/333] took 96.04119277000427s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5607208915031587, train accuracy: 0.7201285422144318
Val mean loss: 0.6373794405925565, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3811 			 4497 			 2717
6458 			 5772 			 4678
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
489 			 616 			 324
795 			 668 			 503
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [269/333] took 96.4595410823822s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5603810687117116, train accuracy: 0.7230499561787905
Val mean loss: 0.6362840983925796, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3817 			 4497 			 2735
6452 			 5772 			 4690
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
543 			 616 			 351
741 			 668 			 476
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3844867072
Epoch [270/333] took 96.5588550567627s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5602644534311562, train accuracy: 0.7219787710585257
Val mean loss: 0.630959004890628, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3874 			 4497 			 2758
6395 			 5772 			 4656
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
498 			 616 			 332
786 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3817439232
Epoch [271/333] took 96.29040622711182s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5583595240784582, train accuracy: 0.7235368585061837
Val mean loss: 0.6299683953203806, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3832 			 4497 			 2745
6437 			 5772 			 4685
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
554 			 616 			 357
730 			 668 			 471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891955712
Epoch [272/333] took 96.22219777107239s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5595643771028964, train accuracy: 0.722952575713312
Val mean loss: 0.6358412620497913, val accuracy: 0.6362928348909658

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3850 			 4497 			 2751
6419 			 5772 			 4673
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 616 			 323
787 			 668 			 494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [273/333] took 96.01293683052063s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5592706757728184, train accuracy: 0.7224656733859188
Val mean loss: 0.6341763843850392, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3861 			 4497 			 2754
6408 			 5772 			 4665
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
490 			 616 			 328
794 			 668 			 506
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3815309312
Epoch [274/333] took 95.88132858276367s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5589327818693773, train accuracy: 0.721102346869218
Val mean loss: 0.6331852819861435, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3843 			 4497 			 2738
6426 			 5772 			 4667
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
510 			 616 			 339
774 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846407168
Epoch [275/333] took 95.58878326416016s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5591168078678048, train accuracy: 0.7241211412990554
Val mean loss: 0.6388711674911219, val accuracy: 0.6386292834890965

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3874 			 4497 			 2769
6395 			 5772 			 4667
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
456 			 616 			 304
828 			 668 			 516
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3847259136
Epoch [276/333] took 96.47673487663269s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5590796807659006, train accuracy: 0.7232447171097478
Val mean loss: 0.6401696597657552, val accuracy: 0.6510903426791277

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3769 			 4497 			 2712
6500 			 5772 			 4715
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
514 			 616 			 341
770 			 668 			 495
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [277/333] took 96.15646839141846s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5589515314295285, train accuracy: 0.7234394780407051
Val mean loss: 0.6352394891948234, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3831 			 4497 			 2744
6438 			 5772 			 4685
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
521 			 616 			 343
763 			 668 			 490
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [278/333] took 95.93490028381348s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5583203890798991, train accuracy: 0.7241211412990554
Val mean loss: 0.6276371362732678, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3856 			 4497 			 2760
6413 			 5772 			 4676
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
537 			 616 			 350
747 			 668 			 481
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [279/333] took 95.78885436058044s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5574078890393456, train accuracy: 0.7233420975752264
Val mean loss: 0.6444080849973167, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3828 			 4497 			 2742
6441 			 5772 			 4686
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
508 			 616 			 334
776 			 668 			 494
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [280/333] took 96.03570127487183s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5591560355228056, train accuracy: 0.722952575713312
Val mean loss: 0.6444579573666177, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3828 			 4497 			 2740
6441 			 5772 			 4684
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
511 			 616 			 335
773 			 668 			 492
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3815309312
Epoch [281/333] took 96.02582025527954s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5577791096451127, train accuracy: 0.7216866296620897
Val mean loss: 0.6369943662387568, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3825 			 4497 			 2732
6444 			 5772 			 4679
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
546 			 616 			 355
738 			 668 			 477
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3854566400
Epoch [282/333] took 95.99628686904907s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5577703445128562, train accuracy: 0.7248028045574058
Val mean loss: 0.6328760138372096, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3913 			 4497 			 2792
6356 			 5772 			 4651
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
488 			 616 			 327
796 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [283/333] took 95.975919008255s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5584561548129049, train accuracy: 0.7248028045574058
Val mean loss: 0.6338692772679213, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3883 			 4497 			 2777
6386 			 5772 			 4666
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 616 			 331
787 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892185088
Epoch [284/333] took 96.03935432434082s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5576300846639081, train accuracy: 0.725776609212192
Val mean loss: 0.6381220236057188, val accuracy: 0.6425233644859814

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3829 			 4497 			 2755
6440 			 5772 			 4698
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
527 			 616 			 342
757 			 668 			 483
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892414464
Epoch [285/333] took 96.24042534828186s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5584884909825905, train accuracy: 0.7241211412990554
Val mean loss: 0.6405113455725879, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3832 			 4497 			 2748
6437 			 5772 			 4688
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
517 			 616 			 338
767 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [286/333] took 96.09535574913025s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5582847901593859, train accuracy: 0.7240237608335768
Val mean loss: 0.6459587303603568, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3879 			 4497 			 2771
6390 			 5772 			 4664
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 616 			 331
782 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3821699072
Epoch [287/333] took 96.20822215080261s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5571746243123324, train accuracy: 0.7241211412990554
Val mean loss: 0.6365800427227486, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3812 			 4497 			 2738
6457 			 5772 			 4698
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
528 			 616 			 347
756 			 668 			 487
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846374400
Epoch [288/333] took 96.31073808670044s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.559145679355039, train accuracy: 0.7244132826954913
Val mean loss: 0.634821866343661, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3897 			 4497 			 2782
6372 			 5772 			 4657
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
464 			 616 			 311
820 			 668 			 515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891726336
Epoch [289/333] took 96.4265251159668s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5560610774335831, train accuracy: 0.7239263803680982
Val mean loss: 0.6344850855629619, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3892 			 4497 			 2777
6377 			 5772 			 4657
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
450 			 616 			 304
834 			 668 			 522
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [290/333] took 96.09972310066223s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5567672636093008, train accuracy: 0.7192521180251241
Val mean loss: 0.6492338791126158, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3768 			 4497 			 2691
6501 			 5772 			 4695
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
536 			 616 			 348
748 			 668 			 480
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [291/333] took 96.72785067558289s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5564586983477215, train accuracy: 0.7260687506086279
Val mean loss: 0.6337768340983042, val accuracy: 0.6409657320872274

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3868 			 4497 			 2776
6401 			 5772 			 4680
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
461 			 616 			 308
823 			 668 			 515
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845850112
Epoch [292/333] took 96.55900120735168s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.557256828865901, train accuracy: 0.7250949459538416
Val mean loss: 0.6465789239581038, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3842 			 4497 			 2758
6427 			 5772 			 4688
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
543 			 616 			 353
741 			 668 			 478
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846603776
Epoch [293/333] took 96.13037014007568s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5566043964241896, train accuracy: 0.7239263803680982
Val mean loss: 0.6373744897726106, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3896 			 4497 			 2779
6373 			 5772 			 4655
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 616 			 325
798 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846112256
Epoch [294/333] took 95.81471395492554s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5561311949636335, train accuracy: 0.7247054240919272
Val mean loss: 0.6369532215886, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 4497 			 2766
6407 			 5772 			 4676
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
473 			 616 			 316
811 			 668 			 511
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845293056
Epoch [295/333] took 96.15358018875122s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5561883499689191, train accuracy: 0.7248028045574058
Val mean loss: 0.6358563885456179, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3825 			 4497 			 2748
6444 			 5772 			 4695
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
545 			 616 			 355
739 			 668 			 478
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [296/333] took 96.22834134101868s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5566342194503713, train accuracy: 0.7261661310741065
Val mean loss: 0.6296775144774739, val accuracy: 0.6487538940809969

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3849 			 4497 			 2767
6420 			 5772 			 4690
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
519 			 616 			 342
765 			 668 			 491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [297/333] took 96.52351140975952s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5562543503220579, train accuracy: 0.7248028045574058
Val mean loss: 0.631289171009529, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3839 			 4497 			 2755
6430 			 5772 			 4688
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
501 			 616 			 332
783 			 668 			 499
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [298/333] took 96.83883500099182s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5568242436071794, train accuracy: 0.7253870873502776
Val mean loss: 0.6391234565071944, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3859 			 4497 			 2768
6410 			 5772 			 4681
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 616 			 323
797 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3811049472
Epoch [299/333] took 96.15831708908081s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.556383721553648, train accuracy: 0.7278215989872432
Val mean loss: 0.6313800499206637, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3856 			 4497 			 2779
6413 			 5772 			 4695
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
521 			 616 			 340
763 			 668 			 487
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846505472
Epoch [300/333] took 96.58150219917297s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5557877364745393, train accuracy: 0.7261661310741065
Val mean loss: 0.648659232912994, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3865 			 4497 			 2775
6404 			 5772 			 4682
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
503 			 616 			 333
781 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846112256
Epoch [301/333] took 95.95507836341858s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5558584840312554, train accuracy: 0.7255818482812347
Val mean loss: 0.6388934254646301, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3863 			 4497 			 2771
6406 			 5772 			 4680
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
500 			 616 			 329
784 			 668 			 497
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845784576
Epoch [302/333] took 95.94031476974487s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5533818430804018, train accuracy: 0.7251923264193203
Val mean loss: 0.6463558005123604, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3893 			 4497 			 2784
6376 			 5772 			 4663
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
446 			 616 			 303
838 			 668 			 525
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846407168
Epoch [303/333] took 95.61837339401245s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5550252377429855, train accuracy: 0.7251923264193203
Val mean loss: 0.6403285395808336, val accuracy: 0.6386292834890965

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3813 			 4497 			 2744
6456 			 5772 			 4703
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
618 			 616 			 385
666 			 668 			 435
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [304/333] took 96.49084377288818s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5554881918467465, train accuracy: 0.7256792287467134
Val mean loss: 0.6314635662043967, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3910 			 4497 			 2795
6359 			 5772 			 4657
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
513 			 616 			 338
771 			 668 			 493
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845850112
Epoch [305/333] took 96.92450904846191s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5562984325061334, train accuracy: 0.7252897068847989
Val mean loss: 0.6365415148618745, val accuracy: 0.6503115264797508

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3898 			 4497 			 2787
6371 			 5772 			 4661
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
487 			 616 			 327
797 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846439936
Epoch [306/333] took 96.0226571559906s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5537818434453827, train accuracy: 0.7260687506086279
Val mean loss: 0.6457896130840953, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3854 			 4497 			 2769
6415 			 5772 			 4687
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
538 			 616 			 351
746 			 668 			 481
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891988480
Epoch [307/333] took 95.98405170440674s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5544837658464723, train accuracy: 0.7240237608335768
Val mean loss: 0.631569307024886, val accuracy: 0.6394080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3823 			 4497 			 2743
6446 			 5772 			 4692
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
577 			 616 			 365
707 			 668 			 456
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [308/333] took 96.66263914108276s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5545295327437629, train accuracy: 0.7245106631609699
Val mean loss: 0.6379231890527214, val accuracy: 0.6401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3912 			 4497 			 2790
6357 			 5772 			 4650
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
486 			 616 			 320
798 			 668 			 502
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846472704
Epoch [309/333] took 95.9946939945221s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5541327743329735, train accuracy: 0.7262635115395851
Val mean loss: 0.6533290133243654, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3880 			 4497 			 2783
6389 			 5772 			 4675
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
467 			 616 			 313
817 			 668 			 514
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [310/333] took 96.25076746940613s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5552154965118455, train accuracy: 0.7268477943324569
Val mean loss: 0.6389555771176408, val accuracy: 0.6409657320872274

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3816 			 4497 			 2754
6453 			 5772 			 4710
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
543 			 616 			 349
741 			 668 			 474
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [311/333] took 96.09762597084045s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5540113971797848, train accuracy: 0.7273346966598501
Val mean loss: 0.6330199190756169, val accuracy: 0.6526479750778816

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3823 			 4497 			 2760
6446 			 5772 			 4709
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
560 			 616 			 365
724 			 668 			 473
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3891988480
Epoch [312/333] took 96.37389636039734s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5539002653408645, train accuracy: 0.724997565488363
Val mean loss: 0.6289258675604332, val accuracy: 0.6394080996884736

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3861 			 4497 			 2767
6408 			 5772 			 4678
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
547 			 616 			 350
737 			 668 			 471
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845620736
Epoch [313/333] took 95.97594690322876s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5545426715757246, train accuracy: 0.7259713701431493
Val mean loss: 0.6496274224141749, val accuracy: 0.6417445482866043

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3863 			 4497 			 2773
6406 			 5772 			 4682
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
474 			 616 			 315
810 			 668 			 509
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3893168128
Epoch [314/333] took 96.52534770965576s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5541823275178392, train accuracy: 0.7258739896776707
Val mean loss: 0.6333526569168743, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3814 			 4497 			 2748
6455 			 5772 			 4706
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
518 			 616 			 339
766 			 668 			 489
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845456896
Epoch [315/333] took 96.25446009635925s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5539183506156053, train accuracy: 0.7259713701431493
Val mean loss: 0.6337202518451505, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3903 			 4497 			 2793
6366 			 5772 			 4662
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
483 			 616 			 323
801 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846603776
Epoch [316/333] took 96.46357560157776s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5542051954618495, train accuracy: 0.7284058817801149
Val mean loss: 0.6507096930247981, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3860 			 4497 			 2784
6409 			 5772 			 4696
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
512 			 616 			 335
772 			 668 			 491
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3817439232
Epoch [317/333] took 95.83864378929138s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5527131377350876, train accuracy: 0.7267504138669783
Val mean loss: 0.637628707943893, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3895 			 4497 			 2793
6374 			 5772 			 4670
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
445 			 616 			 302
839 			 668 			 525
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846472704
Epoch [318/333] took 96.74761247634888s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5544098835682201, train accuracy: 0.7267504138669783
Val mean loss: 0.6340655153844414, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3843 			 4497 			 2767
6426 			 5772 			 4696
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
501 			 616 			 331
783 			 668 			 498
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3851518976
Epoch [319/333] took 95.94019556045532s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5526570639691991, train accuracy: 0.7295744473658584
Val mean loss: 0.6420823597326512, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3884 			 4497 			 2802
6385 			 5772 			 4690
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
471 			 616 			 315
813 			 668 			 512
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3892217856
Epoch [320/333] took 96.00407338142395s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5534202414695347, train accuracy: 0.7248028045574058
Val mean loss: 0.6352290256721217, val accuracy: 0.6433021806853583

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3895 			 4497 			 2783
6374 			 5772 			 4660
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
502 			 616 			 330
782 			 668 			 496
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845653504
Epoch [321/333] took 96.20985341072083s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5522561592290706, train accuracy: 0.729671827831337
Val mean loss: 0.6355182899207603, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3849 			 4497 			 2785
6420 			 5772 			 4708
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
497 			 616 			 330
787 			 668 			 501
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Epoch [322/333] took 96.35978722572327s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5530640847772081, train accuracy: 0.7270425552634142
Val mean loss: 0.6445199520122714, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3862 			 4497 			 2778
6407 			 5772 			 4688
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
520 			 616 			 340
764 			 668 			 488
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845948416
Epoch [323/333] took 96.36178708076477s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5531056243868261, train accuracy: 0.724218521764534
Val mean loss: 0.6357187265303077, val accuracy: 0.6479750778816199

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3897 			 4497 			 2781
6372 			 5772 			 4656
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
492 			 616 			 328
792 			 668 			 504
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [324/333] took 96.02862000465393s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5523658170135594, train accuracy: 0.7278215989872432
Val mean loss: 0.630997492772777, val accuracy: 0.6401869158878505

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3840 			 4497 			 2771
6429 			 5772 			 4703
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
562 			 616 			 358
722 			 668 			 464
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3823828992
Epoch [325/333] took 96.30567860603333s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5528266408547434, train accuracy: 0.7286006427110722
Val mean loss: 0.6282513127094362, val accuracy: 0.6495327102803738

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3876 			 4497 			 2793
6393 			 5772 			 4689
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
532 			 616 			 349
752 			 668 			 485
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [326/333] took 96.376047372818s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5518297104634972, train accuracy: 0.7286980231765507
Val mean loss: 0.6321539188303599, val accuracy: 0.647196261682243

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3861 			 4497 			 2786
6408 			 5772 			 4697
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
565 			 616 			 364
719 			 668 			 467
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3804659712
Epoch [327/333] took 95.88551139831543s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5516206236828897, train accuracy: 0.7292823059694226
Val mean loss: 0.639808978976273, val accuracy: 0.6456386292834891

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3889 			 4497 			 2803
6380 			 5772 			 4686
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
529 			 616 			 345
755 			 668 			 484
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845719040
Epoch [328/333] took 96.23490500450134s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5511255831547616, train accuracy: 0.7291849255039439
Val mean loss: 0.6397896859703994, val accuracy: 0.6409657320872274

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3872 			 4497 			 2794
6397 			 5772 			 4694
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
579 			 616 			 367
705 			 668 			 456
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3851518976
Epoch [329/333] took 96.52329015731812s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5524465131611096, train accuracy: 0.7275294575908073
Val mean loss: 0.6354002312916082, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3851 			 4497 			 2775
6418 			 5772 			 4696
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
525 			 616 			 342
759 			 668 			 485
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3846538240
Epoch [330/333] took 96.06960201263428s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5521264011243422, train accuracy: 0.7272373161943714
Val mean loss: 0.6492484437256325, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3880 			 4497 			 2788
6389 			 5772 			 4680
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
481 			 616 			 320
803 			 668 			 507
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3819569152
Epoch [331/333] took 96.21955919265747s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5515878838356411, train accuracy: 0.7274320771253286
Val mean loss: 0.6402289213203802, val accuracy: 0.6448598130841121

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3864 			 4497 			 2781
6405 			 5772 			 4689
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
480 			 616 			 320
804 			 668 			 508
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3845981184
Epoch [332/333] took 96.37549424171448s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5517234536717613, train accuracy: 0.7284058817801149
Val mean loss: 0.6549153088069544, val accuracy: 0.6417445482866043

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3848 			 4497 			 2778
6421 			 5772 			 4702
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
536 			 616 			 346
748 			 668 			 478
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3817439232
Epoch [333/333] took 96.11313772201538s
Experiment configuration: {'LM': 'LLAMA 2 7B', 'HUGGINGFACE_IMPLEMENTATION': 'AutoModel', 'CLF_HEAD': 'SimplestLinearHead', 'FREEZE_LM': True, 'BATCH_SIZE': 32, 'NUM_EPOCHS': 333, 'EARLY_STOPPING_AFTER': 'NEVER', 'LEARNING_RATE': 1e-05, 'OPTIMIZER': 'Adam', 'QUANTIZATION': True, 'DATASET': 'Liar', 'DATA_FRAC': 1, 'KEEP_COLUMNS': ['statement', 'label'], 'NUM_CLASSES': 6, 'LABEL_MAPPING': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0}}
Train mean loss: 0.5507701055097431, train accuracy: 0.7282111208491576
Val mean loss: 0.6439199702041906, val accuracy: 0.6440809968847352

TRAINING:
Labels predicted: 	 True targets: 	 Correct labels:
3882 			 4497 			 2794
6387 			 5772 			 4684
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
VALIDATION:
Labels predicted: 	 True targets: 	 Correct labels:
521 			 616 			 340
763 			 668 			 487
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
0 			 0 			 0
Max memory allocated: 9085343744; Memory allocated: 3813179392
Training finished! Training for 333 epochs took: 32067.85309290886s
Training loss: [0.8896279669253626, 0.6962316660123451, 0.6748957743525876, 0.6642837240317158, 0.6592237732120764, 0.6554616931071534, 0.652318934970927, 0.6491627509348861, 0.6474338337268414, 0.6449193179236022, 0.6432810871400566, 0.6414814819799406, 0.6405059628397505, 0.6383335335975124, 0.6367238372842842, 0.6356662656659278, 0.6343556372361763, 0.6322542259997668, 0.6317189944867404, 0.6307999201095735, 0.6303795340276581, 0.629234841679487, 0.6276682028517916, 0.6270042223351024, 0.6257777408090336, 0.6250432341640983, 0.6248431474991677, 0.6243266599757649, 0.6243474187323609, 0.6219226495127812, 0.6224378230415772, 0.6216605616692813, 0.6202958037734403, 0.6200654800992889, 0.6193730416141938, 0.6190078743150301, 0.6186743589390847, 0.6179213522936324, 0.6165047005700917, 0.6167352988712513, 0.6162467278609766, 0.615525525399829, 0.6147448654486755, 0.6141341265488265, 0.6141978947915764, 0.6134659089960414, 0.6127649017397859, 0.6130112009442112, 0.6116277853090815, 0.6116512394582743, 0.6117000144404414, 0.6102434135857401, 0.6102623901448888, 0.6089921904687198, 0.6095958514562648, 0.6091209327877496, 0.60870777799333, 0.6083999773794988, 0.607466679217288, 0.6078588106550532, 0.6066438149997379, 0.6062223712603251, 0.605973530038495, 0.6064456326196498, 0.6054343394586973, 0.6045660306917173, 0.6041517618846299, 0.6038299669914899, 0.6044695345783531, 0.6039686124087122, 0.6032567737258483, 0.6034435447874099, 0.6027043089502697, 0.6021423946102832, 0.6014486327535267, 0.6012554289395935, 0.60051556493263, 0.6006772807825391, 0.6007241430312302, 0.6003963105218061, 0.5996049957297672, 0.5995390716000139, 0.5999151296519045, 0.5980061913762137, 0.5978898397672956, 0.597953536892977, 0.5974663717910137, 0.5980327675275714, 0.5973458723672825, 0.5963774033796008, 0.5962840622273561, 0.5955961852615868, 0.5952671169306258, 0.5956918734627721, 0.5956644822503919, 0.5950242878863373, 0.5944301440522678, 0.5940828005844188, 0.5930492745195965, 0.5942864612069828, 0.5933965580114323, 0.5933753070058853, 0.5925848684578299, 0.5922538472855945, 0.5912365436182586, 0.5928148611498028, 0.5915645122342392, 0.5915135014279981, 0.5913927229208367, 0.5904527170078777, 0.5899886191819688, 0.5912651247881655, 0.5895814318151861, 0.5895017310280666, 0.5897550723077352, 0.5894820238013877, 0.5878216393083056, 0.5890033483690933, 0.5879719943458046, 0.5878739549177829, 0.5883671378606576, 0.5876630545590897, 0.5869828378114373, 0.587349361348375, 0.5869907899251979, 0.5862317570830431, 0.5865544936738653, 0.5864950855758703, 0.5851094648474102, 0.585122890932909, 0.5860293189127497, 0.5854220913020992, 0.5844249710487057, 0.584140327025054, 0.5840391204735943, 0.5849523173871441, 0.5836409731446025, 0.584390587802988, 0.5845628545106014, 0.5831245786490099, 0.5839037533118346, 0.5823435386021932, 0.5822862069183421, 0.5827780597120802, 0.580947339813286, 0.5819751210858889, 0.5814105893406912, 0.5819990296044454, 0.581692004408049, 0.5811359471064119, 0.5812659045431844, 0.5801394765622148, 0.5807919994321568, 0.5802850830963467, 0.5800021709497101, 0.5797087191792664, 0.5793330046432412, 0.5787121958078997, 0.5790413814913076, 0.5779962697504466, 0.5787793319916057, 0.5785379914851203, 0.5788743932299153, 0.5779437665070328, 0.5781557985183977, 0.5781369650289648, 0.5770324035039943, 0.5782866231934675, 0.5764604766049489, 0.5764977130748773, 0.5760204612837402, 0.5770742403940992, 0.5760957751875726, 0.5765061099952626, 0.5760341783364614, 0.5758513834246223, 0.5763186439175472, 0.5764148738525366, 0.5759543390288903, 0.5738782084248147, 0.5738709024922498, 0.5743887033603644, 0.5739766880173549, 0.5736842653090337, 0.5748277603651504, 0.5734733354265444, 0.5738818827447861, 0.5732523778517298, 0.5733462537746192, 0.5727797556331967, 0.5730582347540097, 0.573386813342757, 0.5721852253901996, 0.5717818787164777, 0.5727874759201691, 0.5713439826096329, 0.5719961625207621, 0.5716671704131866, 0.5715332095311066, 0.5713048166946458, 0.5706623635745123, 0.5717356787106701, 0.5705801120428281, 0.5715505273728356, 0.5709102073933848, 0.5704128644733786, 0.568724591969701, 0.5703587840279315, 0.5695638402228786, 0.5698047839221182, 0.5689054101798393, 0.568786280177464, 0.5692950934635888, 0.5679790993160176, 0.5693470288845609, 0.5685964272215359, 0.5686004654826405, 0.5668727814037109, 0.5671359074078617, 0.566925591954561, 0.5682541564617573, 0.5673684862172492, 0.5672141001603314, 0.5672450481545517, 0.5670218454714505, 0.566803985017111, 0.5661181450075821, 0.5671597778611466, 0.565561127718364, 0.5666447800824946, 0.5659702345032558, 0.5662769536920055, 0.564718009619698, 0.5653734585949194, 0.5648087829444267, 0.5654542333797502, 0.5651259839163391, 0.5653366809507768, 0.5643513517402042, 0.5641709772225852, 0.5646653054659241, 0.5650199547734959, 0.5641410461281691, 0.5638090230037118, 0.5626732641105712, 0.5629110061491018, 0.5630047515359623, 0.5633647365733471, 0.5632239658141804, 0.5629661768396325, 0.562252511487943, 0.5627835097714006, 0.5628232765606259, 0.5625703313454661, 0.5621413609877554, 0.56252948229558, 0.5615545212294082, 0.5615094854638584, 0.5616860842779047, 0.5617884131049813, 0.5607392510335394, 0.5601793506249461, 0.5612126589749833, 0.5614487413676729, 0.5610140502638534, 0.5604894224357011, 0.5602535251702103, 0.5607208915031587, 0.5603810687117116, 0.5602644534311562, 0.5583595240784582, 0.5595643771028964, 0.5592706757728184, 0.5589327818693773, 0.5591168078678048, 0.5590796807659006, 0.5589515314295285, 0.5583203890798991, 0.5574078890393456, 0.5591560355228056, 0.5577791096451127, 0.5577703445128562, 0.5584561548129049, 0.5576300846639081, 0.5584884909825905, 0.5582847901593859, 0.5571746243123324, 0.559145679355039, 0.5560610774335831, 0.5567672636093008, 0.5564586983477215, 0.557256828865901, 0.5566043964241896, 0.5561311949636335, 0.5561883499689191, 0.5566342194503713, 0.5562543503220579, 0.5568242436071794, 0.556383721553648, 0.5557877364745393, 0.5558584840312554, 0.5533818430804018, 0.5550252377429855, 0.5554881918467465, 0.5562984325061334, 0.5537818434453827, 0.5544837658464723, 0.5545295327437629, 0.5541327743329735, 0.5552154965118455, 0.5540113971797848, 0.5539002653408645, 0.5545426715757246, 0.5541823275178392, 0.5539183506156053, 0.5542051954618495, 0.5527131377350876, 0.5544098835682201, 0.5526570639691991, 0.5534202414695347, 0.5522561592290706, 0.5530640847772081, 0.5531056243868261, 0.5523658170135594, 0.5528266408547434, 0.5518297104634972, 0.5516206236828897, 0.5511255831547616, 0.5524465131611096, 0.5521264011243422, 0.5515878838356411, 0.5517234536717613, 0.5507701055097431]
Validation loss: [0.7292609781753726, 0.6854266800531527, 0.6751408547889896, 0.6682333451945607, 0.675533313576768, 0.66241596966255, 0.6580311597847357, 0.6544074139943937, 0.6570606769585028, 0.648286487998032, 0.6456692989279584, 0.6499536924245881, 0.6477396982472118, 0.6417042932859282, 0.6538909201214953, 0.6442058130008418, 0.6460336781129604, 0.6526132211452578, 0.6407857290128383, 0.6416772574913211, 0.6344537291584945, 0.6360365944664653, 0.6379930885826669, 0.6384831027286809, 0.6359932640703713, 0.6498873655388995, 0.6414392808588539, 0.6254282135788988, 0.6337778103060838, 0.6454988223750416, 0.6351081627171214, 0.6425668190165263, 0.6374448334298483, 0.6322828182360021, 0.6334642535302697, 0.636233909827907, 0.6362576760896822, 0.6323244542610355, 0.6367943693951863, 0.6409069546839086, 0.6338600327328938, 0.6347505566550464, 0.6378049886808163, 0.6348782268966117, 0.6391310793597523, 0.6325001164180476, 0.6383956670761108, 0.644006066206025, 0.6331932021350395, 0.6335304234086013, 0.6295149936908628, 0.6373737309037185, 0.6360882302609886, 0.6327575794080409, 0.6272017359733582, 0.6403641976961275, 0.6301131081290361, 0.6294302838604625, 0.6343370865030986, 0.6345750311525856, 0.6337572234432872, 0.6303940240929766, 0.625094935661409, 0.6404396019330839, 0.6248959637269741, 0.6365967901741586, 0.6285766341337343, 0.6269950110737871, 0.6278562487625494, 0.6331825416262556, 0.6401496078909897, 0.6338456273078918, 0.6305901800713888, 0.6365115395406398, 0.6269357756870549, 0.6326992264608058, 0.6296213421879745, 0.6358457672886733, 0.6315147934890375, 0.633893155470127, 0.6325977168432096, 0.6293278234760936, 0.6339576753174386, 0.6308788729877006, 0.6318067006948518, 0.6266951335639488, 0.6308806422280102, 0.6338740325555569, 0.6373149912531783, 0.6259383064944569, 0.6262404787831191, 0.6256252112911969, 0.6358029478933753, 0.6349942829550766, 0.628498243849452, 0.640109071644341, 0.6363113406227856, 0.6274451591619631, 0.6317560992589811, 0.627086134218588, 0.627277135848999, 0.6343538136017032, 0.6278188555705838, 0.6264625453367466, 0.6339540626944565, 0.6323969872986398, 0.6281469195354276, 0.6350287831411129, 0.6275904200425962, 0.6329643261141893, 0.6342739048527508, 0.6372267974586021, 0.634493656274749, 0.6397615278639445, 0.6484869326033244, 0.634898850103704, 0.635449659533617, 0.6409559097231888, 0.6283548561538138, 0.635037726018487, 0.6279127081719841, 0.6253969989171843, 0.62890600285879, 0.6307095369187797, 0.6381826560671736, 0.6312265730485683, 0.6299479342088466, 0.6318361163139343, 0.637268371698333, 0.6431203920666765, 0.624610655918354, 0.6299131352727007, 0.6299441878388568, 0.6302952054070263, 0.6318149668414418, 0.6293800807580715, 0.6283696657273827, 0.6280230458189802, 0.6306448964084067, 0.63539011740103, 0.6269201229258281, 0.6481685042381287, 0.6361811669861398, 0.629476876520529, 0.6418749050396245, 0.6276557954346261, 0.6327623492333947, 0.6477542962969803, 0.632774383556552, 0.6444957430769758, 0.6331150982438064, 0.6377990929091849, 0.6307431306780839, 0.6372405479593974, 0.634429222199975, 0.6290881546532235, 0.6434609541078893, 0.6280746699833288, 0.6375485920324558, 0.6298611462116241, 0.6210083699807888, 0.6287738869829875, 0.6342265758572555, 0.6326512032892646, 0.6309308286120252, 0.6315090489096757, 0.6299729056474639, 0.6263471601939783, 0.6422009548036064, 0.6398787789228486, 0.6316924647587102, 0.6365496210935639, 0.6302231157698283, 0.6363047593977393, 0.6288484589355748, 0.6257769145616671, 0.6309140440894336, 0.6232804954051971, 0.6425498207894768, 0.6335922101648842, 0.6330167164162892, 0.6276702946279107, 0.6271411485788299, 0.6411741034286779, 0.6291344093113411, 0.638304179034582, 0.6385416824643205, 0.6605329615313832, 0.6344728280858296, 0.6275555767664095, 0.6337177767986204, 0.6268363529589118, 0.6275471339865428, 0.6317205792520104, 0.6323179348212916, 0.6387891013447832, 0.6285633502936945, 0.6240936205154513, 0.6261708983560887, 0.6300842231366692, 0.6359056641415852, 0.6397101355762016, 0.6272682816517062, 0.6407028698339695, 0.6266161137964668, 0.6265194823102254, 0.630746446731614, 0.633362368839543, 0.6424733247698807, 0.6299188885746932, 0.6433752637083937, 0.637918489735301, 0.6247464978113407, 0.6460162517501087, 0.6334154453219437, 0.6365793507273604, 0.6371130521704511, 0.6349583311778743, 0.6376009932378444, 0.6367015024510826, 0.6355277285343264, 0.6347921621508714, 0.6425190684272022, 0.6298989726275932, 0.6346585256297413, 0.6399698460974345, 0.6379340211065804, 0.6325528636211302, 0.6336247455783006, 0.6234808440615491, 0.630364468911799, 0.6380406327363921, 0.6532174421519767, 0.6447874830990303, 0.6255501879424583, 0.6305094092357449, 0.6283509840325612, 0.6536901353335962, 0.6290879380412218, 0.6365646341951882, 0.6263374584477123, 0.6355947546842622, 0.6279929672799459, 0.6443447884989948, 0.6381686257153023, 0.6384767802750192, 0.6347379357349582, 0.6320615701559114, 0.627235736788773, 0.6380905610759083, 0.6430107689485317, 0.6322817620707721, 0.6432160517064537, 0.629946612003373, 0.6377494945758726, 0.6320947510440175, 0.6353287696838379, 0.6442658893945741, 0.6556256369846624, 0.6273306746308397, 0.6391466528904147, 0.6364713979930412, 0.6385408349153472, 0.6395674478716966, 0.6364038608423094, 0.6339034031077129, 0.6387436317234505, 0.6373794405925565, 0.6362840983925796, 0.630959004890628, 0.6299683953203806, 0.6358412620497913, 0.6341763843850392, 0.6331852819861435, 0.6388711674911219, 0.6401696597657552, 0.6352394891948234, 0.6276371362732678, 0.6444080849973167, 0.6444579573666177, 0.6369943662387568, 0.6328760138372096, 0.6338692772679213, 0.6381220236057188, 0.6405113455725879, 0.6459587303603568, 0.6365800427227486, 0.634821866343661, 0.6344850855629619, 0.6492338791126158, 0.6337768340983042, 0.6465789239581038, 0.6373744897726106, 0.6369532215886, 0.6358563885456179, 0.6296775144774739, 0.631289171009529, 0.6391234565071944, 0.6313800499206637, 0.648659232912994, 0.6388934254646301, 0.6463558005123604, 0.6403285395808336, 0.6314635662043967, 0.6365415148618745, 0.6457896130840953, 0.631569307024886, 0.6379231890527214, 0.6533290133243654, 0.6389555771176408, 0.6330199190756169, 0.6289258675604332, 0.6496274224141749, 0.6333526569168743, 0.6337202518451505, 0.6507096930247981, 0.637628707943893, 0.6340655153844414, 0.6420823597326512, 0.6352290256721217, 0.6355182899207603, 0.6445199520122714, 0.6357187265303077, 0.630997492772777, 0.6282513127094362, 0.6321539188303599, 0.639808978976273, 0.6397896859703994, 0.6354002312916082, 0.6492484437256325, 0.6402289213203802, 0.6549153088069544, 0.6439199702041906]
Training accuracy: [0.5418249099230694, 0.591781088713604, 0.6033693641055604, 0.6110624208783718, 0.614665498101081, 0.612815269256987, 0.6229428376667641, 0.6254747297692083, 0.6303437530431395, 0.6299542311812251, 0.6345311130587205, 0.6367708637647288, 0.6402765605219592, 0.6382315707469082, 0.6460220079851982, 0.6448534423994546, 0.6444639205375402, 0.6493329438114714, 0.6469958126399844, 0.6487486610185996, 0.6504041289317363, 0.6515726945174798, 0.6523517382413088, 0.6547862498782744, 0.653325542896095, 0.6573181419807187, 0.655662674067582, 0.6578050443081118, 0.657512902911676, 0.6617002629272568, 0.6566364787223683, 0.6598500340831629, 0.6625766871165644, 0.6630635894439575, 0.6631609699094362, 0.6635504917713506, 0.6636478722368293, 0.6656928620118804, 0.6633557308403935, 0.6647190573570941, 0.6667640471321453, 0.6667640471321453, 0.6677378517869316, 0.6698802220274613, 0.6672509494595384, 0.671243548544162, 0.6703671243548545, 0.6710487876132047, 0.6729963969227772, 0.6728990164572987, 0.6709514071477262, 0.6748466257668712, 0.6729963969227772, 0.6769889960074009, 0.6761125718180933, 0.6749440062323497, 0.6765994741454864, 0.6760151913526147, 0.6750413866978284, 0.6746518648359139, 0.6772811374038368, 0.679033985782452, 0.6760151913526147, 0.6784497029895803, 0.679033985782452, 0.6771837569383582, 0.679326127178888, 0.6784497029895803, 0.6808842146265459, 0.6815658778848963, 0.6802999318336742, 0.6816632583503749, 0.683221345798033, 0.6788392248514948, 0.6811763560229818, 0.6838056285909047, 0.6808842146265459, 0.6835134871944688, 0.6859479988314344, 0.6854610965040413, 0.6854610965040413, 0.6835134871944688, 0.6841951504528192, 0.6877008472100496, 0.6834161067289901, 0.6873113253481352, 0.6856558574349986, 0.6856558574349986, 0.6867270425552634, 0.6869218034862207, 0.6881877495374428, 0.6870191839516993, 0.6883825104684, 0.6885772713993573, 0.6876034667445711, 0.690232739312494, 0.6925698704839809, 0.6895510760541436, 0.6894536955886649, 0.6895510760541436, 0.6888694127957932, 0.6932515337423313, 0.6932515337423313, 0.6924724900185023, 0.6934462946732886, 0.6928620118804167, 0.6926672509494596, 0.6932515337423313, 0.693056772811374, 0.6894536955886649, 0.6934462946732886, 0.6950043821209465, 0.6943227188625961, 0.6945174797935534, 0.6929593923458954, 0.6958808063102542, 0.6951991430519038, 0.6946148602590321, 0.6974388937579121, 0.6924724900185023, 0.6964650891031259, 0.6948096211899892, 0.6948096211899892, 0.6942253383971175, 0.6975362742233908, 0.6958808063102542, 0.6994838835329633, 0.6983153179472198, 0.6996786444639206, 0.6951991430519038, 0.6970493718959977, 0.6974388937579121, 0.6977310351543481, 0.7020157756354075, 0.7033791021521083, 0.7014314928425358, 0.6986074593436556, 0.7023079170318434, 0.700847210049664, 0.6976336546888694, 0.6994838835329633, 0.7014314928425358, 0.7009445905151427, 0.7029895802901938, 0.7014314928425358, 0.7010419709806213, 0.7004576881877496, 0.705034570065245, 0.7064952770474243, 0.7029895802901938, 0.7036712435485442, 0.7058136137890739, 0.7030869607556725, 0.7068847989093388, 0.7026000584282793, 0.7058136137890739, 0.7049371895997663, 0.7052293309962021, 0.7052293309962021, 0.7054240919271594, 0.7075664621676891, 0.7076638426331678, 0.705034570065245, 0.7063978965819456, 0.7097088324082189, 0.7048398091342877, 0.7065926575129029, 0.7053267114616808, 0.707858603564125, 0.708150744960561, 0.7073717012367319, 0.7063978965819456, 0.7059109942545525, 0.7089297886843899, 0.7054240919271594, 0.7069821793748174, 0.7106826370630052, 0.7076638426331678, 0.7090271691498685, 0.7076638426331678, 0.7092219300808258, 0.7095140714772616, 0.7098062128736975, 0.7111695393903983, 0.7092219300808258, 0.7092219300808258, 0.7105852565975266, 0.7112669198558769, 0.710195734735612, 0.7100009738046548, 0.7100983542701335, 0.7089297886843899, 0.7104878761320479, 0.71175382218327, 0.7132145291654494, 0.7136040510273639, 0.7113643003213556, 0.7105852565975266, 0.71175382218327, 0.7106826370630052, 0.7129223877690135, 0.7107800175284837, 0.7135066705618853, 0.7136040510273639, 0.7135066705618853, 0.7079559840296037, 0.7146752361476287, 0.7097088324082189, 0.7127276268380562, 0.7127276268380562, 0.7138961924237998, 0.7141883338202356, 0.7125328659070991, 0.7129223877690135, 0.7158438017333723, 0.7152595189405005, 0.7169149868536372, 0.7167202259226799, 0.7134092900964066, 0.714090953354757, 0.7174992696465089, 0.7178887915084234, 0.718765215697731, 0.714869997078586, 0.7154542798714578, 0.7155516603369364, 0.7170123673191158, 0.7173045087155516, 0.715649040802415, 0.7167202259226799, 0.718765215697731, 0.7166228454572013, 0.7182783133703379, 0.7166228454572013, 0.7168176063881585, 0.717207128250073, 0.7165254649917226, 0.7174992696465089, 0.7206154445418249, 0.7164280845262441, 0.7189599766286883, 0.7196416398870387, 0.7181809329048593, 0.7188625961632097, 0.7189599766286883, 0.7205180640763463, 0.7213944882656539, 0.7188625961632097, 0.7174018891810303, 0.7194468789560814, 0.7209075859382608, 0.7196416398870387, 0.7197390203525172, 0.721102346869218, 0.7204206836108676, 0.7203233031453891, 0.7186678352322524, 0.7209075859382608, 0.7214918687311326, 0.718765215697731, 0.7192521180251241, 0.7220761515240043, 0.7214918687311326, 0.7204206836108676, 0.7197390203525172, 0.7237316194371409, 0.7206154445418249, 0.7201285422144318, 0.7230499561787905, 0.7219787710585257, 0.7235368585061837, 0.722952575713312, 0.7224656733859188, 0.721102346869218, 0.7241211412990554, 0.7232447171097478, 0.7234394780407051, 0.7241211412990554, 0.7233420975752264, 0.722952575713312, 0.7216866296620897, 0.7248028045574058, 0.7248028045574058, 0.725776609212192, 0.7241211412990554, 0.7240237608335768, 0.7241211412990554, 0.7244132826954913, 0.7239263803680982, 0.7192521180251241, 0.7260687506086279, 0.7250949459538416, 0.7239263803680982, 0.7247054240919272, 0.7248028045574058, 0.7261661310741065, 0.7248028045574058, 0.7253870873502776, 0.7278215989872432, 0.7261661310741065, 0.7255818482812347, 0.7251923264193203, 0.7251923264193203, 0.7256792287467134, 0.7252897068847989, 0.7260687506086279, 0.7240237608335768, 0.7245106631609699, 0.7262635115395851, 0.7268477943324569, 0.7273346966598501, 0.724997565488363, 0.7259713701431493, 0.7258739896776707, 0.7259713701431493, 0.7284058817801149, 0.7267504138669783, 0.7267504138669783, 0.7295744473658584, 0.7248028045574058, 0.729671827831337, 0.7270425552634142, 0.724218521764534, 0.7278215989872432, 0.7286006427110722, 0.7286980231765507, 0.7292823059694226, 0.7291849255039439, 0.7275294575908073, 0.7272373161943714, 0.7274320771253286, 0.7284058817801149, 0.7282111208491576]
Validation accuracy: [0.5700934579439252, 0.5887850467289719, 0.5942367601246106, 0.5973520249221184, 0.5989096573208723, 0.6051401869158879, 0.618380062305296, 0.6160436137071651, 0.6137071651090342, 0.6152647975077882, 0.6269470404984424, 0.6261682242990654, 0.6339563862928349, 0.6277258566978193, 0.6362928348909658, 0.6246105919003115, 0.6199376947040498, 0.6269470404984424, 0.6339563862928349, 0.6433021806853583, 0.6362928348909658, 0.6308411214953271, 0.6378504672897196, 0.6378504672897196, 0.631619937694704, 0.6401869158878505, 0.6347352024922118, 0.631619937694704, 0.6409657320872274, 0.6238317757009346, 0.6433021806853583, 0.6370716510903427, 0.6339563862928349, 0.6433021806853583, 0.6464174454828661, 0.6479750778816199, 0.6409657320872274, 0.6464174454828661, 0.6518691588785047, 0.6487538940809969, 0.6495327102803738, 0.6433021806853583, 0.6526479750778816, 0.6503115264797508, 0.6495327102803738, 0.6596573208722741, 0.6464174454828661, 0.6542056074766355, 0.6401869158878505, 0.6433021806853583, 0.6534267912772586, 0.6503115264797508, 0.6526479750778816, 0.6495327102803738, 0.6573208722741433, 0.6456386292834891, 0.6394080996884736, 0.6542056074766355, 0.6596573208722741, 0.6580996884735203, 0.6487538940809969, 0.6588785046728972, 0.6433021806853583, 0.6573208722741433, 0.6479750778816199, 0.6440809968847352, 0.6542056074766355, 0.6565420560747663, 0.6542056074766355, 0.6557632398753894, 0.6518691588785047, 0.6510903426791277, 0.6518691588785047, 0.6479750778816199, 0.6510903426791277, 0.6456386292834891, 0.6526479750778816, 0.6510903426791277, 0.6433021806853583, 0.6526479750778816, 0.6518691588785047, 0.6518691588785047, 0.6518691588785047, 0.647196261682243, 0.6596573208722741, 0.6518691588785047, 0.6526479750778816, 0.6464174454828661, 0.6487538940809969, 0.6479750778816199, 0.6487538940809969, 0.6503115264797508, 0.6510903426791277, 0.6503115264797508, 0.6448598130841121, 0.6526479750778816, 0.6448598130841121, 0.6495327102803738, 0.6479750778816199, 0.6464174454828661, 0.6510903426791277, 0.6526479750778816, 0.6534267912772586, 0.6534267912772586, 0.6518691588785047, 0.6495327102803738, 0.6573208722741433, 0.6526479750778816, 0.6588785046728972, 0.6495327102803738, 0.647196261682243, 0.647196261682243, 0.6573208722741433, 0.6503115264797508, 0.6588785046728972, 0.6557632398753894, 0.6495327102803738, 0.6573208722741433, 0.6534267912772586, 0.6565420560747663, 0.6518691588785047, 0.6448598130841121, 0.6526479750778816, 0.6549844236760125, 0.6487538940809969, 0.6549844236760125, 0.6456386292834891, 0.6542056074766355, 0.6495327102803738, 0.6440809968847352, 0.6588785046728972, 0.6549844236760125, 0.6495327102803738, 0.6503115264797508, 0.6557632398753894, 0.6518691588785047, 0.6510903426791277, 0.6518691588785047, 0.6495327102803738, 0.6518691588785047, 0.6526479750778816, 0.6557632398753894, 0.6557632398753894, 0.6510903426791277, 0.6557632398753894, 0.6627725856697819, 0.660436137071651, 0.6549844236760125, 0.6565420560747663, 0.6464174454828661, 0.6557632398753894, 0.6479750778816199, 0.6542056074766355, 0.6596573208722741, 0.6526479750778816, 0.647196261682243, 0.6495327102803738, 0.6588785046728972, 0.6534267912772586, 0.6456386292834891, 0.6518691588785047, 0.6510903426791277, 0.6495327102803738, 0.6479750778816199, 0.6487538940809969, 0.6479750778816199, 0.6487538940809969, 0.6588785046728972, 0.6433021806853583, 0.6456386292834891, 0.6573208722741433, 0.6510903426791277, 0.6487538940809969, 0.6510903426791277, 0.6510903426791277, 0.6549844236760125, 0.6542056074766355, 0.6518691588785047, 0.6557632398753894, 0.6510903426791277, 0.6479750778816199, 0.6503115264797508, 0.6526479750778816, 0.6510903426791277, 0.660436137071651, 0.6464174454828661, 0.6479750778816199, 0.6409657320872274, 0.6518691588785047, 0.6518691588785047, 0.6526479750778816, 0.6542056074766355, 0.6479750778816199, 0.6487538940809969, 0.6542056074766355, 0.6503115264797508, 0.647196261682243, 0.6464174454828661, 0.6557632398753894, 0.6440809968847352, 0.6518691588785047, 0.6565420560747663, 0.6510903426791277, 0.6503115264797508, 0.6518691588785047, 0.6526479750778816, 0.6580996884735203, 0.6549844236760125, 0.6495327102803738, 0.6464174454828661, 0.6503115264797508, 0.6495327102803738, 0.6542056074766355, 0.6448598130841121, 0.6495327102803738, 0.6503115264797508, 0.6479750778816199, 0.6518691588785047, 0.647196261682243, 0.6510903426791277, 0.6518691588785047, 0.6495327102803738, 0.6526479750778816, 0.6495327102803738, 0.6510903426791277, 0.6417445482866043, 0.6378504672897196, 0.6503115264797508, 0.6479750778816199, 0.6464174454828661, 0.6534267912772586, 0.6549844236760125, 0.6448598130841121, 0.647196261682243, 0.6526479750778816, 0.6456386292834891, 0.6440809968847352, 0.6479750778816199, 0.6518691588785047, 0.6464174454828661, 0.6487538940809969, 0.6487538940809969, 0.6464174454828661, 0.6448598130841121, 0.6503115264797508, 0.647196261682243, 0.6440809968847352, 0.6510903426791277, 0.6503115264797508, 0.6456386292834891, 0.647196261682243, 0.6479750778816199, 0.6487538940809969, 0.6417445482866043, 0.6425233644859814, 0.647196261682243, 0.6440809968847352, 0.6479750778816199, 0.6417445482866043, 0.6503115264797508, 0.6464174454828661, 0.6510903426791277, 0.6495327102803738, 0.6464174454828661, 0.6487538940809969, 0.6433021806853583, 0.6456386292834891, 0.6440809968847352, 0.6440809968847352, 0.6495327102803738, 0.6448598130841121, 0.6362928348909658, 0.6495327102803738, 0.6510903426791277, 0.6386292834890965, 0.6510903426791277, 0.6487538940809969, 0.647196261682243, 0.6448598130841121, 0.6440809968847352, 0.6479750778816199, 0.6495327102803738, 0.6487538940809969, 0.6425233644859814, 0.6440809968847352, 0.6448598130841121, 0.6495327102803738, 0.6433021806853583, 0.6433021806853583, 0.6448598130841121, 0.6409657320872274, 0.647196261682243, 0.6479750778816199, 0.6440809968847352, 0.6487538940809969, 0.6487538940809969, 0.647196261682243, 0.6440809968847352, 0.6440809968847352, 0.647196261682243, 0.6433021806853583, 0.6448598130841121, 0.6386292834890965, 0.647196261682243, 0.6503115264797508, 0.6479750778816199, 0.6394080996884736, 0.6401869158878505, 0.6440809968847352, 0.6409657320872274, 0.6526479750778816, 0.6394080996884736, 0.6417445482866043, 0.6448598130841121, 0.647196261682243, 0.6433021806853583, 0.6440809968847352, 0.6456386292834891, 0.6440809968847352, 0.6433021806853583, 0.647196261682243, 0.6448598130841121, 0.6479750778816199, 0.6401869158878505, 0.6495327102803738, 0.647196261682243, 0.6456386292834891, 0.6409657320872274, 0.6440809968847352, 0.6440809968847352, 0.6448598130841121, 0.6417445482866043, 0.6440809968847352]
Accuracy plot saved at 'binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825/accuracy_binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825.png'
Loss plot saved at 'binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825/loss_binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825.png'
Checkpoint saved at 'binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825/checkpoint_binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825.pth'
Best checkpoint saved at 'binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825/best_checkpoint_binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825.pth'
Output logfile saved at binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825/output_log_binary_Llama-7b_1e-5_333_SimpleLinearHead_1710702938.5718825.txt
