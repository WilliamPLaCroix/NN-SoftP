{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["162d1e59d6bd4ac688a59991d333c53c","f63c70e2d67048c28395bdfb47d4b46e","51d3197a15a940a293729a6109abed8f","0928992e87a94488b705e18bf6ac93f1","d4dfc7aa6600480785aed23c0c464886","cb178798ef0c416a88829ae4a625bbf3","7a22b37f51b54d17b291332fb5066d62","05235f8ff8e54741aebc06e748c66cc4","c6899887dadf4f20b7aa37311c3d83f7","c269b3fc8311446e895abb4fba8308ce","b00f37b269a643a6943fadeaeddf6046","571d9caa54ba46e593d54d08d0aa5fa1","0fe5f5cd897949bd9fb6c811d7317eac","05b4232f95ff41a0badfd34aa54a630a","cc8d0d8c3c7a416087ca32548f4d2208","392935d7bc0249f28ff4004fedaa06c3","5d9542811bd740608587dba37797fad1"]},"executionInfo":{"elapsed":14784,"status":"ok","timestamp":1708608646939,"user":{"displayName":"ì•¼ì±„ê³±ì°½","userId":"12867923236169769890"},"user_tz":0},"id":"7OKPpb5IV0lP","outputId":"7889e05d-a0c3-410a-8f75-44e78e554551"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: dill, multiprocess, datasets\n","Successfully installed datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"162d1e59d6bd4ac688a59991d333c53c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from collections import Counter\n","from huggingface_hub import login\n","!pip install datasets\n","from datasets import load_dataset, Dataset\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","from tqdm import tqdm\n","import numpy as np\n","from transformers import XLMRobertaModel, XLMRobertaTokenizerFast\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_class_weight\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# authentication with huggingface\n","# create token at https://huggingface.co/settings/tokens (create as read)\n","# token should be stored locally, so technically login is only needed one time\n","login()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":267,"status":"error","timestamp":1708608801892,"user":{"displayName":"ì•¼ì±„ê³±ì°½","userId":"12867923236169769890"},"user_tz":0},"id":"UYo_d-mQV0lb","outputId":"f85d00e9-e6ab-4891-e602-d0bb33c3bee1"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './data/articles.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-6b82488b581a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# open from csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/articles.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0marticle_replies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/article_replies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mart_rep_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_replies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"articleId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/articles.csv'"]}],"source":["# # download specific dataset files; entire archive is only ~250 mb\n","# articles = load_dataset(\"Cofacts/line-msg-fact-check-tw\", \"articles\") # article contents and some meta info\n","# article_replies = load_dataset(\"Cofacts/line-msg-fact-check-tw\", \"article_replies\") # 'join table' for articles and replies with added meta info\n","\n","# open from csv\n","articles = pd.read_csv('./content/articles.csv', lineterminator='\\n')\n","article_replies = pd.read_csv('./content/article_replies.csv')\n","art_rep_df = pd.merge(articles, article_replies, left_on=\"id\", right_on=\"articleId\", how=\"left\")\n","art_rep_df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"elapsed":29633,"status":"error","timestamp":1708609254084,"user":{"displayName":"ì•¼ì±„ê³±ì°½","userId":"12867923236169769890"},"user_tz":0},"id":"UaW6jBuzCBQw","outputId":"accc49cb-25bc-455c-9192-7f38c88bf8ab"},"outputs":[{"ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["9c626a6340314656bc08cdb56a31a658","d8ad357b7f664908bc502ceec903a01b","7a6003adc0b64182965b89f0dfa2b368","22a1dac906154bf7869a21d8282b798d","1c35aeb8045445569b58078ad91205ac"]},"id":"4t5_7YpwAkmL","outputId":"02bcf444-f831-4d42-f1b2-b54dec58b89d"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c626a6340314656bc08cdb56a31a658","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/19.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8ad357b7f664908bc502ceec903a01b","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/57.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a6003adc0b64182965b89f0dfa2b368","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22a1dac906154bf7869a21d8282b798d","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.61M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c35aeb8045445569b58078ad91205ac","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>articleType</th>\n","      <th>status_x</th>\n","      <th>text</th>\n","      <th>normalArticleReplyCount</th>\n","      <th>createdAt_x</th>\n","      <th>updatedAt_x</th>\n","      <th>lastRequestedAt</th>\n","      <th>userIdsha256_x</th>\n","      <th>appId_x</th>\n","      <th>...</th>\n","      <th>articleId</th>\n","      <th>replyId</th>\n","      <th>userIdsha256_y</th>\n","      <th>negativeFeedbackCount</th>\n","      <th>positiveFeedbackCount</th>\n","      <th>replyType</th>\n","      <th>appId_y</th>\n","      <th>status_y</th>\n","      <th>createdAt_y</th>\n","      <th>updatedAt_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14h550ymn3m3u</td>\n","      <td>TEXT</td>\n","      <td>NORMAL</td>\n","      <td>BA.5ç—…æ¯’å¼•ç™¼çš„ä¸åªã€Œç¸®çŸ­æ½›ä¼æœŸï¼Œå¢åŠ R0å€¼ã€ï¼Œé‚„æœ‰æ˜“ä½¿äººã€Œå†æ„ŸæŸ“ï¼ˆReinfecionï¼‰...</td>\n","      <td>1.0</td>\n","      <td>2022-09-05T05:26:33.360Z</td>\n","      <td>2022-09-05T05:26:33.360Z</td>\n","      <td>2022-09-05T05:26:33.381Z</td>\n","      <td>3753ca22ca96f5fc1f13e62291f28e405d56b1a976b21d...</td>\n","      <td>RUMORS_LINE_BOT</td>\n","      <td>...</td>\n","      <td>14h550ymn3m3u</td>\n","      <td>6oo8DYMBv5it-Cx_8405</td>\n","      <td>6892d0026181e95d034bf8781025afbf395d57cc88ac05...</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>RUMOR</td>\n","      <td>WEBSITE</td>\n","      <td>NORMAL</td>\n","      <td>2022-09-05T10:40:41.789Z</td>\n","      <td>2022-09-05T10:40:41.789Z</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>326xjpkjbf01i</td>\n","      <td>TEXT</td>\n","      <td>NORMAL</td>\n","      <td>https://youtu.be/xK9NzL3PkdE</td>\n","      <td>0.0</td>\n","      <td>2022-09-08T12:34:27.602Z</td>\n","      <td>2022-09-08T12:34:27.602Z</td>\n","      <td>2022-09-08T12:34:27.634Z</td>\n","      <td>243b5897c14f02fb5b92a9e4f4cc39d5fb84ff16173add...</td>\n","      <td>RUMORS_LINE_BOT</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>oupi0eu9aocr</td>\n","      <td>TEXT</td>\n","      <td>NORMAL</td>\n","      <td>è¢«å–æ¶ˆçš„èˆªç­\\n\\n2018å¹´çš„ä¸€å¤©ï¼Œæˆ‘å¾æ´›æ‰ç£¯å›åœ‹ï¼Œä¹˜åå‡Œæ™¨ä¸€é»çš„åœ‹èˆªèˆªç­ï¼Œé¦¬ä¸Šè¦ç™»æ©Ÿäº†ï¼Œ...</td>\n","      <td>1.0</td>\n","      <td>2021-11-13T16:36:56.548Z</td>\n","      <td>2021-11-13T16:36:56.548Z</td>\n","      <td>2022-04-27T08:52:17.115Z</td>\n","      <td>4a266a6fdefc88e59eef644402e97c7f4c8196becca686...</td>\n","      <td>RUMORS_LINE_BOT</td>\n","      <td>...</td>\n","      <td>oupi0eu9aocr</td>\n","      <td>MYotCYMBv5it-Cx_gIpH</td>\n","      <td>fc9652aa205dab75e19ecff420945e95aa3909a54b0d9a...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>OPINIONATED</td>\n","      <td>WEBSITE</td>\n","      <td>NORMAL</td>\n","      <td>2022-09-04T15:45:20.464Z</td>\n","      <td>2022-09-04T15:45:20.464Z</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>my5ep5z69tql</td>\n","      <td>TEXT</td>\n","      <td>NORMAL</td>\n","      <td>ä½ å¥½ğŸ‘±ğŸ»â€â™€ï¸\\n\\nç°¡å–®è·Ÿä½ èªªä¸€ä¸‹å…¬å¸å·¥ä½œå…§å®¹ï¼š\\næˆ‘å€‘æ˜¯åšè³¼ç‰©ç³»çµ±è¨‚å–®çš„å·¥ä½œï¼Œä¸»è¦å°±æ˜¯å¢...</td>\n","      <td>1.0</td>\n","      <td>2022-08-11T20:53:15.644Z</td>\n","      <td>2022-08-11T20:53:15.644Z</td>\n","      <td>2022-09-07T11:02:00.344Z</td>\n","      <td>8a8a319bea0b3bff580d8507ae6470ba37e87791171886...</td>\n","      <td>RUMORS_LINE_BOT</td>\n","      <td>...</td>\n","      <td>my5ep5z69tql</td>\n","      <td>y22DlmsBFV14knB4ErTJ</td>\n","      <td>d16417c7ce4ab67ac5a7901ce62621445db3e06da5da6f...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>RUMOR</td>\n","      <td>WEBSITE</td>\n","      <td>NORMAL</td>\n","      <td>2022-09-07T22:59:48.921Z</td>\n","      <td>2022-09-07T22:59:48.921Z</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3dnh713ikpf3c</td>\n","      <td>TEXT</td>\n","      <td>NORMAL</td>\n","      <td>å…ˆå’Œä½ ç°¡å–®ä»‹ç´¹\\næˆ‘å€‘èª å¾µç·šä¸Šæ‰“å·¥å°å¹«æ‰‹\\nå·¥ä½œå…§å®¹æœ‰ï¼šè½å¯«æ‰“å­—ã€é é¢æ’ç‰ˆã€å•†å“è©•è«–åˆ·æµé‡ã€...</td>\n","      <td>1.0</td>\n","      <td>2022-09-07T10:10:41.742Z</td>\n","      <td>2022-09-07T10:10:41.742Z</td>\n","      <td>2022-09-07T10:10:41.761Z</td>\n","      <td>47e90b2538a5615b323f50571b77d91f7f105e55684aa1...</td>\n","      <td>RUMORS_LINE_BOT</td>\n","      <td>...</td>\n","      <td>3dnh713ikpf3c</td>\n","      <td>H8Hz4WsBqwaEkHKwtyFm</td>\n","      <td>d16417c7ce4ab67ac5a7901ce62621445db3e06da5da6f...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>RUMOR</td>\n","      <td>WEBSITE</td>\n","      <td>NORMAL</td>\n","      <td>2022-09-07T23:00:19.207Z</td>\n","      <td>2022-09-07T23:00:19.207Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 21 columns</p>\n","</div>"],"text/plain":["              id articleType status_x  \\\n","0  14h550ymn3m3u        TEXT   NORMAL   \n","1  326xjpkjbf01i        TEXT   NORMAL   \n","2   oupi0eu9aocr        TEXT   NORMAL   \n","3   my5ep5z69tql        TEXT   NORMAL   \n","4  3dnh713ikpf3c        TEXT   NORMAL   \n","\n","                                                text  normalArticleReplyCount  \\\n","0  BA.5ç—…æ¯’å¼•ç™¼çš„ä¸åªã€Œç¸®çŸ­æ½›ä¼æœŸï¼Œå¢åŠ R0å€¼ã€ï¼Œé‚„æœ‰æ˜“ä½¿äººã€Œå†æ„ŸæŸ“ï¼ˆReinfecionï¼‰...                      1.0   \n","1                       https://youtu.be/xK9NzL3PkdE                      0.0   \n","2  è¢«å–æ¶ˆçš„èˆªç­\\n\\n2018å¹´çš„ä¸€å¤©ï¼Œæˆ‘å¾æ´›æ‰ç£¯å›åœ‹ï¼Œä¹˜åå‡Œæ™¨ä¸€é»çš„åœ‹èˆªèˆªç­ï¼Œé¦¬ä¸Šè¦ç™»æ©Ÿäº†ï¼Œ...                      1.0   \n","3  ä½ å¥½ğŸ‘±ğŸ»â€â™€ï¸\\n\\nç°¡å–®è·Ÿä½ èªªä¸€ä¸‹å…¬å¸å·¥ä½œå…§å®¹ï¼š\\næˆ‘å€‘æ˜¯åšè³¼ç‰©ç³»çµ±è¨‚å–®çš„å·¥ä½œï¼Œä¸»è¦å°±æ˜¯å¢...                      1.0   \n","4  å…ˆå’Œä½ ç°¡å–®ä»‹ç´¹\\næˆ‘å€‘èª å¾µç·šä¸Šæ‰“å·¥å°å¹«æ‰‹\\nå·¥ä½œå…§å®¹æœ‰ï¼šè½å¯«æ‰“å­—ã€é é¢æ’ç‰ˆã€å•†å“è©•è«–åˆ·æµé‡ã€...                      1.0   \n","\n","                createdAt_x               updatedAt_x  \\\n","0  2022-09-05T05:26:33.360Z  2022-09-05T05:26:33.360Z   \n","1  2022-09-08T12:34:27.602Z  2022-09-08T12:34:27.602Z   \n","2  2021-11-13T16:36:56.548Z  2021-11-13T16:36:56.548Z   \n","3  2022-08-11T20:53:15.644Z  2022-08-11T20:53:15.644Z   \n","4  2022-09-07T10:10:41.742Z  2022-09-07T10:10:41.742Z   \n","\n","            lastRequestedAt  \\\n","0  2022-09-05T05:26:33.381Z   \n","1  2022-09-08T12:34:27.634Z   \n","2  2022-04-27T08:52:17.115Z   \n","3  2022-09-07T11:02:00.344Z   \n","4  2022-09-07T10:10:41.761Z   \n","\n","                                      userIdsha256_x          appId_x  ...  \\\n","0  3753ca22ca96f5fc1f13e62291f28e405d56b1a976b21d...  RUMORS_LINE_BOT  ...   \n","1  243b5897c14f02fb5b92a9e4f4cc39d5fb84ff16173add...  RUMORS_LINE_BOT  ...   \n","2  4a266a6fdefc88e59eef644402e97c7f4c8196becca686...  RUMORS_LINE_BOT  ...   \n","3  8a8a319bea0b3bff580d8507ae6470ba37e87791171886...  RUMORS_LINE_BOT  ...   \n","4  47e90b2538a5615b323f50571b77d91f7f105e55684aa1...  RUMORS_LINE_BOT  ...   \n","\n","       articleId               replyId  \\\n","0  14h550ymn3m3u  6oo8DYMBv5it-Cx_8405   \n","1            NaN                   NaN   \n","2   oupi0eu9aocr  MYotCYMBv5it-Cx_gIpH   \n","3   my5ep5z69tql  y22DlmsBFV14knB4ErTJ   \n","4  3dnh713ikpf3c  H8Hz4WsBqwaEkHKwtyFm   \n","\n","                                      userIdsha256_y negativeFeedbackCount  \\\n","0  6892d0026181e95d034bf8781025afbf395d57cc88ac05...                   0.0   \n","1                                                NaN                   NaN   \n","2  fc9652aa205dab75e19ecff420945e95aa3909a54b0d9a...                   0.0   \n","3  d16417c7ce4ab67ac5a7901ce62621445db3e06da5da6f...                   0.0   \n","4  d16417c7ce4ab67ac5a7901ce62621445db3e06da5da6f...                   0.0   \n","\n","   positiveFeedbackCount    replyType  appId_y status_y  \\\n","0                    3.0        RUMOR  WEBSITE   NORMAL   \n","1                    NaN          NaN      NaN      NaN   \n","2                    1.0  OPINIONATED  WEBSITE   NORMAL   \n","3                    1.0        RUMOR  WEBSITE   NORMAL   \n","4                    1.0        RUMOR  WEBSITE   NORMAL   \n","\n","                createdAt_y               updatedAt_y  \n","0  2022-09-05T10:40:41.789Z  2022-09-05T10:40:41.789Z  \n","1                       NaN                       NaN  \n","2  2022-09-04T15:45:20.464Z  2022-09-04T15:45:20.464Z  \n","3  2022-09-07T22:59:48.921Z  2022-09-07T22:59:48.921Z  \n","4  2022-09-07T23:00:19.207Z  2022-09-07T23:00:19.207Z  \n","\n","[5 rows x 21 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["articles = load_dataset(\"Cofacts/line-msg-fact-check-tw\", \"articles\") # article contents and some meta info\n","article_replies = load_dataset(\"Cofacts/line-msg-fact-check-tw\", \"article_replies\") # 'join table' for articles and replies with added meta info\n","art_rep_df = pd.merge(articles[\"train\"].to_pandas(), article_replies[\"train\"].to_pandas(), left_on=\"id\", right_on=\"articleId\", how=\"left\")\n","art_rep_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzGoLqlDV0ld"},"outputs":[],"source":["def remove_url(text: str):\n","    regex = r\"https?\\S+|\\S*\\.com\\S*\"\n","    text = re.sub(\"\\n\", \" \", text) # also remove newlines. Beware trailing whitespaces\n","    text = re.sub(regex, \"\", text)\n","    if len(text) == 0:\n","        text = pd.NA\n","    return text\n","\n","def filter_unicodes(texts: list):\n","    retain = list()\n","    remove = list()\n","    for t in texts:\n","        if pd.notna(t):\n","            regex = re.compile(r\"[^\\u4E00-\\u9FFF\\u3000-\\u303F\\u0000-\\u007F\\u2000-\\u206F\\uFF00-\\uFF65]\")\n","            filtered_txt = regex.sub(\"\", t)\n","            retain.append(filtered_txt)\n","            deleted = regex.findall(t)\n","            remove.append(deleted)\n","        else:\n","            retain.append(t)\n","    remove = Counter([i for l in remove for i in l])\n","    return retain, remove\n","\n","def find_unicodes(chars: list):\n","    out = {char : char.encode(\"unicode_escape\") for char in chars}\n","    return out\n","\n","# processing steps\n","clean_df = art_rep_df.copy()\n","clean_df = clean_df[clean_df[\"replyType\"] != \"NOT_ARTICLE\"] # remove non articles\n","clean_df = clean_df.dropna(subset=[\"text\", \"replyType\"]) # drop na's\n","clean_df[\"text\"] = clean_df[\"text\"].apply(remove_url) # delete urls\n","clean_df[\"text\"], remove = filter_unicodes(clean_df[\"text\"]) # filter for chinese and latin script\n","clean_df = clean_df.dropna(subset=[\"text\", \"replyType\"])\n","clean_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["0647532a792d43488361d96b96555355","0857de5c26744e2a99bac0683f7a0f77","6830561fe5d84033ab12bb7e03586506","49fc19efbeab464bbd18fe35e0fd28c8"]},"id":"S5-3xQ8WV0lg","outputId":"6120c224-77b9-4ef7-fbe4-60496da69169"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0647532a792d43488361d96b96555355","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0857de5c26744e2a99bac0683f7a0f77","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6830561fe5d84033ab12bb7e03586506","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49fc19efbeab464bbd18fe35e0fd28c8","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n","\n","listed = clean_df[['text','replyType']].dropna().copy()\n","listed['replyType'] = listed['replyType'].map(lambda x: x.replace(\"NOT_RUMOR\", \"0\"))\n","listed['replyType'] = listed['replyType'].map(lambda x: x.replace(\"OPINIONATED\", \"1\"))\n","listed['replyType'] = listed['replyType'].map(lambda x: x.replace(\"RUMOR\", \"2\"))\n","listed['replyType'] = listed['replyType'].astype(int)\n","listed['tokenizer'] = [tokenizer(x[:500]) for x in listed['text']]\n","listed['tokens'] = [torch.tensor(x.input_ids, dtype=torch.long) for x in listed['tokenizer']]\n","listed['attention'] = [torch.tensor(x.attention_mask, dtype=torch.long) for x in listed['tokenizer']]\n","listed['replyType'] = listed['replyType'].map(lambda x: torch.tensor(x, dtype=torch.long))\n","#padded = torch.nn.utils.rnn.pad_sequence(listed['text'], batch_first=True)\n","padded_tokens = torch.nn.utils.rnn.pad_sequence([i.flip(dims=[0]) for i in listed['tokens']], batch_first=True).flip(dims=[0])\n","padded_attention_mask = torch.nn.utils.rnn.pad_sequence([i.flip(dims=[0]) for i in listed['attention']], batch_first=True).flip(dims=[0])\n","zipped = list(zip(listed['tokens'], listed['replyType'], listed['attention']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hhmaEUsV0lh"},"outputs":[],"source":["# def k_fold_split_data(dataset, batch_size, k=5):\n","#     n = len(dataset)\n","#     fold_size = n // k\n","#     folds = []\n","\n","#     def collate_fn(data):\n","#         tensors, targets = zip(*data)\n","#         features = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n","#         targets = torch.stack(targets)\n","#         return features, targets\n","\n","#     for i in range(k):\n","#         start = i * fold_size\n","#         end = (i + 1) * fold_size if i < k - 1 else n\n","#         folds.append(torch.utils.data.Subset(dataset, range(start, end)))\n","\n","#     dataloaders = []\n","#     for i in range(k):\n","#         validation_dataset = folds[i]\n","#         train_folds = [folds[j] for j in range(k) if j != i]\n","#         train_dataset = torch.utils.data.ConcatDataset(train_folds)\n","\n","#         y = torch.tensor([label for _, label in train_dataset], dtype=torch.long)\n","\n","#         global class_weights\n","#         class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y.numpy())\n","#         class_weights = torch.tensor(class_weights, dtype=torch.float)\n","\n","#         train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","#         validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","#         dataloaders.append((train_dataloader, validation_dataloader))\n","\n","#     return dataloaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7a2FBUsV0li"},"outputs":[],"source":["def randomly_split_data(dataset, batch_size):\n","\n","\n","    #generator = torch.Generator().manual_seed(42)\n","    #train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=generator)\n","    train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1])\n","\n","    y = torch.tensor([label for _, label, _ in dataset], dtype=torch.long)\n","\n","    def collate_fn(data):\n","        tensors, targets, attention_mask = zip(*data)\n","        features = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n","        targets = torch.stack(targets)\n","        attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True)\n","        return features, targets, attention_mask\n","\n","    global class_weights\n","    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y.numpy())\n","    class_weights = torch.tensor(class_weights, dtype=torch.float)\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","\n","    return train_dataloader, validation_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwVW-giXV0lk"},"outputs":[],"source":["class TuneableModel(torch.nn.Module):\n","    def __init__(self, input_size, layer_size, dropout_rate, n_layers):\n","        super(TuneableModel, self).__init__()\n","        self.roberta = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n","        self.requires_grad_(False)\n","        self.lstm = torch.nn.LSTM(input_size=32, hidden_size=layer_size, bidirectional=False,\n","                                  num_layers=n_layers, batch_first=True, dropout=dropout_rate, proj_size=3)\n","        self.downshift = torch.nn.Linear(768, 32)\n","        # self.output_layer = torch.nn.Linear(1, 3)\n","        #self.batchnorm = torch.nn.BatchNorm1d(32)\n","        self.activation = torch.nn.ReLU()\n","        # self.linear = torch.nn.Linear(layer_size, layer_size)\n","\n","    def forward(self, x, attention_mask):\n","        x = self.roberta(x, attention_mask=attention_mask).last_hidden_state\n","        x = self.downshift(x)\n","        #x = self.batchnorm(x)\n","        x = self.activation(x)\n","        x = self.lstm(x)\n","        #print(x[0].shape)\n","        #x = self.activation(x)\n","        # x = self.linear(x)\n","        # x = self.batchnorm(x)\n","        # x = self.activation(x)\n","        # x = self.output_layer(x[0][:,-1:])\n","        return x[0][:,-1,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3L-PL9HV0lm"},"outputs":[],"source":["def train_test(model, dataloader, optimizer, training=\"train\"):\n","\n","    loss_function = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n","\n","    if training == \"train\":\n","        model.train()\n","    elif training == \"validation\":\n","        model.eval()\n","    elif training == \"test\":\n","        model.eval()\n","    else:\n","        raise ValueError(\"training argument must be either 'train', 'validation' or 'test'\")\n","\n","    cumulative_loss = 0\n","    prediction_list = []\n","    label_list = []\n","    for sample in tqdm(dataloader):\n","        if training == \"train\":\n","            optimizer.zero_grad()\n","        input, targets, attention_mask = sample[0].to(device).long(), sample[1].to(device), sample[2].to(device)\n","        output = model(input, attention_mask).to(device)\n","        loss_value = loss_function(output, targets)\n","        cumulative_loss += loss_value.item()\n","        if training == \"train\":\n","            print(\"batch loss:\", loss_value.sum().item())\n","            loss_value.sum().backward()\n","            optimizer.step()\n","\n","        predictions = output.to('cpu').detach().numpy().argmax(axis=1)\n","        target_labels = sample[1]\n","        prediction_list.extend(predictions)\n","        label_list.extend(target_labels)\n","    #f1 = f1_score(label_list, prediction_list)\n","    accuracy = accuracy_score(label_list, prediction_list)\n","    #confusion = confusion_matrix(label_list, prediction_list)\n","\n","    return cumulative_loss, accuracy#, f1, confusion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2vnB-czV0ln"},"outputs":[],"source":["# Training sample\n","def evaluate(params, dataset):\n","    dropout, hidden_size, learning_rate, batch_size, n_hidden = params\n","\n","    max_epochs = 1000\n","    max_patience = 5\n","    seed = 42\n","\n","    accuracies = []\n","    f1s = []\n","    train_dataloader, validation_dataloader, test_dataloader = randomly_split_data(dataset, batch_size)\n","    #dataloaders = k_fold_split_data(dataset, batch_size, k=5)\n","    # train_dataloader, validation_dataloader = dataloader[0], dataloader[1]\n","    # test_dataloader = dataloader[1]\n","    PATH = \"model_.pt\"\n","    last_loss = 1000000\n","    torch.manual_seed(seed)\n","    input_size = train_dataloader.dataset[0][0].size()[0]\n","    model = TuneableModel(input_size, hidden_size, dropout, n_hidden)\n","    model.to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","    for epoch in range(max_epochs):\n","        # training\n","        train_loss, train_accuracy = train_test(model, train_dataloader, optimizer, training=\"train\")\n","        train_loss, train_accuracy = train_loss, round(train_accuracy, 4)\n","        # validation at end of epoch\n","        validation_loss, validation_accuracy = train_test(model, validation_dataloader, optimizer, training=\"validation\")\n","        validation_loss, validation_accuracy = validation_loss, round(validation_accuracy, 4)\n","        if validation_loss < last_loss:\n","            last_loss = validation_loss\n","            current_patience = 0\n","        else:\n","            if current_patience == 0:\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'loss': last_loss,\n","                    }, PATH)\n","            current_patience += 1\n","        if current_patience == max_patience:\n","            break\n","        if epoch % 1 == 0:\n","            print(f\"Epoch {epoch} validation loss: {validation_loss} validation accuracy: {validation_accuracy*100}%\")\n","    # Testing once patience is reached\n","    torch.manual_seed(seed)\n","    model = TuneableModel(input_size, hidden_size, dropout, n_hidden)\n","    model.to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","    checkpoint = torch.load(PATH)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    test_loss, test_accuracy = train_test(model, test_dataloader, optimizer, training=\"test\")\n","    test_loss, test_accuracy = test_loss, test_accuracy\n","    #print(f\"Model {i} at epoch {checkpoint['epoch']} test results: accuracy: {test_accuracy*100}% f1: {test_f1}\")\n","    # accuracies.append(test_accuracy)\n","    # f1s.append(test_f1)\n","    #print(test_confusion)\n","\n","    return round(test_accuracy*100, 2)\n","    # print(f\"Average accuracy: {round(np.mean(accuracies), 2)}%\")\n","    # print(f\"Average f1: {round(np.mean(f1s), 2)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f4027cd2f3fa4455858ad9808b4882e6"]},"id":"i-sf3a8XV0lo","outputId":"319a693e-9e7c-45be-ca96-962147747497"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4027cd2f3fa4455858ad9808b4882e6","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  0%|          | 1/1657 [00:02<1:06:11,  2.40s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1014227867126465\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 2/1657 [00:04<1:00:02,  2.18s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.11203932762146\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 3/1657 [00:06<56:43,  2.06s/it]  "]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1181036233901978\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 4/1657 [00:08<54:22,  1.97s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0712642669677734\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 5/1657 [00:09<50:48,  1.85s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.211561918258667\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 6/1657 [00:11<53:18,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0958173274993896\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 7/1657 [00:13<52:38,  1.91s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1169003248214722\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 8/1657 [00:15<53:04,  1.93s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0982500314712524\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 9/1657 [00:17<54:34,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.120307445526123\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 10/1657 [00:19<54:48,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0847809314727783\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 11/1657 [00:21<53:59,  1.97s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1137760877609253\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 12/1657 [00:23<54:23,  1.98s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1153098344802856\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 13/1657 [00:25<55:00,  2.01s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0822285413742065\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 14/1657 [00:27<54:28,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1083118915557861\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 15/1657 [00:29<54:20,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0972511768341064\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 16/1657 [00:31<54:03,  1.98s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0950779914855957\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 17/1657 [00:33<55:11,  2.02s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1046632528305054\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 18/1657 [00:35<52:42,  1.93s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0879549980163574\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 19/1657 [00:37<54:18,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0855287313461304\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 20/1657 [00:40<56:48,  2.08s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0891175270080566\n"]},{"name":"stderr","output_type":"stream","text":["  1%|â–         | 21/1657 [00:41<55:55,  2.05s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0958988666534424\n"]},{"name":"stderr","output_type":"stream","text":["  1%|â–         | 22/1657 [00:43<55:11,  2.03s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0926786661148071\n"]},{"name":"stderr","output_type":"stream","text":["  1%|â–         | 23/1657 [00:46<56:24,  2.07s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.094404935836792\n"]},{"name":"stderr","output_type":"stream","text":["  1%|â–         | 24/1657 [00:48<58:50,  2.16s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0656906366348267\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 25/1657 [00:50<1:00:00,  2.21s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1030504703521729\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 26/1657 [00:52<57:37,  2.12s/it]  "]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1017682552337646\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 27/1657 [00:55<59:36,  2.19s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1300958395004272\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 28/1657 [00:56<57:00,  2.10s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1022788286209106\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 29/1657 [00:59<56:26,  2.08s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0873093605041504\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 30/1657 [01:00<54:15,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1181548833847046\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 31/1657 [01:02<53:00,  1.96s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0672825574874878\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 32/1657 [01:05<59:31,  2.20s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.10356867313385\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 33/1657 [01:06<53:57,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.076945185661316\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 34/1657 [01:09<54:28,  2.01s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0975340604782104\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 35/1657 [01:11<57:13,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0912588834762573\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 36/1657 [01:13<57:18,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.113524317741394\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 37/1657 [01:15<55:09,  2.04s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.091995358467102\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 38/1657 [01:17<57:21,  2.13s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.112212896347046\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 39/1657 [01:19<58:02,  2.15s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.089670181274414\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 40/1657 [01:21<53:54,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1043676137924194\n"]},{"name":"stderr","output_type":"stream","text":["  2%|â–         | 41/1657 [01:23<53:53,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1174427270889282\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 42/1657 [01:25<54:32,  2.03s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0980594158172607\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 43/1657 [01:27<53:41,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.085623025894165\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 44/1657 [01:29<55:16,  2.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0999783277511597\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 45/1657 [01:31<55:21,  2.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1111550331115723\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 46/1657 [01:33<55:33,  2.07s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1235469579696655\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 47/1657 [01:36<57:50,  2.16s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1107673645019531\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 48/1657 [01:38<57:14,  2.13s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1048129796981812\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 49/1657 [01:40<57:18,  2.14s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.105818748474121\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 50/1657 [01:42<56:15,  2.10s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1114445924758911\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 51/1657 [01:44<53:43,  2.01s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0835657119750977\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 52/1657 [01:46<51:09,  1.91s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0963319540023804\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 53/1657 [01:47<51:09,  1.91s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1091700792312622\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 54/1657 [01:49<49:23,  1.85s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0909062623977661\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 55/1657 [01:51<52:12,  1.96s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1014007329940796\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 56/1657 [01:53<51:50,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.095099687576294\n"]},{"name":"stderr","output_type":"stream","text":["  3%|â–         | 57/1657 [01:55<51:58,  1.95s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.08566415309906\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 58/1657 [01:57<53:08,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0924010276794434\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 59/1657 [01:58<45:43,  1.72s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1028034687042236\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 60/1657 [02:00<48:07,  1.81s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1049513816833496\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 61/1657 [02:03<51:14,  1.93s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.106142282485962\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 62/1657 [02:05<52:34,  1.98s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0970103740692139\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 63/1657 [02:07<52:59,  1.99s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.086296796798706\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 64/1657 [02:09<53:08,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1016559600830078\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 65/1657 [02:11<52:03,  1.96s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0939066410064697\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 66/1657 [02:13<53:02,  2.00s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0872141122817993\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 67/1657 [02:15<52:22,  1.98s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0906717777252197\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 68/1657 [02:17<53:43,  2.03s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0984325408935547\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 69/1657 [02:19<53:31,  2.02s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0887190103530884\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 70/1657 [02:20<50:37,  1.91s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0983613729476929\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 71/1657 [02:23<52:01,  1.97s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0905240774154663\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 72/1657 [02:24<50:59,  1.93s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1059234142303467\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 73/1657 [02:26<51:58,  1.97s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1025713682174683\n"]},{"name":"stderr","output_type":"stream","text":["  4%|â–         | 74/1657 [02:28<51:06,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1048094034194946\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 75/1657 [02:30<50:11,  1.90s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0999257564544678\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 76/1657 [02:32<50:24,  1.91s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0875896215438843\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 77/1657 [02:34<51:06,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.088308572769165\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 78/1657 [02:36<51:01,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0914332866668701\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 79/1657 [02:38<51:39,  1.96s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0933387279510498\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 80/1657 [02:40<50:57,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0795550346374512\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 81/1657 [02:42<50:52,  1.94s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0955913066864014\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 82/1657 [02:44<51:33,  1.96s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0975092649459839\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 83/1657 [02:46<53:02,  2.02s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0991755723953247\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 84/1657 [02:48<54:36,  2.08s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1038089990615845\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 85/1657 [02:50<55:34,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0702301263809204\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 86/1657 [02:52<54:52,  2.10s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0821434259414673\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 87/1657 [02:54<53:33,  2.05s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0999468564987183\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 88/1657 [02:56<53:29,  2.05s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0918959379196167\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 89/1657 [02:59<55:32,  2.13s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1020541191101074\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 90/1657 [03:01<54:01,  2.07s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.055096983909607\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 91/1657 [03:03<56:32,  2.17s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1021034717559814\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 92/1657 [03:05<53:48,  2.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1060577630996704\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 93/1657 [03:07<57:00,  2.19s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0960887670516968\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 94/1657 [03:10<58:59,  2.26s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1308492422103882\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 95/1657 [03:12<57:47,  2.22s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1024338006973267\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 96/1657 [03:14<55:07,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1210936307907104\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 97/1657 [03:16<53:35,  2.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0634223222732544\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 98/1657 [03:18<53:29,  2.06s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1263489723205566\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 99/1657 [03:20<55:52,  2.15s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0841271877288818\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 100/1657 [03:22<56:08,  2.16s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.103926658630371\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 101/1657 [03:25<55:53,  2.16s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1050623655319214\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 102/1657 [03:26<53:36,  2.07s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1159710884094238\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–Œ         | 103/1657 [03:29<54:35,  2.11s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0955731868743896\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–‹         | 104/1657 [03:30<52:34,  2.03s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1061750650405884\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–‹         | 105/1657 [03:33<58:56,  2.28s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1003855466842651\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–‹         | 106/1657 [03:36<59:37,  2.31s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0836336612701416\n"]},{"name":"stderr","output_type":"stream","text":["  6%|â–‹         | 107/1657 [03:38<57:44,  2.23s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0858938694000244\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 108/1657 [03:40<56:47,  2.20s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0905325412750244\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 109/1657 [03:42<57:53,  2.24s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1072860956192017\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 110/1657 [03:45<59:08,  2.29s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1086440086364746\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 111/1657 [03:47<57:49,  2.24s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0957553386688232\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 112/1657 [03:49<54:41,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0948846340179443\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 113/1657 [03:51<55:50,  2.17s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1077762842178345\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 114/1657 [03:53<55:13,  2.15s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.099075436592102\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 115/1657 [03:55<54:29,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1065552234649658\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 116/1657 [03:57<55:27,  2.16s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.1200910806655884\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 117/1657 [03:59<55:06,  2.15s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0835766792297363\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 118/1657 [04:01<53:29,  2.09s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.092104434967041\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 119/1657 [04:03<53:05,  2.07s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0874273777008057\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 120/1657 [04:06<54:04,  2.11s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0872187614440918\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 121/1657 [04:08<54:23,  2.12s/it]"]},{"name":"stdout","output_type":"stream","text":["batch loss: 1.0957530736923218\n"]},{"name":"stderr","output_type":"stream","text":["  7%|â–‹         | 121/1657 [04:10<52:57,  2.07s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/wolfingten/ml/misinformation/crappy_first_model.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m zipped\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m params \u001b[39m=\u001b[39m (\u001b[39m0.0\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m accuracy\u001b[39m=\u001b[39m evaluate(params, dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfinal test accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[1;32m/home/wolfingten/ml/misinformation/crappy_first_model.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train_test(model, train_dataloader, optimizer, training\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train_loss, \u001b[39mround\u001b[39m(train_accuracy, \u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# validation at end of epoch\u001b[39;00m\n","\u001b[1;32m/home/wolfingten/ml/misinformation/crappy_first_model.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39minput\u001b[39m, targets, attention_mask \u001b[39m=\u001b[39m sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mlong(), sample[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device), sample[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m, attention_mask)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss_value \u001b[39m=\u001b[39m loss_function(output, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m cumulative_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_value\u001b[39m.\u001b[39mitem()\n","File \u001b[0;32m~/.python_environments/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.python_environments/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/home/wolfingten/ml/misinformation/crappy_first_model.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#x = self.batchnorm(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#print(x[0].shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#x = self.activation(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# x = self.linear(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# x = self.batchnorm(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# x = self.activation(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# x = self.output_layer(x[0][:,-1:])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wolfingten/ml/misinformation/crappy_first_model.ipynb#X45sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x[\u001b[39m0\u001b[39m][:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n","File \u001b[0;32m~/.python_environments/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.python_environments/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.python_environments/ML/lib/python3.11/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    879\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    880\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataset = zipped\n","params = (0.0, 10, 0.01, 32, 1)\n","accuracy= evaluate(params, dataset)\n","print(f\"final test accuracy: {accuracy}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05235f8ff8e54741aebc06e748c66cc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05b4232f95ff41a0badfd34aa54a630a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0928992e87a94488b705e18bf6ac93f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_571d9caa54ba46e593d54d08d0aa5fa1","style":"IPY_MODEL_0fe5f5cd897949bd9fb6c811d7317eac","value":true}},"0fe5f5cd897949bd9fb6c811d7317eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"162d1e59d6bd4ac688a59991d333c53c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f63c70e2d67048c28395bdfb47d4b46e","IPY_MODEL_51d3197a15a940a293729a6109abed8f","IPY_MODEL_0928992e87a94488b705e18bf6ac93f1","IPY_MODEL_d4dfc7aa6600480785aed23c0c464886","IPY_MODEL_cb178798ef0c416a88829ae4a625bbf3"],"layout":"IPY_MODEL_7a22b37f51b54d17b291332fb5066d62"}},"392935d7bc0249f28ff4004fedaa06c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51d3197a15a940a293729a6109abed8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_c269b3fc8311446e895abb4fba8308ce","placeholder":"â€‹","style":"IPY_MODEL_b00f37b269a643a6943fadeaeddf6046","value":""}},"571d9caa54ba46e593d54d08d0aa5fa1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d9542811bd740608587dba37797fad1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a22b37f51b54d17b291332fb5066d62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"b00f37b269a643a6943fadeaeddf6046":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c269b3fc8311446e895abb4fba8308ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6899887dadf4f20b7aa37311c3d83f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb178798ef0c416a88829ae4a625bbf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_392935d7bc0249f28ff4004fedaa06c3","placeholder":"â€‹","style":"IPY_MODEL_5d9542811bd740608587dba37797fad1","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"cc8d0d8c3c7a416087ca32548f4d2208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"d4dfc7aa6600480785aed23c0c464886":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_05b4232f95ff41a0badfd34aa54a630a","style":"IPY_MODEL_cc8d0d8c3c7a416087ca32548f4d2208","tooltip":""}},"f63c70e2d67048c28395bdfb47d4b46e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05235f8ff8e54741aebc06e748c66cc4","placeholder":"â€‹","style":"IPY_MODEL_c6899887dadf4f20b7aa37311c3d83f7","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}}}}},"nbformat":4,"nbformat_minor":0}
